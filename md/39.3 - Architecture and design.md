

# 3.1 - Motivation

As described previously in **39.2 - Literature review#2.2 - Analysis of existing synthesizers**, with the notable exception of **ForTrace** and its related synthesizers, no synthesizer been an extension of another synthesizer. This raises the question – why reinvent the wheel by developing yet another distinct architecture for this thesis? This subchapter briefly explores the deficiencies in existing synthesizers and explains why these are issues that warrant building a new architecture from scratch, rather than extending an existing synthesizer. 

The motivations for developing completely new codebases instead of extending existing synthesizers has varied considerably over the years. One reason is that several synthesizers are not open-source and therefore cannot easily be extended, as is the case with **Forensig2** and **TraceGen**. Another reason is that the focus of certain synthesizers resulted in a codebase that is simply incompatible with the goals of newer works. For example, **ForGe**'s architecture focuses largely on direct filesystem manipulation to generate forensic artifacts, and is therefore not suitable for a synthesizer that requires a virtualized operating system. Synthesizers such as **VMPOP**, which exclusively leverages agentless artifact generation as described in **39.4 - Action automation#4.2 - Agentless artifact generation**, require significant architectural changes to support agent-based artifact generation. 

However, perhaps the largest motivation for constructing new synthesizers is simply the lack of ongoing support for virtually all synthesizers. It appears that no synthesizer has gained significant traction within the broader forensic community, possibly with the exception of **ForTrace**; for the synthesizers that *are* open source, none of them are under active development and maintanance. Additionally, the forensic datasets generated by these synthesizers have not seen significant adoption in either education or research; many instructors continue to use the human-generated datasets available on public platforms.

The inflexibility of prior synthesizers, combined with the overall lack of support and success of synthesizer-based datasets, contributes to the disparate codebases that are now observed today. However, this is not to say that the individual contributions of each prior synthesizer cannot be merged into a single project that resolves many of the architectural barriers that have reduced the adoption and extension of existing synthesizers. 

In turn, AKF is built on the following four pillars to help promote its long-term usage. In particular, it allows it to generate datasets that address several of the considerations raised by Horsman and Lyle in the construction of various datasets, such as the need for comprehensive documentation, an awareness of the "realism" of the resulting dataset, and transparency in the scenario development process [@horsmanDatasetConstructionChallenges2021].

First, AKF conforms to modern Python development practices. This includes the use of modern project management practices (such as the use of *uv* and `pyproject.toml`, rather than the use of `setup.py` observed in older synthesizers), as well as static linters (*flake8*) and style enforcers (*black*, *isort*) to promote adherence to the PEP8 standard. Additionally, AKF's libraries make heavy use of Python 3.11+ features, such as type hinting and special type annotations, which allows for tools such as *mypy* to perform static type checking. In addition to greatly improving the development experience, these practices also increase the likelihood of discovering errors earlier in the development process.

Second, AKF takes a modular, agent-based approach to implementing application-specific functionality. This allows AKF to use existing automation frameworks for web browsers and other applications, greatly simplifying the codebase when compared to the same features implemented in other synthesizers. This focus on flexibility makes it significantly easier to install the agent, implement new application-specific features, and more - a particularly important design focus given AKF's dependence on agents for the majority of its application-specific functionality.

Third, AKF is architected to maintain feature parity with all prior synthesizers. That is, although AKF deviates considerably from the implementation details of prior synthesizers, this does not come at the loss of prior advancements in the field. In particular, AKF supports all three artifact generation techniques described in **39.4 - Action automation** using hypervisor-agnostic interfaces, reducing the tight coupling that made certain features difficult to implement in prior synthesizers. This reduces the likelihood that a new feature or technique will require a significant architectural change to support it.

Finally, AKF is designed with the explicit intent of developing an ecosystem of AKF-generated datasets, promoting long-term usage. This is reflected in the design of AKF's logging and reporting mechanisms as described in **39.5 - Output and validation**; the use of an RDF-based standard, CASE, allows for arbitrarily complex queries to be made against AKF datasets. These queries can be made in bulk, significantly improving the ability of researchers to find and use datasets that may be relevant to them.

These four pillars reflect throughout the design of AKF's architecture, which is described in the following section and the next three chapters of this thesis.

# 3.2 - Overview

At a minimum, every synthesizer must fulfill these high-level requirements through some means, largely derived from the criteria developed by Horsman and Lyle [@horsmanDatasetConstructionChallenges2021]:

- The synthesizer must accept commands on how it should operate. These commands should serve as a form of self-documentation, in which it is clear to another person *what* the expected contents of the image are, as well as the intent behind these commands. 
- The synthesizer must be able to accept external inputs, such as files and other binary data, to be included in any final outputs. 
- The synthesizer must implement the mechanisms and technologies necessary to carry out the commands it has been provided – that is, it must be able to generate artifacts. Such mechanisms should be independently verifiable, and preferably leave as little extraneous information as possible.
- The synthesizer must be able to generate a final output (such as a disk image), along with ground truth and reporting that describes the expected contents of that image. This should include a well-structured description of the dataset, a unique identifier for the dataset, and an explicit identification of any data of "evidential value" where possible.

- The synthesizer must be able to generate a final output (such as a disk image), along with ground truth and reporting that describes the expected contents of that image. This should include a well-structured description of the dataset, a unique identifier for the dataset, and an explicit identification of any data of "evidential value" where possible.
hese four requirements are fulfilled by various mechanisms throughout AKF. A complete architecture diagram is shown in the figure below.

!**Architecture 2025-02-07 17.07.24.excalidraw**

This can be simplified to the following high-level diagram, which broadly groups AKF into a set of seven modules:

!**Architecture 2025-02-08 16.35.46.excalidraw**

At a high level, this architecture can be broken up into three distinct concepts, each of which covers a distinct chapter.

The first set of modules are responsible for artifact generation. This encompasses three major systems - a hypervisor and its associated SDK, an OS-specific agent, and `akflib`. `akflib` is a Python library containing the abstract interfaces and concrete implementations necessary to generate individual artifacts and complete datasets. This includes routines for directly interacting with hypervisors, issuing commands to virtual machines, and directly modifying virtual hard drives. This library is also the foundation for OS-specific agents, which carry out actions on the virtual machine on behalf of the host. This is described in greater detail in **39.4 - Action automation**, and corresponds to the *action automation library*, the *OS-specific agent*, and the *virtual machine* (as well as the *user applications* running on the machine).

The second set of modules are responsible for logging and reporting. This encompasses both independent libraries for generating outputs and ground truth, as well as the various logging-related mechanisms that are contained throughout the artifact generation libraries. These modules are responsible for exporting and documenting artifacts generated by AKF; in particular, it makes heavy use of CASE, a standardized ontology for documenting the contents of forensic datasets [@caseyAdvancingCoordinatedCyberinvestigations2017]. This is covered in **39.5 - Output and validation**, and corresponds to the *output and validation library* and any associated components within the *action automation library*.

The final set of modules are responsible for invoking AKF itself and supporting scenario development. AKF is an *imperative* synthesizer, which means that commands are written and executed using an imperative language (here, Python 3) that dictates exactly *how* scenarios should be constructed. However, AKF also supports a *declarative* syntax, which allows users specifies *what* forensic artifacts and datasets are generated without the need to learn the AKF libraries and write Python code. Additionally, AKF contains generative AI tools for constructing scenarios in the declarative syntax as well as individual artifacts. This is described in **39.6 - Building scenarios**, and covers the *scenario construction library* and the *translation unit*, as well as any scripts that leverage AKF libraries.

The following three chapters will focus on these module groups. In simpler terms, this thesis addresses the following questions in order:

- How do we automate or streamline the generation of artifacts? 
- How do we document and report on the artifacts and datasets that are generated? 

- How do we document and report on the artifacts and datasets that are generated? 
 Given the solutions that address these two challenges, how do we actually use them to build scenarios? 
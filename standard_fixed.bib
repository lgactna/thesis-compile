@article{ceballosdelgadoFADEForensicImage2022,
	title = {{FADE}: {A} forensic image generator for android device education},
	volume = {4},
	copyright = {© 2021 Wiley Periodicals LLC.},
	issn = {2573-9468},
	shorttitle = {{FADE}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wfs2.1432},
	doi = {10.1002/wfs2.1432},
	abstract = {Realistic case studies are essential to training successful digital forensics examiners. However, the generation of realistic datasets is time-consuming and resource taxing. This paper presents a technical solution that populates Android emulators with realistic mobile forensic data. The emulator's data can be extracted into a raw disk image that is usable in mobile forensic training scenarios. In addition, the tool allows a user to populate the Android emulators with custom text messages, phone contacts, phone calls, and files. This population task is achieved by utilizing the Android Debug Bridge, Android Content Providers, SQLite databases, and the NodeJS runtime environment. This paper presents the software design and development, the requirements and limitations, and the testing process implemented in this research. The contribution of this paper is twofold. First, it identifies potential data and mechanisms to generate Android mobile forensic datasets using customized data population. Second, it creates a foundation for future research on the topic of mobile forensic emulators for training purposes. This article is categorized under: Digital and Multimedia Science {\textgreater} Mobile Forensics Crime Scene Investigation {\textgreater} Education and Formation},
	language = {en},
	number = {2},
	urldate = {2024-02-13},
	journal = {WIREs Forensic Science},
	author = {Ceballos Delgado, Alberto A. and Glisson, William B. and Grispos, George and Choo, Kim-Kwang Raymond},
	year = {2022},
	keywords = {Android forensics, data generation, mobile forensics},
	pages = {e1432}
}


@inproceedings{yannikosDataCorporaDigital2014,
	address = {Berlin, Heidelberg},
	series = {{IFIP} {Advances} in {Information} and {Communication} {Technology}},
	title = {Data {Corpora} for {Digital} {Forensics} {Education} and {Research}},
	isbn = {978-3-662-44952-3},
	doi = {10.1007/978-3-662-44952-3_21},
	abstract = {Data corpora are very important for digital forensics education and research. Several corpora are available to academia; these range from small manually-created data sets of a few megabytes to many terabytes of real-world data. However, different corpora are suited to different forensic tasks. For example, real data corpora are often desirable for testing forensic tool properties such as effectiveness and efficiency, but these corpora typically lack the ground truth that is vital to performing proper evaluations. Synthetic data corpora can support tool development and testing, but only if the methodologies for generating the corpora guarantee data with realistic properties.},
	language = {en},
	booktitle = {Advances in {Digital} {Forensics} {X}},
	publisher = {Springer},
	author = {Yannikos, York and Graner, Lukas and Steinebach, Martin and Winter, Christian},
	editor = {Peterson, Gilbert and Shenoi, Sujeet},
	year = {2014},
	keywords = {Forensic data corpora, model-based simulation, research/image-purpose, research/image-sources, research/synthesizer-details, synthetic disk images},
	pages = {309--325}
}


@misc{nationalinstituteofstandardsandtechnologyCFReDSPortal,
	title = {Computer {Forensic} {Reference} {Datasets} ({CFReDS})},
	url = {https://cfreds.nist.gov/},
	urldate = {2023-12-04},
	author = {{National Institute of Standards and Technology}},
	year = {2025},
}


@inproceedings{adelsteinAutomaticallyCreatingRealistic2005,
	title = {Automatically {Creating} {Realistic} {Targets} for {Digital} {Forensics} {Investigation}},
	url = {https://www.semanticscholar.org/paper/Automatically-Creating-Realistic-Targets-for-Adelstein-Gao/750d289378fa28f7d78fa2959194fdf6756f55c6},
	abstract = {The need for computer forensics education continues to grow, as digital evidence is present in more crimes, whether the crimes directly involve computers or not. An essential component of training in computer forensics is hands-on, realistic laboratory assignments. Creating detailed, realistic lab assignments, however, is a difficult task. The “crime” must be played out on the machine, often in real-time, since timestamps present in numerous places in the system, such as files and logs, must be discovered and examined by students. Developing, running, and evaluating the labs can be labor intensive and instructors have limited time to spend on creating and grading laboratory experiments. We are developing FALCON (Framework for Laboratory Exercises Conducted Over Networks), an extensible framework that addresses the problem of creating, running, and evaluating detailed, realistic computer laboratory assignments in computer forensics. FALCON includes a component that enables instructors to set up scenarios on virtual target machines for the students to investigate. Existing tools for both “live” and “dead” machine investigations can be integrated into FALCON. In addition, FALCON logs all student activity for automated assessment of student performance. Currently, FALCON is a work in progress and some tasks remain manual. The goal is to automatically transform high-level descriptions of digital forensics scenarios into detailed investigative targets which contain activities derived from the scenarios, as well as historical activity (timestamps, logs, history, etc.). While the initial version of FALCON focuses on computer forensics, it will be extensible to other areas, such as incident response, as well as general computer security instruction.},
	urldate = {2023-11-28},
	booktitle = {{DFRWS}},
	author = {Adelstein, F. and Gao, Yun and Richard, G.},
	year = {2005}
}


@article{grajedaAvailabilityDatasetsDigital2017,
	title = {Availability of datasets for digital forensics – {And} what is missing},
	volume = {22},
	issn = {17422876},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287617301913},
	doi = {10.1016/j.diin.2017.06.004},
	language = {en},
	urldate = {2023-11-06},
	journal = {Digital Investigation},
	author = {Grajeda, Cinthya and Breitinger, Frank and Baggili, Ibrahim},
	month = aug,
	year = {2017},
	keywords = {research/image-sources, research/image-gaps, research/manual-motivation, research/public-datasets},
	pages = {S94--S105}
}


@inproceedings{cooperStandardsDigitalForensics2010,
	address = {Ankara Turkey},
	title = {Towards standards in digital forensics education},
	isbn = {978-1-4503-0677-5},
	url = {https://dl.acm.org/doi/10.1145/1971681.1971688},
	doi = {10.1145/1971681.1971688},
	language = {en},
	urldate = {2023-11-26},
	booktitle = {Proceedings of the 2010 {ITiCSE} working group reports},
	publisher = {ACM},
	author = {Cooper, Peter and Finley, Gail T. and Kaskenpalo, Petteri},
	month = jun,
	year = {2010},
	keywords = {research/image-purpose, research/image-purpose/education},
	pages = {87--95}
}


@inproceedings{lawrenceFrameworkDesignWebbased2009,
	address = {New York, NY, USA},
	series = {{ACM}-{SE} 47},
	title = {Framework for the design of web-based learning for digital forensics labs},
	isbn = {978-1-60558-421-8},
	url = {https://dl.acm.org/doi/10.1145/1566445.1566546},
	doi = {10.1145/1566445.1566546},
	abstract = {Digital forensic education and training has been experiencing radical growth in the past ten years. The core of these training and academic programs is to develop a set of suitable hands-on digital forensic labs. To do this we first must familiarize ourselves with the tools of the trade. The main step to training students, who are preparing to be computer forensic professionals, lies in creating a comprehensive hands-on approach to computer forensics. The goal of this project work is to establish a series of hands-on computer forensic labs, which help students prepare to accede seamlessly into the law enforcement workforce and to make these labs available online by exploiting technologies of Web-based learning and future web developments, one of this includes the Semantic Web. The Semantic Web will enable intelligent services by several methods which all work towards making information machine-understandable [3]. With this we hope to develop an intelligent Web-based educational system which is capable of demonstrating some form of knowledge-based reasoning in lab sequencing, in analysis of the student's answers combining with students' background, and in providing interactive problem-solving support to the student, all adapted to the Web technology [3].},
	urldate = {2023-11-27},
	booktitle = {Proceedings of the 47th {Annual} {Southeast} {Regional} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Lawrence, Kevin R. and Chi, Hongmei},
	month = mar,
	year = {2009},
	keywords = {research/image-purpose, research/image-purpose/education, digital forensics, e-learning, forensics tools, hand-on labs, information systems, semantic web, web-based},
	pages = {1--4}
}


@inproceedings{guptaDigitalForensicsLab2022,
	title = {Digital {Forensics} {Lab} {Design}: {A} framework},
	shorttitle = {Digital {Forensics} {Lab} {Design}},
	url = {https://ieeexplore.ieee.org/document/9800799},
	doi = {10.1109/ISDFS55398.2022.9800799},
	abstract = {Internet connectivity and digital technologies have experienced exponential growth in the past few years. This explosion has spurred a significant increase in crime while also creating a new definition of cybercriminals. Digital Forensics plays an important role in crime reconstruction and thus the need for skilled forensics experts has multiplied. As a result, digital forensics education and training has also experienced radical growth. Teaching digital forensics has always been a challenge as the creation of suitable hands-on digital forensics labs has always been the core of these training programs. There are several challenges faced by both the educators and the students when it comes to the creation and implementation of digital forensics labs. This paper aims to address some of these issues by providing a framework that can be used by educators to establish educational hands-on labs for digital forensics. Firstly, we identify all the challenges faced by digital examiners, educators, and training professionals to deliver high-quality forensic labs. Secondly, we identify specific common technical pitfalls that professionals run into when designing digital forensics labs such as the creation of large image files. We thus, offer tips and tricks to make the process of creating digital forensic labs easier. Finally, we also provide a data set of small-sized image files that can be used by educators for the creation of a digital forensic lab infrastructure.},
	urldate = {2023-11-27},
	booktitle = {2022 10th {International} {Symposium} on {Digital} {Forensics} and {Security} ({ISDFS})},
	author = {Gupta, Khushi and Neyaz, Ashar and Shashidhar, Narasimha and Varol, Cihan},
	month = jun,
	year = {2022},
	keywords = {research/image-purpose, research/image-purpose/education},
	pages = {1--6}
}


@inproceedings{xuDesigningSharedDigital2022,
	title = {Towards {Designing} {Shared} {Digital} {Forensics} {Instructional} {Materials}},
	url = {https://ieeexplore.ieee.org/document/9842462},
	doi = {10.1109/COMPSAC54236.2022.00025},
	abstract = {This paper presents a systematic approach to designing a series of digital forensics instructional materials to address the severe shortage of active learning materials in the digital forensics community. The materials include real-world scenario-based case studies, a set of hands-on problem-driven labs for each case study, and an integrated forensic investigation environment. In this paper, we first clarify some fundamental concepts related to digital forensics, such as digital forensic artifacts, artifact generators, and evidence. We then re-categorize knowledge units of digital forensics based on the artifact generators for measuring the coverage of learning outcomes and topics. Finally, we utilize a real-world cybercrime scenario to demonstrate how knowledge units, digital forensics topics, concepts, artifacts, and investigation tools can be infused into each lab through active learning. The repository of the instructional materials is publicly available on GitHub. It has gained nearly 600 stars and 22k views within several months.},
	urldate = {2023-11-27},
	booktitle = {2022 {IEEE} 46th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Xu, Weifeng and Deng, Lin and Xu, Dianxiang},
	month = jun,
	year = {2022},
	keywords = {research/image-purpose, research/image-purpose/education},
	pages = {117--122}
}


@incollection{mochEvaluatingForensicImage2012,
	address = {Berlin, Heidelberg},
	title = {Evaluating the {Forensic} {Image} {Generator} {Generator}},
	volume = {88},
	isbn = {978-3-642-35514-1 978-3-642-35515-8},
	url = {http://link.springer.com/10.1007/978-3-642-35515-8_20},
	urldate = {2023-11-26},
	booktitle = {Digital {Forensics} and {Cyber} {Crime}},
	publisher = {Springer Berlin Heidelberg},
	author = {Moch, Christian and Freiling, Felix C.},
	editor = {Gladyshev, Pavel and Rogers, Marcus K.},
	year = {2012},
	doi = {10.1007/978-3-642-35515-8_20},
	keywords = {research/synthesizer-details},
	pages = {238--252}
}


@article{garfinkelForensicCorporaChallenge2007,
	title = {Forensic {Corpora}: {A} {Challenge} for {Forensic} {Research}},
	volume = {2007},
	shorttitle = {Forensic {Corpora}},
	abstract = {Research in the field of computer forensics is hobbled by the lack of realistic data. Academics are not developing automated techniques and tools because they lack the raw data necessary to develop and validate algorithms. Investigators that have access to real data operate under legal and practical restraints that prevent the data from being used in research. To make progress, we must "prime the pump" by collecting or creating forensic corpora that can be used by researchers. We must also pursue targeted technical developments in forensic file formats, knowledge representation, inference techniques, and the presentation of forensic results.},
	journal = {Electronic Evidence Information Center},
	author = {Garfinkel, Simson},
	month = jan,
	year = {2007},
	keywords = {research/image-purpose, research/image-gaps}
}


@article{russellForensicImageDescription2012,
	title = {A {Forensic} {Image} {Description} {Language} for {Generating} {Test} {Images}},
	abstract = {Digital Forensics is a fast developing job market, as well as being topical and interesting, and as such is an area in which University students are keen to develop and study. At Edinburgh Napier University this topic has been taught with flexible and distance learning students in mind, and to promote accessibility the practical exercises have been formed around the use of cloud-based technologies. This approach has highlighted a key issue, in that cost-effective cloud-based resources struggle to provide adequate CPU and IO capabilities to drive large simultaneous student numbers when performing forensic exercises on disk images created using physical disk acquisition techniques obtained from real systems. This paper considers the issue, and proposes a simplistic and easily reconfigurable image creation technique specifically designed to support digital forensic practical sessions.},
	language = {en},
	author = {Russell, Dr Gordon and Macfarlane, Rich and Ludwiniak, Robert},
	year = {2012},
	keywords = {research/synthesizer-details}
}


@article{bruecknerAutomatedComputerForensics2008,
	series = {The {Proceedings} of the {Eighth} {Annual} {DFRWS} {Conference}},
	title = {Automated computer forensics training in a virtualized environment},
	volume = {5},
	issn = {1742-2876},
	url = {https://www.sciencedirect.com/science/article/pii/S1742287608000406},
	doi = {10.1016/j.diin.2008.05.009},
	abstract = {The CYber DEfenSe Trainer (CYDEST) is a virtualized training platform for network defense and computer forensics. It uses virtual machines to provide tactical level exercises for personnel such as network administrators, first responders, and digital forensics investigators. CYDEST incorporates a number of features to reduce instructor workload and to improve training realism, including: (1) automated assessment of trainee performance, (2) automated attacks that respond dynamically to the student's actions, (3) a full fidelity training environment, (4) an unrestricted user interface incorporating real tools, and (5) continuous, remote accessibility via the Web.},
	urldate = {2023-08-31},
	journal = {Digital Investigation},
	author = {Brueckner, Stephen and Guaspari, David and Adelstein, Frank and Weeks, Joseph},
	month = sep,
	year = {2008},
	keywords = {research/synthesizer-details, Automated assessment, Automated evaluation, Computer training, Digital forensic training, Virtualized training},
	pages = {S105--S111}
}


@article{garfinkelBringingScienceDigital2009,
	title = {Bringing science to digital forensics with standardized forensic corpora},
	volume = {6},
	issn = {17422876},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287609000346},
	doi = {10.1016/j.diin.2009.06.016},
	language = {en},
	urldate = {2023-11-26},
	journal = {Digital Investigation},
	author = {Garfinkel, Simson and Farrell, Paul and Roussev, Vassil and Dinolt, George},
	month = sep,
	year = {2009},
	keywords = {research/image-purpose, research/public-datasets},
	pages = {S2--S11}
}


@article{gobelForTraceHolisticForensic2022,
	series = {Selected {Papers} of the {Ninth} {Annual} {DFRWS} {Europe} {Conference}},
	title = {{ForTrace} - {A} holistic forensic data set synthesis framework},
	volume = {40},
	issn = {2666-2817},
	url = {https://www.sciencedirect.com/science/article/pii/S2666281722000130},
	doi = {10.1016/j.fsidi.2022.301344},
	abstract = {Digital forensic experts are confronted with a wide variety of investigation objectives, e.g., to deal with an infected IT system. The same holds for digital forensic tools. Mostly different sources of digital traces have to be inspected including persistent storage devices (e.g., SSDs, SD cards, USB drives), volatile main memory snapshots, and network captures, respectively. In order to train experts and tools and keep their knowledge and capabilities up-to-date, a capacious amount of realistic, timely training data is necessary. However, due to different reasons like privacy, secrecy, or intellectual property rights there is a large gap in digital forensic training data. In recent years different synthesis frameworks to generate realistic digital forensic data sets have been proposed. However, none of these frameworks provides a holistic approach to generate realistic digital forensic relevant traces of different sources. In this paper we introduce ForTrace, a holistic framework for the simultaneous generation of persistent, volatile and network traces. Our approach is based on the data synthesis framework hystck. We explain our extension of hystck by defining properties of a holistic data set synthesis framework and by discussing different forensically relevant scenarios and their implementation in ForTrace. We then successfully evaluate ForTrace with respect to diverse realistic and complex scenarios. ForTrace is open source and may be adapted or extended with respect to individual needs.},
	urldate = {2023-08-31},
	journal = {Forensic Science International: Digital Investigation},
	author = {Göbel, Thomas and Maltan, Stephan and Türr, Jan and Baier, Harald and Mann, Florian},
	month = apr,
	year = {2022},
	keywords = {Data synthesis, Digital forensic corpora, research/synthesizer-details, Forensic data set, Forensic education, Forensic image generation, Forensic tool testing, User simulation},
	pages = {301344}
}


@incollection{gobelNovelApproachGenerating2020,
	address = {Cham},
	title = {A {Novel} {Approach} for {Generating} {Synthetic} {Datasets} for {Digital} {Forensics}},
	volume = {589},
	isbn = {978-3-030-56222-9 978-3-030-56223-6},
	url = {http://link.springer.com/10.1007/978-3-030-56223-6_5},
	language = {en},
	urldate = {2023-09-17},
	booktitle = {Advances in {Digital} {Forensics} {XVI}},
	publisher = {Springer International Publishing},
	author = {Göbel, Thomas and Schäfer, Thomas and Hachenberger, Julien and Türr, Jan and Baier, Harald},
	editor = {Peterson, Gilbert and Shenoi, Sujeet},
	year = {2020},
	doi = {10.1007/978-3-030-56223-6_5},
	keywords = {research/synthesizer-details},
	pages = {73--93}
}


@article{woodsCreatingRealisticCorpora2011,
	title = {Creating {Realistic} {Corpora} for {Security} and {Forensic} {Education}},
	abstract = {We present work on the design, implementation, distribution, and use of realistic forensic datasets to support digital forensics and security education. We describe in particular the "M57-Patents" scenario, a multi-modal corpus consisting of hard drive images, RAM images, network captures, and images from other devices typically found in forensics investigations such as USB drives and cellphones. Corpus creation has been performed as part of a scripted scenario; subsequently it is less "noisy" than real-world data but retains the complexity necessary to support a wide variety of forensic education activities. Realistic forensic corpora allow direct comparison of approaches and tools across classrooms and institutions, reduce the time required to prepare useful educational materials, and eliminate concerns of exposing students to privacy-sensitive or illegal digital materials. The "M57-Patents" corpus can be freely redistributed without rights-restricted materials, and is available with disk images packaged in both open (Advanced Forensic Format) and commercial (EnCase) formats.},
	journal = {Proceedings of the ADFSL Conference on Digital Forensics Security and Law},
	author = {Woods, Kam and Lee, Christopher and Garfinkel, Simson and Dittrich, David and Russell, Adam and Kearton, Kris},
	month = jan,
	year = {2011},
	keywords = {research/image-purpose}
}


@article{parkTREDEVMPOPCultivating2018,
	title = {{TREDE} and {VMPOP}: {Cultivating} multi-purpose datasets for digital forensics – {A} {Windows} registry corpus as an example},
	volume = {26},
	issn = {17422876},
	shorttitle = {{TREDE} and {VMPOP}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287617303614},
	doi = {10.1016/j.diin.2018.04.025},
	language = {en},
	urldate = {2023-09-17},
	journal = {Digital Investigation},
	author = {Park, Jungheum},
	month = sep,
	year = {2018},
	keywords = {research/synthesizer-details},
	pages = {3--18}
}


@article{scanlonEviPlantEfficientDigital2017,
	series = {{DFRWS} 2017 {Europe}},
	title = {{EviPlant}: {An} efficient digital forensic challenge creation, manipulation and distribution solution},
	volume = {20},
	issn = {1742-2876},
	shorttitle = {{EviPlant}},
	url = {https://www.sciencedirect.com/science/article/pii/S1742287617300397},
	doi = {10.1016/j.diin.2017.01.010},
	abstract = {Education and training in digital forensics requires a variety of suitable challenge corpora containing realistic features including regular wear-and-tear, background noise, and the actual digital traces to be discovered during investigation. Typically, the creation of these challenges requires overly arduous effort on the part of the educator to ensure their viability. Once created, the challenge image needs to be stored and distributed to a class for practical training. This storage and distribution step requires significant time and resources and may not even be possible in an online/distance learning scenario due to the data sizes involved. As part of this paper, we introduce a more capable methodology and system as an alternative to current approaches. EviPlant is a system designed for the efficient creation, manipulation, storage and distribution of challenges for digital forensics education and training. The system relies on the initial distribution of base disk images, i.e., images containing solely base operating systems. In order to create challenges for students, educators can boot the base system, emulate the desired activity and perform a “diffing” of resultant image and the base image. This diffing process extracts the modified artefacts and associated metadata and stores them in an “evidence package”. Evidence packages can be created for different personae, different wear-and-tear, different emulated crimes, etc., and multiple evidence packages can be distributed to students and integrated into the base images. A number of additional applications in digital forensic challenge creation for tool testing and validation, proficiency testing, and malware analysis are also discussed as a result of using EviPlant.},
	urldate = {2023-08-31},
	journal = {Digital Investigation},
	author = {Scanlon, Mark and Du, Xiaoyu and Lillis, David},
	month = mar,
	year = {2017},
	keywords = {research/synthesizer-details, Digital forensic challenges, Digital forensics education, Evidence injection, Forensic corpora, Tool testing and validation},
	pages = {S29--S36}
}


@inproceedings{mochForensicImageGenerator2009,
	address = {Stuttgart, Germany},
	title = {The {Forensic} {Image} {Generator} {Generator} ({Forensig2})},
	isbn = {978-0-7695-3807-5},
	url = {http://ieeexplore.ieee.org/document/5277859/},
	doi = {10.1109/IMF.2009.8},
	urldate = {2023-09-17},
	booktitle = {2009 {Fifth} {International} {Conference} on {IT} {Security} {Incident} {Management} and {IT} {Forensics}},
	publisher = {IEEE},
	author = {Moch, Christian and Freiling, Felix C.},
	year = {2009},
	keywords = {research/synthesizer-details},
	pages = {78--93}
}


@incollection{vistiAutomaticCreationComputer2015,
	address = {Cham},
	title = {Automatic {Creation} of {Computer} {Forensic} {Test} {Images}},
	volume = {8915},
	isbn = {978-3-319-20124-5 978-3-319-20125-2},
	url = {https://link.springer.com/10.1007/978-3-319-20125-2_14},
	language = {en},
	urldate = {2023-09-17},
	booktitle = {Computational {Forensics}},
	publisher = {Springer International Publishing},
	author = {Visti, Hannu and Tohill, Sean and Douglas, Paul},
	editor = {Garain, Utpal and Shafait, Faisal},
	year = {2015},
	doi = {10.1007/978-3-319-20125-2_14},
	keywords = {research/synthesizer-details},
	pages = {163--175}
}


@article{micheletAutomationDigitalForensics2023,
	title = {Automation for digital forensics: {Towards} a definition for the community},
	volume = {349},
	issn = {0379-0738},
	shorttitle = {Automation for digital forensics},
	url = {https://www.sciencedirect.com/science/article/pii/S0379073823002190},
	doi = {10.1016/j.forsciint.2023.111769},
	abstract = {Automation is crucial for managing the increasing volume of digital evidence. However, the absence of a clear foundation comprising a definition, classification, and common terminology has led to a fragmented landscape where diverse interpretations of automation exist. This resembles the wild west: some consider keyword searches or file carving as automation while others do not. We, therefore, reviewed automation literature (in the domain of digital forensics and other domains), performed three practitioner interviews, and discussed the topic with domain experts from academia. On this basis, we propose a definition and then showcase several considerations concerning automation for digital forensics, e.g., what we classify as no/basic automation or full automation (autonomous). We conclude that it requires these foundational discussions to promote and progress the discipline through a common understanding.},
	urldate = {2024-12-03},
	journal = {Forensic Science International},
	author = {Michelet, Gaëtan and Breitinger, Frank and Horsman, Graeme},
	month = aug,
	year = {2023},
	keywords = {Automation, Definition, Digital Forensic investigation, Investigative task, Practitioner interviews},
	pages = {111769}
}


@article{caseyAdvancingCoordinatedCyberinvestigations2017,
	title = {Advancing coordinated cyber-investigations and tool interoperability using a community developed specification language},
	volume = {22},
	issn = {1742-2876},
	url = {https://www.sciencedirect.com/science/article/pii/S1742287617301007},
	doi = {10.1016/j.diin.2017.08.002},
	abstract = {Any investigation can have a digital dimension, often involving information from multiple data sources, organizations and jurisdictions. Existing approaches to representing and exchanging cyber-investigation information are inadequate, particularly when combining data sources from numerous organizations or dealing with large amounts of data from various tools. To conduct investigations effectively, there is a pressing need to harmonize how this information is represented and exchanged. This paper addresses this need for information exchange and tool interoperability with an open community-developed specification language called Cyber-investigation Analysis Standard Expression (CASE). To further promote a common structure, CASE aligns with and extends the Unified Cyber Ontology (UCO) construct, which provides a format for representing information in all cyber domains. This ontology abstracts objects and concepts that are not CASE-specific, so that they can be used across other cyber disciplines that may extend UCO. This work is a rational evolution of the Digital Forensic Analysis eXpression (DFAX) for representing digital forensic information and provenance. CASE is more flexible than DFAX and can be utilized in any context, including criminal, corporate and intelligence. CASE also builds on the Hansken data model developed and implemented by the Netherlands Forensic Institute (NFI). CASE enables the fusion of information from different organizations, data sources, and forensic tools to foster more comprehensive and cohesive analysis. This paper includes illustrative examples of how CASE can be implemented and used to capture information in a structured form to advance sharing, interoperability and analysis in cyber-investigations. In addition to capturing technical details and relationships between objects, CASE provides structure for representing and sharing details about how cyber-information was handled, transferred, processed, analyzed, and interpreted. CASE also supports data marking for sharing information at different levels of trust and classification, and for protecting sensitive and private information. Furthermore, CASE supports the sharing of knowledge related to cyber-investigations, including distinctive patterns of activity/behavior that are common across cases. This paper features a proof-of-concept Application Program Interface (API) to facilitate implementation of CASE in tools. Community members are encouraged to participate in the development and implementation of CASE and UCO.},
	urldate = {2024-12-03},
	journal = {Digital Investigation},
	author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan and Snyder, Jonathan and Nelson, Alex and van Beek, Harm},
	month = sep,
	year = {2017},
	keywords = {Digital forensics, CybOX, DFAX, DFXML, Standard representation, Cyber-investigation, Digital evidence exchange, Evidence provenance, Information sharing, Specification language, Unified cyber ontology},
	pages = {14--45}
}


@misc{colvinPydantic2024,
	title = {Pydantic},
	copyright = {MIT},
	url = {https://github.com/pydantic/pydantic},
	abstract = {Data validation using Python type hints},
	urldate = {2024-12-07},
	author = {Colvin, Samuel and Jolibois, Eric and Ramezani, Hasan and Garcia Badaracco, Adrian and Dorsey, Terrence and Montague, David and Matveenko, Serge and Trylesinski, Marcelo and Runkle, Sydney and Hewitt, David and Hall, Alex and Plot, Victorien},
	year = {2025},
}


@misc{CaseworkCASEMappingPython,
	title = {casework/{CASE}-{Mapping}-{Python}},
	url = {https://github.com/casework/CASE-Mapping-Python},
	urldate = {2024-12-14},
	author = {Nelson, Alex and Turchi, Fabrizio and Chason, Keith and Protopapas, Panos},
	month = apr,
	year = {2025}
}


@article{demmelDataSynthesisGoing2024,
	title = {Data {Synthesis} {Is} {Going} {Mobile}—{On} {Community}-{Driven} {Dataset} {Generation} for {Android} {Devices}},
	volume = {5},
	url = {https://dl.acm.org/doi/10.1145/3688807},
	doi = {10.1145/3688807},
	abstract = {Personal electronic devices such as smartphones and smartwatches have become indispensable daily companions, collecting a multitude of personal and sensitive data. As a result, they are of paramount importance in digital forensic examinations. However, there is a lack of publicly available and ready-to-use digital forensic datasets, especially in mobile forensics. This work presents a concept and an open-source proof-of-concept implementation, which simplifies and automates the creation of mobile forensic datasets within the scope of the Android operating system. In contrast to previous approaches, which populate the most common databases of an Android device, our concept is based on community-driven playbooks and makes use of interaction with the actual smartphone GUI. Hence, we are able to generate coherent and realistic traces as they occur in real-world human usage. Our proof-of-concept implementation is based on the standard Android emulation environment and borrows tools from the user interface testing community. Our evaluation shows that our approach actually generates realistic Android datasets. For instance, we can generate traces that cannot be simulated by gestures (e.g., changing the GPS position or triggering incoming phone calls). Recording the actual data synthesis process allows users to either create and share their own playbooks (i.e., the exact instructions for the data synthesis process rather than having to share the full image) or reproduce Android images with different scenarios using playbooks previously created and shared by the community.},
	number = {3},
	urldate = {2024-12-29},
	journal = {Digital Threats},
	author = {Demmel, Markus and Göbel, Thomas and Gonçalves, Patrik and Baier, Harald},
	month = oct,
	year = {2024},
	pages = {30:1--30:19}
}


@article{duTraceGenUserActivity2021,
	title = {{TraceGen}: {User} activity emulation for digital forensic test image generation},
	volume = {38},
	issn = {2666-2817},
	shorttitle = {{TraceGen}},
	url = {https://www.sciencedirect.com/science/article/pii/S2666281721000317},
	doi = {10.1016/j.fsidi.2021.301133},
	abstract = {Digital forensic test images are commonly used across a variety of digital forensic use cases including education and training, tool testing and validation, proficiency testing, malware analysis, and research and development. Using real digital evidence for these purposes is often not viable or permissible, especially when factoring in the ethical and in some cases legal considerations of working with individuals' personal data. Furthermore, when using real data it is not usually known what actions were performed when, i.e., what was the ‘ground truth’. The creation of synthetic digital forensic test images typically involves an arduous, time-consuming process of manually performing a list of actions, or following a ‘story’ to generate artefacts in a subsequently imaged disk. Besides the manual effort and time needed in executing the relevant actions in the scenario, there is often little room to build a realistic volume of non-pertinent wear-and-tear or ‘background noise’ on the suspect device, meaning the resulting disk images are inherently limited and to a certain extent simplistic. This work presents the TraceGen framework, an automated system focused on the emulation of user actions to create realistic and comprehensive artefacts in an auditable and reproducible manner. The framework consists of a series of actions contained within scripts that are executed both externally and internally to a target virtual machine. These actions use existing automation APIs to emulate a real user's behaviour on a Windows system to generate realistic and comprehensive artefacts. These actions can be quickly scripted together to form complex stories or to emulate wear-and-tear on the test image. In addition to the development of the framework, evaluation is also performed in terms of the ability to produce background artefacts at scale, and also the realism of the artefacts compared with their human-generated counterparts.},
	urldate = {2024-12-30},
	journal = {Forensic Science International: Digital Investigation},
	author = {Du, Xiaoyu and Hargreaves, Christopher and Sheppard, John and Scanlon, Mark},
	month = oct,
	year = {2021},
	keywords = {Forensic education, Tool testing and validation, Evidence planting, Forensic disk image creation, User emulation},
	pages = {301133}
}


@misc{TomerfilibaorgRpyc2025,
	title = {tomerfiliba-org/rpyc},
	url = {https://github.com/tomerfiliba-org/rpyc},
	abstract = {RPyC (Remote Python Call) - A transparent and symmetric RPC library for python},
	urldate = {2025-02-05},
	publisher = {tomerfiliba-org},
	author = {Filiba, Tomer},
	month = feb,
	year = {2025},
}


@misc{MicrosoftPlaywrightpython2025,
	title = {microsoft/playwright-python},
	copyright = {Apache-2.0},
	url = {https://github.com/microsoft/playwright-python},
	abstract = {Python version of the Playwright testing and automation library.},
	urldate = {2025-02-05},
	publisher = {Microsoft},
	author = {{Microsoft}},
	month = feb,
	year = {2025},
	keywords = {chromium, firefox, playwright, webkit},
}


@misc{TheoryOperationRPyC,
	title = {Theory of {Operation} — {RPyC}},
	url = {https://rpyc.readthedocs.io/en/latest/docs/theory.html#theory},
	urldate = {2025-02-06},
	author = {Fibila, Tomer},
	month = mar,
	year = {2025}
}


@misc{maxfraggMaxfraggForGeOSI2023,
	title = {maxfragg/{ForGeOSI}},
	copyright = {BSD-2-Clause},
	url = {https://github.com/maxfragg/ForGeOSI},
	abstract = {Forensic Generator that automates disk image generation with virtualbox in python. Uses pyvbox as basis.},
	urldate = {2025-02-06},
	author = {Fragg, Max},
	year = {2014},
}


@misc{HashicorpVagrant2025,
	title = {hashicorp/vagrant},
	url = {https://github.com/hashicorp/vagrant},
	abstract = {Vagrant is a tool for building and distributing development environments.},
	urldate = {2025-02-23},
	publisher = {HashiCorp},
	author = {{HashiCorp}},
	month = feb,
	year = {2025},
	keywords = {automation, ruby, vagrant, virtualization},
}


@misc{hashicorpHashiCorpCloudPlatform,
	title = {{HashiCorp} {Cloud} {Platform}},
	url = {https://portal.cloud.hashicorp.com/vagrant/discover},
	urldate = {2025-02-23},
	journal = {Vagrant Public Registry},
	author = {{HashiCorp}},
	month = feb,
	year = {2025}
}


@misc{SleuthkitSleuthkit2025,
	title = {sleuthkit/sleuthkit},
	url = {https://github.com/sleuthkit/sleuthkit},
	abstract = {The Sleuth Kit® (TSK) is a library and collection of command line digital forensics tools that allow you to investigate volume and file system data. The library can be incorporated into larger digital forensics tools and the command line tools can be directly used to find evidence.},
	urldate = {2025-02-26},
	publisher = {The Sleuth Kit},
	author = {Carrier, Brian},
	month = feb,
	year = {2025},
	keywords = {forensics, incident-response, ntfs, sleuthkit, tct},
}


@misc{Log2timelineDfvfs2025,
	title = {log2timeline/dfvfs},
	copyright = {Apache-2.0},
	url = {https://github.com/log2timeline/dfvfs},
	abstract = {Digital Forensics Virtual File System (dfVFS)},
	urldate = {2025-02-26},
	publisher = {log2timeline},
	author = {{The dfVFS authors}},
	year = {2024},
}


@inproceedings{ricanekMORPHLongitudinalImage2006,
	title = {{MORPH}: a longitudinal image database of normal adult age-progression},
	shorttitle = {{MORPH}},
	url = {https://ieeexplore.ieee.org/document/1613043},
	doi = {10.1109/FGR.2006.78},
	abstract = {This paper details MORPH a longitudinal face database developed for researchers investigating all facets of adult age-progression, e.g. face modeling, photo-realistic animation, face recognition, etc. This database contributes to several active research areas, most notably face recognition, by providing: the largest set of publicly available longitudinal images; longitudinal spans from a few months to over twenty years; and, the inclusion of key physical parameters that affect aging appearance. The direct contribution of this data corpus for face recognition is highlighted in the evaluation of a standard face recognition algorithm, which illustrates the impact that age-progression, has on recognition rates. Assessment of the efficacy of this algorithm is evaluated against the variables of gender and racial origin. This work further concludes that the problem of age-progression on face recognition (FR) is not unique to the algorithm used in this work.},
	urldate = {2025-03-05},
	booktitle = {7th {International} {Conference} on {Automatic} {Face} and {Gesture} {Recognition} ({FGR06})},
	author = {Ricanek, K. and Tesafaye, T.},
	month = apr,
	year = {2006},
	keywords = {Computer science, Aging, Biometrics, Cranial, Face recognition, Facial animation, Humans, Image databases, Morphology, Skin},
	pages = {341--345}
}


@misc{SeleniumHQSelenium2025,
	title = {{SeleniumHQ}/selenium},
	copyright = {Apache-2.0},
	url = {https://github.com/SeleniumHQ/selenium},
	abstract = {A browser automation framework and ecosystem.},
	urldate = {2025-03-05},
	publisher = {Selenium},
	author = {{Software Freedom Conservancy}},
	month = mar,
	year = {2025},
	keywords = {python, ruby, dotnet, java, javascript, rust, selenium, webdriver},
}


@misc{sweigartAsweigartPyautogui2025,
	title = {asweigart/pyautogui},
	copyright = {BSD-3-Clause},
	url = {https://github.com/asweigart/pyautogui},
	abstract = {A cross-platform GUI automation Python module for human beings. Used to programmatically control the mouse \& keyboard.},
	urldate = {2025-03-05},
	author = {Sweigart, Al},
	month = mar,
	year = {2025},
}


@misc{jjk422Jjk422ForGen2019,
	title = {Jjk422/{ForGen}},
	copyright = {Apache-2.0},
	url = {https://github.com/Jjk422/ForGen},
	abstract = {Forensic generator},
	urldate = {2025-03-08},
	author = {Keighley, Jason},
	year = {2017},
}


@misc{macfarlanePandoc2025,
	title = {Pandoc},
	url = {https://github.com/jgm/pandoc},
	abstract = {Universal markup converter},
	urldate = {2025-03-15},
	author = {MacFarlane, John and Krewinkel, Albert and Rosenthal, Jesse},
	month = mar,
	year = {2025},
}


@misc{waglerWandmalfarbePandoclatextemplate2025,
	title = {Wandmalfarbe/pandoc-latex-template},
	copyright = {BSD-3-Clause},
	url = {https://github.com/Wandmalfarbe/pandoc-latex-template},
	abstract = {A pandoc LaTeX template to convert markdown files to PDF or LaTeX.},
	urldate = {2025-03-15},
	author = {Wagler, Pascal},
	month = mar,
	year = {2025},
	keywords = {eisvogel, koma-script, latex, latex-template, markdown, markdown-to-pdf, pandoc, pandoc-template, pandoc-templates, pdf, pdf-generation, tex},
}


@misc{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
	title = {{DeepSeek}-{R1}: {Incentivizing} {Reasoning} {Capability} in {LLMs} via {Reinforcement} {Learning}},
	shorttitle = {{DeepSeek}-{R1}},
	url = {http://arxiv.org/abs/2501.12948},
	doi = {10.48550/arXiv.2501.12948},
	abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
	urldate = {2025-03-24},
	publisher = {arXiv},
	author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
	month = jan,
	year = {2025},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning}
}


@misc{podellSDXLImprovingLatent2023,
	title = {{SDXL}: {Improving} {Latent} {Diffusion} {Models} for {High}-{Resolution} {Image} {Synthesis}},
	shorttitle = {{SDXL}},
	url = {http://arxiv.org/abs/2307.01952},
	doi = {10.48550/arXiv.2307.01952},
	abstract = {We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. In the spirit of promoting open research and fostering transparency in large model training and evaluation, we provide access to code and model weights at https://github.com/Stability-AI/generative-models},
	urldate = {2025-03-24},
	publisher = {arXiv},
	author = {Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and Müller, Jonas and Penna, Joe and Rombach, Robin},
	month = jul,
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition}
}


@misc{wittPoorBillionaireWindowsPrefetchParser2021,
	title = {{PoorBillionaire}/{Windows}-{Prefetch}-{Parser}},
	url = {https://github.com/PoorBillionaire/Windows-Prefetch-Parser},
	abstract = {Parse Windows Prefetch files: Supports XP - Windows 10 Prefetch files},
	urldate = {2025-03-28},
	author = {Witt, Adam},
	year = {2021},
}


@inproceedings{wiedemeierPYLINGUALPerfectDecompilation2024,
	title = {{PYLINGUAL}: {Toward} {Perfect} {Decompilation} of {Evolving} {High}-{Level} {Languages}},
	isbn = {979-8-3315-2236-0},
	shorttitle = {{PYLINGUAL}},
	url = {https://www.computer.org/csdl/proceedings-article/sp/2025/223600a052/21B7QZB86cg},
	doi = {10.1109/SP61157.2025.00052},
	abstract = {Python is one of the most popular programming languages among both industry developers and malware authors. Despite demand for Python decompilers, community efforts to maintain automatic Python decompilation tools have been hindered by Python's aggressive language improvements and unstable bytecode specification. Every year, language features are added, code generation undergoes significant changes, and opcodes are added, deleted, and modified. Our research aims to integrate NLP techniques with classical PL theory to create a Python decompiler that accomodates evolving language features and changes to the bytecode specification with minimal human maintenance effort. PyLingual plugs in data-driven NLP components to a version-agnostic core to automatically absorb superficial bytecode and compiler changes, while leveraging programmatic components for abstract control flow reconstruction. To establish trust in the decompilation results, we introduce a stringent correctness measure based on "perfect decompilation", a statically verifiable refinement of semantic equivalence. We demonstrate the efficacy of our approach with extensive real-world datasets of benign and malicious Python source code and their corresponding compiled PYC binaries. Our research makes three major contributions: (1) we present PyLingual, a scalable, data-driven decompilation framework with state-of-the-art support for Python versions 3.6 through 3.12, improving the perfect decompilation rate by an average of 45\% over the best results of existing decompiler across four datasets; (2) we provide a Python decompiler evaluation framework that verifies decompilation results with perfect decompilation; and (3) we launch PyLingual as a public online service.},
	language = {English},
	urldate = {2025-05-26},
	booktitle = {2025 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	publisher = {IEEE Computer Society},
	author = {Wiedemeier, Josh and Tarbet, Elliot and Zheng, Max and Ko, Sangsoo and Ouyang, Jessica and Cha, Sang Kil and Jee, Kangkook},
	month = nov,
	year = {2024},
	pages = {2976--2994},
}


@misc{extremecodersExtremecodersrePyinstxtractor2025,
	title = {extremecoders-re/pyinstxtractor},
	copyright = {GPL-3.0},
	url = {https://github.com/extremecoders-re/pyinstxtractor},
	abstract = {PyInstaller Extractor},
	urldate = {2025-05-26},
	author = {{ExtremeCoders} and Vincent, Maxime and {2press}},
	month = may,
	year = {2025},
	keywords = {python, pyinstaller, decompile, pyc, pyc-files, pyinstaller-extractor, python-decompiler, reverse-engineering},
}


@inproceedings{buchananCloudbasedDigitalForensics2010,
	title = {Cloud-based digital forensics evaluation test ({D}-{FET}) platform.},
	url = {http://researchrepository.napier.ac.uk/id/eprint/4429},
	abstract = {This paper outlines the specification of the Cloud-based DFET platform which is used to evaluate the performance of digital forensics tools, which aim to detect the presence of trails of evidence, such as for the presence of illicit images and determination of user accounts from a host. Along with measuring key quality metrics, such as truepositives, and false-positives, it also measures operational performance, such as for the speed of success, CPU utilization and memory usage. This is used to determine the basic footprint of the package-under-test. The paper presents a proof-of-concept of the system using the VMware vSphere Hypervisor (ESXi) within the vCenter Cloud management infrastructure, which provides a cluster environment, and supports the creation and instantiation of a well-defined virtual test operation system. The infrastructure has been used within a teaching environment for two semesters, and has been shown to cope well in terms of performance and administration. Two key evaluation points related to whether a cloudbased infrastructure will provide improvement on existing stand-alone and workstation-based virtualisation are related to the improvement in energy consumption and in the CPU utilization footprint for each virtual machine. Thus the results show some metrics related to the energy and CPU consumptions of the created digital forensics instances, which can be used to justify the improvements in energy consumption, as opposed to stand-alone instances, and in the scalability of the infrastructure.},
	publisher = {University of Strathclyde, Glasgow},
	author = {Buchanan, William J and Macfarlane, Richard and Flandrin, Flavien and Graves, Jamie and Fan, Lu and Ekonomou, Elias and Bose, Niladri and Ludwiniak, Robert},
	year = {2010},
	keywords = {digital forensics, Cloud computing, D-Fet platform, evidence trails, VMware vSphere Hypervisor (ESXi)},
}

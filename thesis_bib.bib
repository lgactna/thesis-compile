@inproceedings{abbottAutomatedRecognitionEvent2006,
  title = {Automated Recognition of Event Scenarios for Digital Forensics},
  booktitle = {Proceedings of the 2006 {{ACM}} Symposium on {{Applied}} Computing},
  author = {Abbott, Jonathon and Bell, Jim and Clark, Andrew and De Vel, Olivier and Mohay, George},
  date = {2006-04-23},
  series = {{{SAC}} '06},
  pages = {293--300},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1141277.1141346},
  url = {https://doi.org/10.1145/1141277.1141346},
  urldate = {2023-08-30},
  abstract = {The authors have previously developed the ECF (Event Correlation for Forensics) framework for scenario matching in the forensic investigation of activity manifested in digital transactional logs. ECF incorporated a suite of log parsers to reduce event records from heterogeneous logs to a canonical form for lodging in an SQL database. This paper presents work since then, the Auto-ECF system, which represents significant advances on ECF. The paper reports on the development and implementation of the new event abstraction and scenario specification methodology and on the development of the Auto-ECF system which builds on that to achieve the automated recognition of event scenarios. The paper also reports on the evaluation of Auto-ECF using three scenarios including one from the well known DARPA test data.},
  isbn = {978-1-59593-108-5},
  keywords = {computer forensics,event correlation,events,heterogeneous event logs,logs,research/image-sources,research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\ZJ3ZZDJH\abbottAutomatedRecognitionEvent2006.pdf}
}

@inproceedings{adelsteinAutomaticallyCreatingRealistic2005,
  title = {Automatically {{Creating Realistic Targets}} for {{Digital Forensics Investigation}}},
  author = {Adelstein, F. and Gao, Yun and Richard, G.},
  date = {2005},
  url = {https://www.semanticscholar.org/paper/Automatically-Creating-Realistic-Targets-for-Adelstein-Gao/750d289378fa28f7d78fa2959194fdf6756f55c6},
  urldate = {2023-11-28},
  abstract = {The need for computer forensics education continues to grow, as digital evidence is present in more crimes, whether the crimes directly involve computers or not. An essential component of training in computer forensics is hands-on, realistic laboratory assignments. Creating detailed, realistic lab assignments, however, is a difficult task. The “crime” must be played out on the machine, often in real-time, since timestamps present in numerous places in the system, such as files and logs, must be discovered and examined by students. Developing, running, and evaluating the labs can be labor intensive and instructors have limited time to spend on creating and grading laboratory experiments. We are developing FALCON (Framework for Laboratory Exercises Conducted Over Networks), an extensible framework that addresses the problem of creating, running, and evaluating detailed, realistic computer laboratory assignments in computer forensics. FALCON includes a component that enables instructors to set up scenarios on virtual target machines for the students to investigate. Existing tools for both “live” and “dead” machine investigations can be integrated into FALCON. In addition, FALCON logs all student activity for automated assessment of student performance. Currently, FALCON is a work in progress and some tasks remain manual. The goal is to automatically transform high-level descriptions of digital forensics scenarios into detailed investigative targets which contain activities derived from the scenarios, as well as historical activity (timestamps, logs, history, etc.). While the initial version of FALCON focuses on computer forensics, it will be extensible to other areas, such as incident response, as well as general computer security instruction.},
  eventtitle = {Digital {{Forensic Research Workshop}}},
  file = {C:\Users\Kisun\Zotero\storage\6URIIW8P\adelsteinAutomaticallyCreatingRealistic2005.pdf}
}

@inproceedings{andersonComparativeStudyTeaching2006,
  title = {A {{Comparative Study}} of {{Teaching Forensics}} at a {{University Degree Level}}.},
  author = {Anderson, Philip and Dornseif, Maximillian and Freiling, Felix and Holz, Thorsten and Irons, Alastair and Laing, Christopher and Mink, Martin},
  date = {2006-01-01},
  pages = {116--127},
  abstract = {Computer forensics is a relatively young University disci- pline which has developed strongly in the United States and the United Kingdom but is still in its infancy in continental Europe. The national programmes and courses offered therefore differ in many ways. We report on two recently established degree programmes from two European coun- tries: Great Britain and Germany. We present and compare the design of both programmes and conclude that they cover two complementary and orthogonal aspects of computer forensics education: (a) rigorous practical skills and (b) competence for fundamental research discoveries.},
  keywords = {research/image-purpose,research/image-purpose/education,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\99TULM3R\andersonComparativeStudyTeaching2006.pdf}
}

@software{AnsibleAnsible2025,
  title = {Ansible/Ansible},
  date = {2025-03-08T05:01:23Z},
  origdate = {2012-03-06T14:58:02Z},
  url = {https://github.com/ansible/ansible},
  urldate = {2025-03-08},
  abstract = {Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.},
  organization = {Ansible},
  keywords = {ansible,hacktoberfest,python}
}

@online{ansibleprojectcontributorsAnsiblePlaybooks,
  title = {Ansible Playbooks},
  author = {{Ansible project contributors}},
  url = {https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_intro.html},
  urldate = {2025-02-24},
  organization = {Ansible Community Documentation},
  file = {C:\Users\Kisun\Zotero\storage\ZJ9MYA4C\playbooks_intro.html}
}

@inproceedings{astekinExploratoryStudyHow2024,
  title = {An {{Exploratory Study}} on {{How Non-Determinism}} in {{Large Language Models Affects Log Parsing}}},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE}} 2nd {{International Workshop}} on {{Interpretability}}, {{Robustness}}, and {{Benchmarking}} in {{Neural Software Engineering}}},
  author = {Astekin, Merve and Hort, Max and Moonen, Leon},
  date = {2024-08-07},
  series = {{{InteNSE}} '24},
  pages = {13--18},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3643661.3643952},
  url = {https://dl.acm.org/doi/10.1145/3643661.3643952},
  urldate = {2025-02-10},
  abstract = {Most software systems used in production generate system logs that provide a rich source of information about the status and execution behavior of the system. These logs are commonly used to ensure the reliability and maintainability of software systems. The first step toward automated log analysis is generally log parsing, which aims to transform unstructured log messages into structured log templates and extract the corresponding parameters.Recently, Large Language Models (LLMs) such as ChatGPT have shown promising results on a wide range of software engineering tasks, including log parsing. However, the extent to which non-determinism influences log parsing using LLMs remains unclear. In particular, it is important to investigate whether LLMs behave consistently when faced with the same log message multiple times.In this study, we investigate the impact of non-determinism in state-of-the-art LLMs while performing log parsing. Specifically, we select six LLMs, including both paid proprietary and free-to-use models, and evaluate their non-determinism on 16 system logs obtained from a selection of mature open-source projects. The results of our study reveal varying degrees of non-determinism among models. Moreover, they show that there is no guarantee for deterministic results even with a temperature of zero.},
  isbn = {979-8-4007-0564-9},
  file = {C:\Users\Kisun\Zotero\storage\R9FQ3VQD\astekinExploratoryStudyHow2024.pdf}
}

@software{AstralshUv2025,
  title = {Astral-Sh/Uv},
  date = {2025-03-08T05:12:10Z},
  origdate = {2023-10-02T20:24:11Z},
  url = {https://github.com/astral-sh/uv},
  urldate = {2025-03-08},
  abstract = {An extremely fast Python package and project manager, written in Rust.},
  organization = {Astral},
  keywords = {packaging,python,resolver,uv}
}

@online{avrahamiOwnershipCreativityGenerative2021,
  title = {Ownership and {{Creativity}} in {{Generative Models}}},
  author = {Avrahami, Omri and Tamir, Bar},
  date = {2021-12-02},
  eprint = {2112.01516},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.01516},
  url = {http://arxiv.org/abs/2112.01516},
  urldate = {2023-12-04},
  abstract = {Machine learning generated content such as image artworks, textual poems and music become prominent in recent years. These tools attract much attention from the media, artists, researchers, and investors. Because these tools are data-driven, they are inherently different than the traditional creative tools which arises the question - who may own the content that is generated by these tools? In this paper we aim to address this question, we start by providing a background to this problem, raising several candidates that may own the content and arguments for each one of them. Then we propose a possible algorithmic solution in the vision-based model's regime. Finally, we discuss the broader implications of this problem.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8H7YFUDD\\avrahamiOwnershipCreativityGenerative2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\49FUZQG8\\2112.html}
}

@inproceedings{baggiliDataSourcesAdvancing2015,
  title = {Data Sources for Advancing Cyber Forensics: {{What}} the Social World Has to Offer},
  author = {Baggili, Ibrahim and Breitinger, Frank},
  date = {2015-03},
  series = {{{AAAI Spring Symposium}} - {{Technical Report}}},
  keywords = {research/image-gaps,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\4FUUX3TQ\baggiliDataSourcesAdvancing2015.pdf}
}

@article{bruecknerAutomatedComputerForensics2008,
  title = {Automated Computer Forensics Training in a Virtualized Environment},
  author = {Brueckner, Stephen and Guaspari, David and Adelstein, Frank and Weeks, Joseph},
  date = {2008-09-01},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  series = {The {{Proceedings}} of the {{Eighth Annual DFRWS Conference}}},
  volume = {5},
  pages = {S105-S111},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2008.05.009},
  url = {https://www.sciencedirect.com/science/article/pii/S1742287608000406},
  urldate = {2023-08-31},
  abstract = {The CYber DEfenSe Trainer (CYDEST) is a virtualized training platform for network defense and computer forensics. It uses virtual machines to provide tactical level exercises for personnel such as network administrators, first responders, and digital forensics investigators. CYDEST incorporates a number of features to reduce instructor workload and to improve training realism, including: (1) automated assessment of trainee performance, (2) automated attacks that respond dynamically to the student's actions, (3) a full fidelity training environment, (4) an unrestricted user interface incorporating real tools, and (5) continuous, remote accessibility via the Web.},
  keywords = {Automated assessment,Automated evaluation,Computer training,Digital forensic training,research/synthesizer-details,Virtualized training},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\9MVY78M9\\bruecknerAutomatedComputerForensics2008.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\6XP3APTW\\S1742287608000406.html}
}

@online{bureauoflaborstatisticsu.s.departmentoflaborInformationSecurityAnalysts2023,
  title = {Information {{Security Analysts}}},
  shorttitle = {Information {{Security Analysts}}},
  author = {{Bureau of Labor Statistics, U.S. Department of Labor}},
  date = {2023-09-06},
  url = {https://www.bls.gov/ooh/computer-and-information-technology/information-security-analysts.htm#tab-1},
  urldate = {2023-12-03},
  abstract = {Information security analysts plan and carry out security measures to protect an organization’s computer networks and systems.},
  langid = {english},
  organization = {Occupational Outlook Handbook},
  file = {C:\Users\Kisun\Zotero\storage\JTQDTKPQ\information-security-analysts.html}
}

@online{CaseworkCASEMappingPython,
  title = {Casework/{{CASE-Mapping-Python}}},
  url = {https://github.com/casework/CASE-Mapping-Python},
  urldate = {2024-12-14},
  file = {C:\Users\Kisun\Zotero\storage\Y97NLSGI\CASE-Mapping-Python.html}
}

@article{caseyAdvancingCoordinatedCyberinvestigations2017,
  title = {Advancing Coordinated Cyber-Investigations and Tool Interoperability Using a Community Developed Specification Language},
  author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan and Snyder, Jonathan and family=Beek, given=Harm, prefix=van, useprefix=true and Nelson, Alex},
  date = {2017-09-01},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {22},
  pages = {14--45},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2017.08.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1742287617301007},
  urldate = {2024-12-03},
  abstract = {Any investigation can have a digital dimension, often involving information from multiple data sources, organizations and jurisdictions. Existing approaches to representing and exchanging cyber-investigation information are inadequate, particularly when combining data sources from numerous organizations or dealing with large amounts of data from various tools. To conduct investigations effectively, there is a pressing need to harmonize how this information is represented and exchanged. This paper addresses this need for information exchange and tool interoperability with an open community-developed specification language called Cyber-investigation Analysis Standard Expression (CASE). To further promote a common structure, CASE aligns with and extends the Unified Cyber Ontology (UCO) construct, which provides a format for representing information in all cyber domains. This ontology abstracts objects and concepts that are not CASE-specific, so that they can be used across other cyber disciplines that may extend UCO. This work is a rational evolution of the Digital Forensic Analysis eXpression (DFAX) for representing digital forensic information and provenance. CASE is more flexible than DFAX and can be utilized in any context, including criminal, corporate and intelligence. CASE also builds on the Hansken data model developed and implemented by the Netherlands Forensic Institute (NFI). CASE enables the fusion of information from different organizations, data sources, and forensic tools to foster more comprehensive and cohesive analysis. This paper includes illustrative examples of how CASE can be implemented and used to capture information in a structured form to advance sharing, interoperability and analysis in cyber-investigations. In addition to capturing technical details and relationships between objects, CASE provides structure for representing and sharing details about how cyber-information was handled, transferred, processed, analyzed, and interpreted. CASE also supports data marking for sharing information at different levels of trust and classification, and for protecting sensitive and private information. Furthermore, CASE supports the sharing of knowledge related to cyber-investigations, including distinctive patterns of activity/behavior that are common across cases. This paper features a proof-of-concept Application Program Interface (API) to facilitate implementation of CASE in tools. Community members are encouraged to participate in the development and implementation of CASE and UCO.},
  keywords = {Cyber-investigation,CybOX,DFAX,DFXML,Digital evidence exchange,Digital forensics,Evidence provenance,Information sharing,Specification language,Standard representation,Unified cyber ontology},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\QQ2FLVE4\\caseyAdvancingCoordinatedCyberinvestigations2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\93M23W87\\S1742287617301007.html}
}

@article{caseyLeveragingCybOXStandardize2015,
  title = {Leveraging {{CybOX}}™ to Standardize Representation and Exchange of Digital Forensic Information},
  author = {Casey, Eoghan and Back, Greg and Barnum, Sean},
  date = {2015-03-01},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  series = {{{DFRWS}} 2015 {{Europe}}},
  volume = {12},
  pages = {S102-S110},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2015.01.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1742287615000158},
  urldate = {2024-12-03},
  abstract = {With the growing number of digital forensic tools and the increasing use of digital forensics in various contexts, including incident response and cyber threat intelligence, there is a pressing need for a widely accepted standard for representing and exchanging digital forensic information. Such a standard representation can support correlation between different data sources, enabling more effective and efficient querying and analysis of digital evidence. This work summarizes the strengths and weaknesses of existing schemas, and proposes the open-source CybOX schema as a foundation for storing and sharing digital forensic information. The suitability of CybOX for representing objects and relationships that are common in forensic investigations is demonstrated with examples involving digital evidence. The capability to represent provenance by leveraging CybOX is also demonstrated, including specifics of the tool used to process digital evidence and the resulting output. An example is provided of an ongoing project that uses CybOX to record the state of a system before and after an event in order to capture cause and effect information that can be useful for digital forensics. An additional open-source schema and associated ontology called Digital Forensic Analysis eXpression (DFAX) is proposed that provides a layer of domain specific information overlaid on CybOX. DFAX extends the capability of CybOX to represent more abstract forensic-relevant actions, including actions performed by subjects and by forensic examiners, which can be useful for sharing knowledge and supporting more advanced forensic analysis. DFAX can be used in combination with other existing schemas for representing identity information (CIQ), and location information (KML). This work also introduces and leverages initial steps of a Unified Cyber Ontology (UCO) effort to abstract and express concepts/constructs that are common across the cyber domain.},
  keywords = {CybOX,DFAX,DFXML,Digital forensic ontology,Digital forensic XML,Digital forensics,Standard representation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8AD2Y9L2\\caseyLeveragingCybOXStandardize2015.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\CM74AFDJ\\S1742287615000158.html}
}

@article{ceballosdelgadoFADEForensicImage2022,
  title = {{{FADE}}: {{A}} Forensic Image Generator for Android Device Education},
  shorttitle = {{{FADE}}},
  author = {Ceballos Delgado, Alberto A. and Glisson, William B. and Grispos, George and Choo, Kim-Kwang Raymond},
  date = {2022},
  journaltitle = {WIREs Forensic Science},
  volume = {4},
  number = {2},
  pages = {e1432},
  issn = {2573-9468},
  doi = {10.1002/wfs2.1432},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wfs2.1432},
  urldate = {2024-02-13},
  abstract = {Realistic case studies are essential to training successful digital forensics examiners. However, the generation of realistic datasets is time-consuming and resource taxing. This paper presents a technical solution that populates Android emulators with realistic mobile forensic data. The emulator's data can be extracted into a raw disk image that is usable in mobile forensic training scenarios. In addition, the tool allows a user to populate the Android emulators with custom text messages, phone contacts, phone calls, and files. This population task is achieved by utilizing the Android Debug Bridge, Android Content Providers, SQLite databases, and the NodeJS runtime environment. This paper presents the software design and development, the requirements and limitations, and the testing process implemented in this research. The contribution of this paper is twofold. First, it identifies potential data and mechanisms to generate Android mobile forensic datasets using customized data population. Second, it creates a foundation for future research on the topic of mobile forensic emulators for training purposes. This article is categorized under: Digital and Multimedia Science {$>$} Mobile Forensics Crime Scene Investigation {$>$} Education and Formation},
  langid = {english},
  keywords = {Android forensics,data generation,mobile forensics},
  file = {C:\Users\Kisun\Zotero\storage\HI7L88TZ\ceballosdelgadoFADEForensicImage2022.pdf}
}

@article{changFbHashNewSimilarity2019,
  title = {{{FbHash}}: {{A New Similarity Hashing Scheme}} for {{Digital Forensics}}},
  shorttitle = {{{FbHash}}},
  author = {Chang, Donghoon and Ghosh, Mohona and Sanadhya, Somitra Kumar and Singh, Monika and White, Douglas R.},
  date = {2019-07},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {29},
  pages = {S113-S123},
  issn = {17422876},
  doi = {10.1016/j.diin.2019.04.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287619301550},
  urldate = {2023-12-04},
  abstract = {With the rapid growth of the World Wide Web and Internet of Things, a huge amount of digital data is being produced every day. Digital forensics investigators face an uphill task when they have to manually screen through and examine tons of such data during a crime investigation. To expedite this process, several automated techniques have been proposed and are being used in practice. Among which tools based on Approximate Matching algorithms have gained prominence, e.g., ssdeep, sdhash, mvHash etc. These tools produce hash signatures for all the files to be examined, compute a similarity score and then compare it with a known reference set to filter out known good as well as bad files. In this way, exact as well as similar matches can be screened out. However, all of these schemes have been shown to be prone to active adversary attack, whereby an attacker, by making feasible changes in the content of the file, intelligently modifies the final hash signature produced to evade detection. Thus, an alternate hashing scheme is required which can resist this attack. In this work, we propose a new Approximate Matching scheme termed as - FbHash. We show that our scheme is secure against active attacks and detects similarity with 98\% accuracy. We also provide a detailed comparative analysis with other existing schemes and show that our scheme has a 28\% higher accuracy rate than other schemes for uncompressed file format (e.g., text files) and 50\% higher accuracy rate for compressed file format (e.g., docx etc.). Our proposed scheme is able to correlate a fragment as small as 1\% to the source file with 100\% detection rate and able to detect commonality as small as 1\% between two documents with appropriate similarity score. Further, our scheme also produces the least false negatives in comparison to other schemes.},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\I9I3KC6D\changFbHashNewSimilarity2019.pdf}
}

@article{chernyshevMobileForensicsAdvances2017,
  title = {Mobile {{Forensics}}: {{Advances}}, {{Challenges}}, and {{Research Opportunities}}},
  shorttitle = {Mobile {{Forensics}}},
  author = {Chernyshev, Maxim and Zeadally, Sherali and Baig, Zubair and Woodward, Andrew},
  date = {2017-11},
  journaltitle = {IEEE Security \& Privacy},
  volume = {15},
  number = {6},
  pages = {42--51},
  issn = {1558-4046},
  doi = {10.1109/MSP.2017.4251107},
  url = {https://ieeexplore.ieee.org/document/8123468},
  urldate = {2025-02-10},
  abstract = {The proliferation of mobile devices has led to advanced cybercriminal activities that exploit their ubiquity. Contemporary mobile forensics techniques and the challenges facing forensic investigators are discussed. Also identified are research opportunities that must be explored to enable more efficient mobile forensic techniques and technologies.},
  eventtitle = {{{IEEE Security}} \& {{Privacy}}},
  keywords = {cloud,Cloud computing,Computer security,Data mining,digital forensics,Digital forensics,digital investigation,Mobile communication,mobile forensics,Mobile handsets,privacy,Privacy,security},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\PIYWY6ZR\\chernyshevMobileForensicsAdvances2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\NTJIDNCI\\8123468.html}
}

@software{colvinPydantic2024,
  title = {Pydantic},
  author = {Colvin, Samuel and Jolibois, Eric and Ramezani, Hasan and Garcia Badaracco, Adrian and Dorsey, Terrence and Montague, David and Matveenko, Serge and Trylesinski, Marcelo and Runkle, Sydney and Hewitt, David and Hall, Alex and Plot, Victorien},
  date = {2024-12},
  origdate = {2017-05-03T21:23:58Z},
  url = {https://github.com/pydantic/pydantic},
  urldate = {2024-12-07},
  abstract = {Data validation using Python type hints},
  version = {v2.10.3}
}

@software{comfyanonymousComfyanonymousComfyUI2025,
  title = {Comfyanonymous/{{ComfyUI}}},
  author = {{comfyanonymous}},
  date = {2025-03-24T23:01:01Z},
  origdate = {2023-01-17T03:15:56Z},
  url = {https://github.com/comfyanonymous/ComfyUI},
  urldate = {2025-03-24},
  abstract = {The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.},
  keywords = {pytorch,stable-diffusion}
}

@incollection{conklinComputerForensics2022,
  title = {Computer {{Forensics}}},
  booktitle = {Principles of {{Computer Security}}: {{CompTIA Security}}+ and {{Beyond}} ({{Exam SY0-601}})},
  author = {Conklin, Wm. Arthur and White, Gregory and Cothren, Chuck and Davis, Roger L. and Williams, Dwayne},
  date = {2022},
  edition = {6th Edition},
  publisher = {McGraw-Hill Education},
  location = {New York},
  url = {https://www.accessengineeringlibrary.com/content/book/9781260474312/chapter/chapter23},
  isbn = {978-1-260-47431-2},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\MSUZNL82\conklinComputerForensics2022b.pdf}
}

@article{conlanAntiforensicsFurtheringDigital2016,
  title = {Anti-Forensics: {{Furthering}} Digital Forensic Science through a New Extended, Granular Taxonomy},
  shorttitle = {Anti-Forensics},
  author = {Conlan, Kevin and Baggili, Ibrahim and Breitinger, Frank},
  date = {2016-08-07},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {18},
  pages = {S66-S75},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2016.04.006},
  url = {https://www.sciencedirect.com/science/article/pii/S1742287616300378},
  urldate = {2023-11-27},
  abstract = {Anti-forensic tools, techniques and methods are becoming a formidable obstacle for the digital forensic community. Thus, new research initiatives and strategies must be formulated to address this growing problem. In this work we first collect and categorize 308 anti-digital forensic tools to survey the field. We then devise an extended anti-forensic taxonomy to the one proposed by Rogers (2006) in order to create a more comprehensive taxonomy and facilitate linguistic standardization. Our work also takes into consideration anti-forensic activity which utilizes tools that were not originally designed for anti-forensic purposes, but can still be used with malicious intent. This category was labeled as Possible indications of anti-forensic activity, as certain software, scenarios, and digital artifacts could indicate anti-forensic activity on a system. We also publicly share our data sets, which includes categorical data on 308 collected anti-forensic tools, as well as 2780 unique hash values related to the installation files of 191 publicly available anti-forensic tools. As part of our analysis, the collected hash set was ran against the National Institute of Standards and Technology's 2016 National Software Reference Library, and only 423 matches were found out of the 2780 hashes. Our findings indicate a need for future endeavors in creating and maintaining exhaustive anti-forensic hash data sets.},
  keywords = {Anti-digital forensics,Anti-forensics,Anti-forensics taxonomy,Categorical data set,Computer crime,Digital forensics,Formalizing digital forensics,research/anti-forensics},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\EAUHHMAL\\conlanAntiforensicsFurtheringDigital2016.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\WDSDSHRH\\S1742287616300378.html}
}

@inproceedings{cooperStandardsDigitalForensics2010,
  title = {Towards Standards in Digital Forensics Education},
  booktitle = {Proceedings of the 2010 {{ITiCSE}} Working Group Reports},
  author = {Cooper, Peter and Finley, Gail T. and Kaskenpalo, Petteri},
  date = {2010-06-28},
  pages = {87--95},
  publisher = {ACM},
  location = {Ankara Turkey},
  doi = {10.1145/1971681.1971688},
  url = {https://dl.acm.org/doi/10.1145/1971681.1971688},
  urldate = {2023-11-26},
  eventtitle = {{{ITiCSE}} '10: {{Annual Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  isbn = {978-1-4503-0677-5},
  langid = {english},
  keywords = {research/image-purpose,research/image-purpose/education},
  file = {C:\Users\Kisun\Zotero\storage\G8ULX727\cooperStandardsDigitalForensics2010.pdf}
}

@inproceedings{dafoulasOverviewDigitalForensics2019,
  title = {An Overview of {{Digital Forensics Education}}},
  booktitle = {2019 2nd {{International Conference}} on New {{Trends}} in {{Computing Sciences}} ({{ICTCS}})},
  author = {Dafoulas, Georgios A. and Neilson, David},
  date = {2019-10},
  pages = {1--7},
  publisher = {IEEE},
  location = {Amman, Jordan},
  doi = {10.1109/ICTCS.2019.8923101},
  url = {https://ieeexplore.ieee.org/document/8923101/},
  urldate = {2024-03-30},
  eventtitle = {2019 2nd {{International Conference}} on New {{Trends}} in {{Computing Sciences}} ({{ICTCS}})},
  isbn = {978-1-7281-2882-5},
  file = {C:\Users\Kisun\Zotero\storage\DNDE9DPQ\dafoulasOverviewDigitalForensics2019.pdf}
}

@online{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  date = {2025-01-22},
  eprint = {2501.12948},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.12948},
  url = {http://arxiv.org/abs/2501.12948},
  urldate = {2025-03-24},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\FXKFD3KU\\deepseek-aiDeepSeekR1IncentivizingReasoning2025.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\RDQG8UR4\\2501.html}
}

@article{demmelDataSynthesisGoing2024,
  title = {Data {{Synthesis Is Going Mobile}}—{{On Community-Driven Dataset Generation}} for {{Android Devices}}},
  author = {Demmel, Markus and Göbel, Thomas and Gonçalves, Patrik and Baier, Harald},
  date = {2024-10-26},
  journaltitle = {Digital Threats},
  volume = {5},
  number = {3},
  pages = {30:1--30:19},
  doi = {10.1145/3688807},
  url = {https://dl.acm.org/doi/10.1145/3688807},
  urldate = {2024-12-29},
  abstract = {Personal electronic devices such as smartphones and smartwatches have become indispensable daily companions, collecting a multitude of personal and sensitive data. As a result, they are of paramount importance in digital forensic examinations. However, there is a lack of publicly available and ready-to-use digital forensic datasets, especially in mobile forensics. This work presents a concept and an open-source proof-of-concept implementation, which simplifies and automates the creation of mobile forensic datasets within the scope of the Android operating system. In contrast to previous approaches, which populate the most common databases of an Android device, our concept is based on community-driven playbooks and makes use of interaction with the actual smartphone GUI. Hence, we are able to generate coherent and realistic traces as they occur in real-world human usage. Our proof-of-concept implementation is based on the standard Android emulation environment and borrows tools from the user interface testing community. Our evaluation shows that our approach actually generates realistic Android datasets. For instance, we can generate traces that cannot be simulated by gestures (e.g., changing the GPS position or triggering incoming phone calls). Recording the actual data synthesis process allows users to either create and share their own playbooks (i.e., the exact instructions for the data synthesis process rather than having to share the full image) or reproduce Android images with different scenarios using playbooks previously created and shared by the community.},
  file = {C:\Users\Kisun\Zotero\storage\8ZP3PIDL\demmelDataSynthesisGoing2024.pdf}
}

@article{duTraceGenUserActivity2021,
  title = {{{TraceGen}}: {{User}} Activity Emulation for Digital Forensic Test Image Generation},
  shorttitle = {{{TraceGen}}},
  author = {Du, Xiaoyu and Hargreaves, Christopher and Sheppard, John and Scanlon, Mark},
  date = {2021-10-01},
  journaltitle = {Forensic Science International: Digital Investigation},
  shortjournal = {Forensic Science International: Digital Investigation},
  volume = {38},
  pages = {301133},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2021.301133},
  url = {https://www.sciencedirect.com/science/article/pii/S2666281721000317},
  urldate = {2024-12-30},
  abstract = {Digital forensic test images are commonly used across a variety of digital forensic use cases including education and training, tool testing and validation, proficiency testing, malware analysis, and research and development. Using real digital evidence for these purposes is often not viable or permissible, especially when factoring in the ethical and in some cases legal considerations of working with individuals' personal data. Furthermore, when using real data it is not usually known what actions were performed when, i.e., what was the ‘ground truth’. The creation of synthetic digital forensic test images typically involves an arduous, time-consuming process of manually performing a list of actions, or following a ‘story’ to generate artefacts in a subsequently imaged disk. Besides the manual effort and time needed in executing the relevant actions in the scenario, there is often little room to build a realistic volume of non-pertinent wear-and-tear or ‘background noise’ on the suspect device, meaning the resulting disk images are inherently limited and to a certain extent simplistic. This work presents the TraceGen framework, an automated system focused on the emulation of user actions to create realistic and comprehensive artefacts in an auditable and reproducible manner. The framework consists of a series of actions contained within scripts that are executed both externally and internally to a target virtual machine. These actions use existing automation APIs to emulate a real user's behaviour on a Windows system to generate realistic and comprehensive artefacts. These actions can be quickly scripted together to form complex stories or to emulate wear-and-tear on the test image. In addition to the development of the framework, evaluation is also performed in terms of the ability to produce background artefacts at scale, and also the realism of the artefacts compared with their human-generated counterparts.},
  keywords = {Evidence planting,Forensic disk image creation,Forensic education,Tool testing and validation,User emulation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\NE7US37Y\\duTraceGenUserActivity2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\I3WY2FEZ\\S2666281721000317.html}
}

@article{eshraghianHumanOwnershipArtificial2020,
  title = {Human Ownership of Artificial Creativity},
  author = {Eshraghian, Jason K.},
  date = {2020-03},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {2},
  number = {3},
  pages = {157--160},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-0161-x},
  url = {https://www.nature.com/articles/s42256-020-0161-x},
  urldate = {2023-12-04},
  abstract = {Advances in generative algorithms have enhanced the quality and accessibility of artificial intelligence (AI) as a tool in building synthetic datasets. By generating photorealistic images and videos, these networks can pose a major technological disruption to a broad range of industries from medical imaging to virtual reality. However, as artwork developed by generative algorithms and cognitive robotics enters the arena, the notion of human-driven creativity has been thoroughly tested. When creativity is automated by the programmer, in a style determined by the trainer, using features from information available in public and private datasets, who is the proprietary owner of the rights in AI-generated artworks and designs? This Perspective seeks to provide an answer by systematically exploring the key issues in copyright law that arise at each phase of artificial creativity, from programming to deployment. Ultimately, four guiding actions are established for artists, programmers and end users that utilize AI as a tool such that they may be appropriately awarded the necessary proprietary rights.},
  issue = {3},
  langid = {english},
  keywords = {Computer science,Law},
  file = {C:\Users\Kisun\Zotero\storage\T6XCDWTA\eshraghianHumanOwnershipArtificial2020.pdf}
}

@online{exterroFTKImagerForensic,
  title = {{{FTK Imager}} - {{Forensic Data Imaging}} and {{Preview Solution}}},
  author = {{Exterro}},
  url = {https://www.exterro.com/digital-forensics-software/ftk-imager},
  urldate = {2025-03-06},
  abstract = {FTK Imager, the choice for global digital forensics professionals. Quick, forensically sound data preview and imaging for electronic device investigations.},
  langid = {american},
  organization = {Exterro},
  file = {C:\Users\Kisun\Zotero\storage\LFSTIE94\ftk-imager.html}
}

@book{finkel1996advanced,
  title = {Advanced Programming Language Design},
  author = {Finkel, Raphael A},
  date = {1996},
  publisher = {Addison-Wesley Reading}
}

@article{garfinkelBringingScienceDigital2009,
  title = {Bringing Science to Digital Forensics with Standardized Forensic Corpora},
  author = {Garfinkel, Simson and Farrell, Paul and Roussev, Vassil and Dinolt, George},
  date = {2009-09},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {6},
  pages = {S2-S11},
  issn = {17422876},
  doi = {10.1016/j.diin.2009.06.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287609000346},
  urldate = {2023-11-26},
  langid = {english},
  keywords = {research/image-purpose,research/public-datasets},
  file = {C:\Users\Kisun\Zotero\storage\B87VH8VI\garfinkelBringingScienceDigital2009.pdf}
}

@article{garfinkelForensicCorporaChallenge2007,
  title = {Forensic {{Corpora}}: {{A Challenge}} for {{Forensic Research}}},
  shorttitle = {Forensic {{Corpora}}},
  author = {Garfinkel, Simson},
  date = {2007-01-01},
  volume = {2007},
  abstract = {Research in the field of computer forensics is hobbled by the lack of realistic data. Academics are not developing automated techniques and tools because they lack the raw data necessary to develop and validate algorithms. Investigators that have access to real data operate under legal and practical restraints that prevent the data from being used in research. To make progress, we must "prime the pump" by collecting or creating forensic corpora that can be used by researchers. We must also pursue targeted technical developments in forensic file formats, knowledge representation, inference techniques, and the presentation of forensic results.},
  keywords = {research/image-gaps,research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\ITBMI4BV\Garfinkel - 2007 - Forensic Corpora A Challenge for Forensic Researc.pdf}
}

@article{geigerEvaluatingCommercialCounterForensic2005,
  title = {Evaluating {{Commercial Counter-Forensic Tools}}},
  author = {Geiger, Matthew},
  date = {2005},
  abstract = {Digital forensic analysts may find their task complicated by any of more than a dozen commercial software packages designed to irretrievably erase files and records of computer activity. These counter-forensic tools have been used to eliminate evidence in criminal and civil legal proceedings and represent an area of continuing concern for forensic investigators. In this paper, we review the performance of six counter-forensic tools and highlight operational shortfalls that could permit the recovery of significant evidentiary data. In addition, each tool creates a distinct operational fingerprint that an analyst may use to identify the application used and, thus, guide the search for residual data. These operational fingerprints may also help demonstrate the use of a tool in cases where such action has legal ramifications.},
  langid = {english},
  keywords = {research/anti-forensics},
  file = {C:\Users\Kisun\Zotero\storage\Q5LXE38H\Geiger - 2005 - Evaluating Commercial Counter-Forensic Tools.pdf}
}

@article{gobelForTraceHolisticForensic2022,
  title = {{{ForTrace}} - {{A}} Holistic Forensic Data Set Synthesis Framework},
  author = {Göbel, Thomas and Maltan, Stephan and Türr, Jan and Baier, Harald and Mann, Florian},
  date = {2022-04-01},
  journaltitle = {Forensic Science International: Digital Investigation},
  shortjournal = {Forensic Science International: Digital Investigation},
  series = {Selected {{Papers}} of the {{Ninth Annual DFRWS Europe Conference}}},
  volume = {40},
  pages = {301344},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2022.301344},
  url = {https://www.sciencedirect.com/science/article/pii/S2666281722000130},
  urldate = {2023-08-31},
  abstract = {Digital forensic experts are confronted with a wide variety of investigation objectives, e.g., to deal with an infected IT system. The same holds for digital forensic tools. Mostly different sources of digital traces have to be inspected including persistent storage devices (e.g., SSDs, SD cards, USB drives), volatile main memory snapshots, and network captures, respectively. In order to train experts and tools and keep their knowledge and capabilities up-to-date, a capacious amount of realistic, timely training data is necessary. However, due to different reasons like privacy, secrecy, or intellectual property rights there is a large gap in digital forensic training data. In recent years different synthesis frameworks to generate realistic digital forensic data sets have been proposed. However, none of these frameworks provides a holistic approach to generate realistic digital forensic relevant traces of different sources. In this paper we introduce ForTrace, a holistic framework for the simultaneous generation of persistent, volatile and network traces. Our approach is based on the data synthesis framework hystck. We explain our extension of hystck by defining properties of a holistic data set synthesis framework and by discussing different forensically relevant scenarios and their implementation in ForTrace. We then successfully evaluate ForTrace with respect to diverse realistic and complex scenarios. ForTrace is open source and may be adapted or extended with respect to individual needs.},
  keywords = {Data synthesis,Digital forensic corpora,Forensic data set,Forensic education,Forensic image generation,Forensic tool testing,research/synthesizer-details,User simulation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\67KLSECY\\gobelForTraceHolisticForensic2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\JBBHY8Z2\\S2666281722000130.html}
}

@incollection{gobelNovelApproachGenerating2020,
  title = {A {{Novel Approach}} for {{Generating Synthetic Datasets}} for {{Digital Forensics}}},
  booktitle = {Advances in {{Digital Forensics XVI}}},
  author = {Göbel, Thomas and Schäfer, Thomas and Hachenberger, Julien and Türr, Jan and Baier, Harald},
  editor = {Peterson, Gilbert and Shenoi, Sujeet},
  date = {2020},
  volume = {589},
  pages = {73--93},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-56223-6_5},
  url = {http://link.springer.com/10.1007/978-3-030-56223-6_5},
  urldate = {2023-09-17},
  isbn = {978-3-030-56222-9 978-3-030-56223-6},
  langid = {english},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\359G4TQ6\gobelNovelApproachGenerating2020.pdf}
}

@article{goncalvesRevisitingDatasetGap2022,
  title = {Revisiting the Dataset Gap Problem – {{On}} Availability, Assessment and Perspective of Mobile Forensic Corpora},
  author = {Gonçalves, Patrik and Dološ, Klara and Stebner, Michelle and Attenberger, Andreas and Baier, Harald},
  date = {2022-09-01},
  journaltitle = {Forensic Science International: Digital Investigation},
  shortjournal = {Forensic Science International: Digital Investigation},
  volume = {43},
  pages = {301439},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2022.301439},
  url = {https://www.sciencedirect.com/science/article/pii/S2666281722001202},
  urldate = {2025-02-10},
  abstract = {Digital forensic corpora are essential for education, academic research, tool development and testing. Due to the increasing pervasiveness of mobile devices like smartphones or tablets, the need for mobile forensic datasets is growing, too. However, publications in the IT forensic community show that there is a large gap in publicly available datasets. In this work we focus on mobile digital forensic corpora as one of the main fields of missing datasets and aim at shifting the focus of the digital forensic community on this topic. In order to do so, we provide three main contributions. We first perform a structured search for mobile forensic corpora and show that 31 publicly available mobile forensic corpora exist, 9 of them more than 5 years old and 18 of them more than 3 years old. Second, we assess these datasets with respect to its content compared to an ordinary real mobile image and conclude that most of the 31 datasets contain too few traces to be considered as realistic. Finally, we propose how to proceed to solve the presumable problem of missing mobile forensic datasets.},
  keywords = {Analysis,Availability,Content,Dataset,Digital forensics corpora,Mobile forensics,Quality,Quantity,Review,Smartphone,Statistics,Timeliness},
  file = {C:\Users\Kisun\Zotero\storage\WP58LWQR\S2666281722001202.html}
}

@online{Govdocs1DigitalCorpora2010,
  title = {Govdocs1 – {{Digital Corpora}}},
  date = {2010-06-21},
  url = {https://digitalcorpora.org/corpora/file-corpora/files/},
  urldate = {2025-03-24},
  langid = {american},
  file = {C:\Users\Kisun\Zotero\storage\6Q6TUNB8\files.html}
}

@article{grajedaAvailabilityDatasetsDigital2017,
  title = {Availability of Datasets for Digital Forensics – {{And}} What Is Missing},
  author = {Grajeda, Cinthya and Breitinger, Frank and Baggili, Ibrahim},
  date = {2017-08},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {22},
  pages = {S94-S105},
  issn = {17422876},
  doi = {10.1016/j.diin.2017.06.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287617301913},
  urldate = {2023-11-06},
  langid = {english},
  keywords = {research/image-gaps,research/image-sources,research/manual-motivation,research/public-datasets},
  file = {C:\Users\Kisun\Zotero\storage\UEHWSGEW\grajedaAvailabilityDatasetsDigital2017.pdf}
}

@inproceedings{guptaDigitalForensicsLab2022,
  title = {Digital {{Forensics Lab Design}}: {{A}} Framework},
  shorttitle = {Digital {{Forensics Lab Design}}},
  booktitle = {2022 10th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})},
  author = {Gupta, Khushi and Neyaz, Ashar and Shashidhar, Narasimha and Varol, Cihan},
  date = {2022-06},
  pages = {1--6},
  doi = {10.1109/ISDFS55398.2022.9800799},
  url = {https://ieeexplore.ieee.org/document/9800799},
  urldate = {2023-11-27},
  abstract = {Internet connectivity and digital technologies have experienced exponential growth in the past few years. This explosion has spurred a significant increase in crime while also creating a new definition of cybercriminals. Digital Forensics plays an important role in crime reconstruction and thus the need for skilled forensics experts has multiplied. As a result, digital forensics education and training has also experienced radical growth. Teaching digital forensics has always been a challenge as the creation of suitable hands-on digital forensics labs has always been the core of these training programs. There are several challenges faced by both the educators and the students when it comes to the creation and implementation of digital forensics labs. This paper aims to address some of these issues by providing a framework that can be used by educators to establish educational hands-on labs for digital forensics. Firstly, we identify all the challenges faced by digital examiners, educators, and training professionals to deliver high-quality forensic labs. Secondly, we identify specific common technical pitfalls that professionals run into when designing digital forensics labs such as the creation of large image files. We thus, offer tips and tricks to make the process of creating digital forensic labs easier. Finally, we also provide a data set of small-sized image files that can be used by educators for the creation of a digital forensic lab infrastructure.},
  eventtitle = {2022 10th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})},
  keywords = {research/image-purpose,research/image-purpose/education},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\7EKX2QKT\\guptaDigitalForensicsLab2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\VHAK9BZ8\\9800799.html}
}

@incollection{hargreavesDigitalForensicsEducation2017,
  title = {Digital {{Forensics Education}}: {{A New Source}} of {{Forensic Evidence}}},
  shorttitle = {Digital {{Forensics Education}}},
  booktitle = {Forensic {{Science Education}} and {{Training}}},
  author = {Hargreaves, Christopher},
  editor = {Williams, Anna and Cassella, John P. and Maskell, Peter D.},
  date = {2017-05-18},
  edition = {1},
  pages = {73--85},
  publisher = {Wiley},
  doi = {10.1002/9781118689196.ch6},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/9781118689196.ch6},
  urldate = {2024-02-13},
  isbn = {978-1-118-68923-3 978-1-118-68919-6},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\C2UQ36WE\hargreavesDigitalForensicsEducation2017.pdf}
}

@article{harrisArrivingAntiforensicsConsensus2006,
  title = {Arriving at an Anti-Forensics Consensus: {{Examining}} How to Define and Control the Anti-Forensics Problem},
  shorttitle = {Arriving at an Anti-Forensics Consensus},
  author = {Harris, Ryan},
  date = {2006-09},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {3},
  pages = {44--49},
  issn = {17422876},
  doi = {10.1016/j.diin.2006.06.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287606000673},
  urldate = {2023-11-27},
  abstract = {There are no general frameworks with which we may analyze the anti-forensics situation. Solving anti-forensic issues requires that we create a consensus view of the problem itself. This paper attempts to arrive at a standardized method of addressing anti-forensics by defining the term, categorizing the anti-forensics techniques and outlining general guidelines to protect forensic integrity.},
  langid = {english},
  keywords = {research/anti-forensics},
  file = {C:\Users\Kisun\Zotero\storage\4HFGL2P3\Harris - 2006 - Arriving at an anti-forensics consensus Examining.pdf}
}

@online{hashicorpHashiCorpCloudPlatform,
  title = {{{HashiCorp Cloud Platform}}},
  author = {{HashiCorp}},
  url = {https://portal.cloud.hashicorp.com/vagrant/discover},
  urldate = {2025-02-23},
  organization = {Vagrant Public Registry},
  file = {C:\Users\Kisun\Zotero\storage\7LY7CBGP\discover.html}
}

@software{HashicorpVagrant2025,
  title = {Hashicorp/Vagrant},
  date = {2025-02-22T17:01:02Z},
  origdate = {2010-01-21T08:34:27Z},
  url = {https://github.com/hashicorp/vagrant},
  urldate = {2025-02-23},
  abstract = {Vagrant is a tool for building and distributing development environments.},
  organization = {HashiCorp},
  keywords = {automation,ruby,vagrant,virtualization}
}

@online{heWebVoyagerBuildingEndtoEnd2024,
  title = {{{WebVoyager}}: {{Building}} an {{End-to-End Web Agent}} with {{Large Multimodal Models}}},
  shorttitle = {{{WebVoyager}}},
  author = {He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  date = {2024-06-06},
  eprint = {2401.13919},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.13919},
  url = {http://arxiv.org/abs/2401.13919},
  urldate = {2025-02-10},
  abstract = {The rapid advancement of large language models (LLMs) has led to a new era marked by the development of autonomous applications in real-world scenarios, which drives innovation in creating advanced web agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we establish a new benchmark by compiling real-world tasks from 15 popular websites and introduce an automatic evaluation protocol leveraging multimodal understanding abilities of GPT-4V to evaluate open-ended web agents. We show that WebVoyager achieves a 59.1\% task success rate on our benchmark, significantly surpassing the performance of both GPT-4 (All Tools) and the WebVoyager (text-only) setups, underscoring the exceptional capability of WebVoyager. The proposed automatic evaluation metric achieves 85.3\% agreement with human judgment, indicating its effectiveness in providing reliable and accurate assessments of web agents.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\SP77ICV2\\heWebVoyagerBuildingEndtoEnd2024.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\3LG5KXNB\\2401.html}
}

@article{horsmanDatasetConstructionChallenges2021,
  title = {Dataset Construction Challenges for Digital Forensics},
  author = {Horsman, Graeme and Lyle, James R.},
  date = {2021-09-01},
  journaltitle = {Forensic Science International: Digital Investigation},
  shortjournal = {Forensic Science International: Digital Investigation},
  volume = {38},
  pages = {301264},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2021.301264},
  url = {https://www.sciencedirect.com/science/article/pii/S2666281721001815},
  urldate = {2024-12-30},
  abstract = {As the digital forensic field develops, taking steps towards ensuring a level of reliability in the processes implemented by its practitioners, emphasis on the need for effective testing has increased. In order to test, test datasets are required, but creating these is not a straightforward task. A poorly constructed and documented test dataset undermines any testing which has taken place using it, eroding the reliability of any subsequent test results. In essence, given the time, effort and knowledge required to generate datasets, the field must guide those carrying out this task to ensure that it is done right at the first instance without wasting resources. Yet, there are currently few standards and best practices defined for dataset creation in digital forensics. This work defines three categories of dataset which typically exist in digital forensic - tool/process evaluation datasets, actions datasets and scenario-based datasets, where the minimum requirements for their creation are outlined and discussed to support those creating them and to help ensure that where datasets are created, they offer maximum value to the field.},
  keywords = {Datasets,Digital forensics,Testing,Tool-testing},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\W8A44WDJ\\horsmanDatasetConstructionChallenges2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\G6LPUVLG\\S2666281721001815.html}
}

@inproceedings{hwangComponentbasedPerformanceComparison2013,
  title = {A Component-Based Performance Comparison of Four Hypervisors},
  booktitle = {2013 {{IFIP}}/{{IEEE International Symposium}} on {{Integrated Network Management}} ({{IM}} 2013)},
  author = {Hwang, Jinho and Zeng, Sai and family=Wu, given=Frederick, prefix=y, useprefix=false and Wood, Timothy},
  date = {2013-05},
  pages = {269--276},
  issn = {1573-0077},
  url = {https://ieeexplore.ieee.org/document/6572995},
  urldate = {2025-02-10},
  abstract = {Virtualization has become a popular way to make more efficient use of server resources within both private data centers and public cloud platforms. While recent advances in CPU architectures and new virtualization techniques have reduced the performance cost of using virtualization, overheads still exist, particularly when multiple virtual machines are competing for resources. We have performed an extensive performance comparison under hardware-assisted virtualization settings considering four popular virtualization platforms, Hyper-V, KVM, vSphere and Xen, and find that the overheads incurred by each hypervisor can vary significantly depending on the type of application and the resources assigned to it. We also find dramatic differences in the performance isolation provided by different hypervisors. However, we find no single hypervisor always outperforms the others. This suggests that effectively managing hypervisor diversity in order to match applications to the best platform is an important, yet unstudied, challenge.},
  eventtitle = {2013 {{IFIP}}/{{IEEE International Symposium}} on {{Integrated Network Management}} ({{IM}} 2013)},
  keywords = {Benchmark,Benchmark testing,Cloud Computing,Dynamic scheduling,Hardware,Hypervisor,Linux,Servers,Virtual machine monitors,Virtualization},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\S9KD88LJ\\hwangComponentbasedPerformanceComparison2013.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\QZ46GWMA\\6572995.html}
}

@article{janickiObstaclesOpportunitiesDeploying2012,
  title = {Obstacles and Opportunities in Deploying Model-Based {{GUI}} Testing of Mobile Software: A Survey},
  shorttitle = {Obstacles and Opportunities in Deploying Model-Based {{GUI}} Testing of Mobile Software},
  author = {Janicki, Marek and Katara, Mika and Pääkkönen, Tuula},
  date = {2012},
  journaltitle = {Software Testing, Verification and Reliability},
  volume = {22},
  number = {5},
  pages = {313--341},
  issn = {1099-1689},
  doi = {10.1002/stvr.460},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.460},
  urldate = {2024-12-30},
  abstract = {Model-based testing has not been widely deployed in industry yet. There seem to be both technical and non-technical reasons for this situation. A survey among mobile software testing professions in Finland was conducted that aimed at investigating possible obstacles and opportunities towards wider deployment of this technology. This paper discusses the results and provides conclusions that indicate that at least in this context, there is much interest among practitioners towards the technology. However, more research is needed to make model creation and maintenance as easy as possible. In addition, metrics should be developed that can be used to report test results in the same manner as using existing testing techniques, enabling comparison between different approaches. Special emphasis should also be placed on enabling quick bug localization. Furthermore, it seems that successful pilot projects are a key to wider industrial adoption. Based on the survey findings, an agenda for the future model-based testing research is outlined. Copyright © 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {GUI testing,model-based testing,survey},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\LRLN5PIJ\\janickiObstaclesOpportunitiesDeploying2012.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\G8INDWME\\stvr.html}
}

@software{jjk422Jjk422ForGen2019,
  title = {Jjk422/{{ForGen}}},
  author = {Jjk422},
  date = {2019-08-15T22:08:23Z},
  origdate = {2016-06-08T12:56:23Z},
  url = {https://github.com/Jjk422/ForGen},
  urldate = {2025-03-08},
  abstract = {Forensic generator}
}

@incollection{jonesInsightDigitalForensics2022,
  title = {An {{Insight}} into {{Digital Forensics}}: {{History}}, {{Frameworks}}, {{Types}} and {{Tools}}},
  shorttitle = {An {{Insight}} into {{Digital Forensics}}},
  booktitle = {Cyber {{Security}} and {{Digital Forensics}}},
  author = {Jones, G Maria and Winster, S Godfrey},
  editor = {Ghonge, Mangesh M. and Pramanik, Sabyasachi and Mangrulkar, Ramchandra and Le, Dac‐Nhuong},
  date = {2022-02-08},
  edition = {1},
  pages = {105--125},
  publisher = {Wiley},
  doi = {10.1002/9781119795667.ch6},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/9781119795667.ch6},
  urldate = {2023-11-27},
  isbn = {978-1-119-79563-6 978-1-119-79566-7},
  langid = {english},
  keywords = {research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\44YYJNZ3\jonesInsightDigitalForensics2022.pdf}
}

@software{lalancetteClalancettePycdlib2025,
  title = {Clalancette/Pycdlib},
  author = {Lalancette, Chris},
  date = {2025-02-06T03:50:04Z},
  origdate = {2015-04-27T02:04:52Z},
  url = {https://github.com/clalancette/pycdlib},
  urldate = {2025-02-23},
  abstract = {Python library to read and write ISOs},
  keywords = {eltorito,iso,iso9660,joliet,python,python-library,rockridge,udf}
}

@software{langaBlackUncompromisingPython2025,
  title = {Black: {{The}} Uncompromising {{Python}} Code Formatter},
  shorttitle = {Black},
  author = {Langa, Łukasz and {contributors to Black}},
  date = {2025-03-08T03:32:05Z},
  origdate = {2018-03-14T19:54:45Z},
  url = {https://github.com/psf/black},
  urldate = {2025-03-08},
  abstract = {The uncompromising Python code formatter}
}

@software{larsonSethmlarsonVirtualboxpython2025,
  title = {Sethmlarson/Virtualbox-Python},
  author = {Larson, Seth Michael},
  date = {2025-01-16T12:48:37Z},
  origdate = {2013-05-25T03:06:25Z},
  url = {https://github.com/sethmlarson/virtualbox-python},
  urldate = {2025-02-10},
  abstract = {Complete implementation of VirtualBox's COM API with a Pythonic interface.},
  keywords = {python,virtual-machine,virtualbox,virtualbox-vm,vm}
}

@inproceedings{lawrenceFrameworkDesignWebbased2009,
  title = {Framework for the Design of Web-Based Learning for Digital Forensics Labs},
  booktitle = {Proceedings of the 47th {{Annual Southeast Regional Conference}}},
  author = {Lawrence, Kevin R. and Chi, Hongmei},
  date = {2009-03-19},
  series = {{{ACM-SE}} 47},
  pages = {1--4},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1566445.1566546},
  url = {https://dl.acm.org/doi/10.1145/1566445.1566546},
  urldate = {2023-11-27},
  abstract = {Digital forensic education and training has been experiencing radical growth in the past ten years. The core of these training and academic programs is to develop a set of suitable hands-on digital forensic labs. To do this we first must familiarize ourselves with the tools of the trade. The main step to training students, who are preparing to be computer forensic professionals, lies in creating a comprehensive hands-on approach to computer forensics. The goal of this project work is to establish a series of hands-on computer forensic labs, which help students prepare to accede seamlessly into the law enforcement workforce and to make these labs available online by exploiting technologies of Web-based learning and future web developments, one of this includes the Semantic Web. The Semantic Web will enable intelligent services by several methods which all work towards making information machine-understandable [3]. With this we hope to develop an intelligent Web-based educational system which is capable of demonstrating some form of knowledge-based reasoning in lab sequencing, in analysis of the student's answers combining with students' background, and in providing interactive problem-solving support to the student, all adapted to the Web technology [3].},
  isbn = {978-1-60558-421-8},
  keywords = {digital forensics,e-learning,forensics tools,hand-on labs,information systems,research/image-purpose,research/image-purpose/education,semantic web,web-based},
  file = {C:\Users\Kisun\Zotero\storage\Z4EY4A4C\lawrenceFrameworkDesignWebbased2009.pdf}
}

@software{LibyalLibyal2025,
  title = {Libyal/Libyal},
  date = {2025-02-26T22:42:24Z},
  origdate = {2014-09-08T05:57:58Z},
  url = {https://github.com/libyal/libyal},
  urldate = {2025-03-05},
  abstract = {Yet another library library (and tools)},
  organization = {libyal}
}

@inproceedings{linares-vasquezHowDevelopersTest2017,
  title = {How Do {{Developers Test Android Applications}}?},
  booktitle = {2017 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  author = {Linares-Vásquez, Mario and Bernal-Cardenas, Cárlos and Moran, Kevin and Poshyvanyk, Denys},
  date = {2017-09},
  pages = {613--622},
  doi = {10.1109/ICSME.2017.47},
  url = {https://ieeexplore.ieee.org/abstract/document/8094467},
  urldate = {2025-02-10},
  abstract = {Enabling fully automated testing of mobile applications has recently become an important topic of study for both researchers and practitioners. A plethora of tools and approaches have been proposed to aid mobile developers both by augmenting manual testing practices and by automating various parts of the testing process. However, current approaches for automated testing fall short in convincing developers about their benefits, leading to a majority of mobile testing being performed manually. With the goal of helping researchers and practitioners - who design approaches supporting mobile testing - to understand developer's needs, we analyzed survey responses from 102 open source contributors to Android projects about their practices when performing testing. The survey focused on questions regarding practices and preferences of developers/testers in-the-wild for (i) designing and generating test cases, (ii) automated testing practices, and (iii) perceptions of quality metrics such as code coverage for determining test quality. Analyzing the information gleaned from this survey, we compile a body of knowledge to help guide researchers and professionals toward tailoring new automated testing approaches to the need of a diverse set of open source developers.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Software Maintenance}} and {{Evolution}} ({{ICSME}})},
  keywords = {Androids,Humanoid robots,Manuals,Mobile communication,Programming,Testing,Tools},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\Q2V2KRLJ\\linares-vasquezHowDevelopersTest2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\SKW2CMAH\\8094467.html}
}

@article{linAutomatedForensicAnalysis2018,
  title = {Automated Forensic Analysis of Mobile Applications on {{Android}} Devices},
  author = {Lin, Xiaodong and Chen, Ting and Zhu, Tong and Yang, Kun and Wei, Fengguo},
  date = {2018-07-01},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {26},
  pages = {S59-S66},
  doi = {10.1016/j.diin.2018.04.012},
  abstract = {It is not uncommon that mobile phones are involved in criminal activities, e.g., the surreptitious collection of credit card information. Forensic analysis of mobile applications plays a crucial part in order to gather evidences against criminals. However, traditional forensic approaches, which are based on manual investigation, are not scalable to the large number of mobile applications. On the other hand, dynamic analysis is hard to automate due to the burden of setting up the proper runtime environment to accommodate OS differences and dependent libraries and activate all feasible program paths. We propose a fully automated tool, Fordroid for the forensic analysis of mobile applications on Android. Fordroid conducts inter-component static analysis on Android APKs and builds control flow and data dependency graphs. Furthermore, Fordroid identifies what and where information written in local storage with taint analysis. Data is located by traversing the graphs. This addresses several technique challenges, which include inter-component string propagation, string operations (e.g., append) and API invocations. Also, Fordroid identifies how the information is stored by parsing SQL commands, i.e., the structure of database tables. Finally, we selected 100 random Android applications consisting of 2841 components from four categories for evaluation. Analysis of all apps took 64 h. Fordroid discovered 469 paths in 36 applications that wrote sensitive information (e.g., GPS) to local storage. Furthermore, Fordroid successfully located where the information was written for 458 (98\%) paths and identified the structure of all (22) database tables.},
  file = {C:\Users\Kisun\Zotero\storage\PIYYAZ6J\linAutomatedForensicAnalysis2018.pdf}
}

@software{Log2timelineDfvfs2025,
  title = {Log2timeline/Dfvfs},
  date = {2025-02-12T20:38:12Z},
  origdate = {2014-09-09T05:06:44Z},
  url = {https://github.com/log2timeline/dfvfs},
  urldate = {2025-02-26},
  abstract = {Digital Forensics Virtual File System (dfVFS)},
  organization = {log2timeline}
}

@software{Log2timelinePlaso2025,
  title = {Log2timeline/Plaso},
  date = {2025-03-28T00:34:58Z},
  origdate = {2014-09-08T23:29:28Z},
  url = {https://github.com/log2timeline/plaso},
  urldate = {2025-03-28},
  abstract = {Super timeline all the things},
  organization = {log2timeline},
  keywords = {forensics,parsing,timeline}
}

@inproceedings{lucianoDigitalForensicsNext2018,
  title = {Digital {{Forensics}} in the {{Next Five Years}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Luciano, Laoise and Baggili, Ibrahim and Topor, Mateusz and Casey, Peter and Breitinger, Frank},
  date = {2018-08-27},
  series = {{{ARES}} '18},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3230833.3232813},
  url = {https://dl.acm.org/doi/10.1145/3230833.3232813},
  urldate = {2024-03-30},
  abstract = {Cyber forensics has encountered major obstacles over the last decade and is at a crossroads. This paper presents data that was obtained during the National Workshop on Redefining Cyber Forensics (NWRCF) on May 23-24, 2017 supported by the National Science Foundation and organized by the University of New Haven. Qualitative and quantitative data were analyzed from twenty-four cyber forensics expert panel members. This work identified important themes that need to be addressed by the community, focusing on (1) where the domain currently is; (2) where it needs to go and; (3) steps needed to improve it. Furthermore, based on the results, we articulate (1) the biggest anticipated challenges the domain will face in the next five years; (2) the most important cyber forensics research opportunities in the next five years and; (3) the most important job-ready skills that need to be addressed by higher education curricula over the next five years. Lastly, we present the key issues and recommendations deliberated by the expert panel. Overall results indicated that a more active and coherent group needs to be formed in the cyber forensics community, with opportunities for continuous reassessment and improvement processes in place.},
  isbn = {978-1-4503-6448-5},
  keywords = {Computer forensics,Cyber Forensics,Digital Forensics,Forensics,Needs analysis,Policy,Research,Tools,Workshop},
  file = {C:\Users\Kisun\Zotero\storage\L52YEH27\lucianoDigitalForensicsNext2018.pdf}
}

@software{macfarlanePandoc2025,
  title = {Pandoc},
  author = {MacFarlane, John and Krewinkel, Albert and Rosenthal, Jesse},
  date = {2025-03-15T08:30:33Z},
  origdate = {2010-03-20T20:34:23Z},
  url = {https://github.com/jgm/pandoc},
  urldate = {2025-03-15},
  abstract = {Universal markup converter}
}

@software{maxfraggMaxfraggForGeOSI2023,
  title = {Maxfragg/{{ForGeOSI}}},
  author = {{maxfragg}},
  date = {2023-06-16T20:16:36Z},
  origdate = {2014-02-03T08:14:59Z},
  url = {https://github.com/maxfragg/ForGeOSI},
  urldate = {2025-02-06},
  abstract = {Forensic Generator that automates disk image generation with virtualbox in python. Uses pyvbox as basis.}
}

@inproceedings{meffertForensicStateAcquisition2017,
  title = {Forensic {{State Acquisition}} from {{Internet}} of {{Things}} ({{FSAIoT}}): {{A}} General Framework and Practical Approach for {{IoT}} Forensics through {{IoT}} Device State Acquisition},
  shorttitle = {Forensic {{State Acquisition}} from {{Internet}} of {{Things}} ({{FSAIoT}})},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Meffert, Christopher and Clark, Devon and Baggili, Ibrahim and Breitinger, Frank},
  date = {2017-08-29},
  series = {{{ARES}} '17},
  pages = {1--11},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3098954.3104053},
  url = {https://dl.acm.org/doi/10.1145/3098954.3104053},
  urldate = {2023-08-30},
  abstract = {IoT device forensics is a difficult problem given that manufactured IoT devices are not standardized, many store little to no historical data, and are always connected; making them extremely volatile. The goal of this paper was to address these challenges by presenting a primary account for a general framework and practical approach we term Forensic State Acquisition from Internet of Things (FSAIoT). We argue that by leveraging the acquisition of the state of IoT devices (e.g. if an IoT lock is open or locked), it becomes possible to paint a clear picture of events that have occurred. To this end, FSAIoT consists of a centralized Forensic State Acquisition Controller (FSAC) employed in three state collection modes: controller to IoT device, controller to cloud, and controller to controller. We present a proof of concept implementation using openHAB -- a device agnostic open source IoT device controller -- and self-created scripts, to resemble a FSAC implementation. Our proof of concept employed an Insteon IP Camera as a controller to device test, an Insteon Hub as a controller to controller test, and a nest thermostat for a a controller to cloud test. Our findings show that it is possible to practically pull forensically relevant state data from IoT devices. Future work and open research problems are shared.},
  isbn = {978-1-4503-5257-4},
  keywords = {Internet of Things,IoT controllers,IoT forensic challenges,IoT forensics framework,IoT research,IoT State acquisition,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\WM97Q72I\meffertForensicStateAcquisition2017.pdf}
}

@article{micheletAutomationDigitalForensics2023,
  title = {Automation for Digital Forensics: {{Towards}} a Definition for the Community},
  shorttitle = {Automation for Digital Forensics},
  author = {Michelet, Gaëtan and Breitinger, Frank and Horsman, Graeme},
  date = {2023-08-01},
  journaltitle = {Forensic Science International},
  shortjournal = {Forensic Science International},
  volume = {349},
  pages = {111769},
  issn = {0379-0738},
  doi = {10.1016/j.forsciint.2023.111769},
  url = {https://www.sciencedirect.com/science/article/pii/S0379073823002190},
  urldate = {2024-12-03},
  abstract = {Automation is crucial for managing the increasing volume of~digital~evidence. However, the absence of a clear foundation comprising a definition, classification, and common terminology has led to a fragmented landscape where diverse interpretations of automation exist.~This resembles the wild west: some consider keyword searches or file carving as automation while others do not. We, therefore, reviewed automation literature (in the domain of digital forensics and other domains), performed three practitioner interviews, and discussed the topic with domain experts from academia. On this basis, we propose a definition and then showcase several considerations concerning automation for digital forensics, e.g., what we classify as no/basic automation or full automation (autonomous). We conclude that it requires these foundational discussions to promote and progress the discipline through a common understanding.},
  keywords = {Automation,Definition,Digital Forensic investigation,Investigative task,Practitioner interviews},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\Q6TNK592\\micheletAutomationDigitalForensics2023.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\MCBTE9XQ\\S0379073823002190.html}
}

@software{MicrosoftPlaywrightpython2025,
  title = {Microsoft/Playwright-Python},
  date = {2025-02-05T22:30:43Z},
  origdate = {2020-07-01T15:28:13Z},
  url = {https://github.com/microsoft/playwright-python},
  urldate = {2025-02-05},
  abstract = {Python version of the Playwright testing and automation library.},
  organization = {Microsoft},
  keywords = {chromium,firefox,playwright,webkit}
}

@incollection{mochEvaluatingForensicImage2012,
  title = {Evaluating the {{Forensic Image Generator Generator}}},
  booktitle = {Digital {{Forensics}} and {{Cyber Crime}}},
  author = {Moch, Christian and Freiling, Felix C.},
  editor = {Gladyshev, Pavel and Rogers, Marcus K.},
  date = {2012},
  volume = {88},
  pages = {238--252},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-35515-8_20},
  url = {http://link.springer.com/10.1007/978-3-642-35515-8_20},
  urldate = {2023-11-26},
  isbn = {978-3-642-35514-1 978-3-642-35515-8},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\2GS7GZPS\mochEvaluatingForensicImage2012.pdf}
}

@inproceedings{mochForensicImageGenerator2009,
  title = {The {{Forensic Image Generator Generator}} ({{Forensig2}})},
  booktitle = {2009 {{Fifth International Conference}} on {{IT Security Incident Management}} and {{IT Forensics}}},
  author = {Moch, Christian and Freiling, Felix C.},
  date = {2009},
  pages = {78--93},
  publisher = {IEEE},
  location = {Stuttgart, Germany},
  doi = {10.1109/IMF.2009.8},
  url = {http://ieeexplore.ieee.org/document/5277859/},
  urldate = {2023-09-17},
  eventtitle = {2009 {{Fifth International Conference}} on {{IT Security Incident Management}} and {{IT Forensics}}},
  isbn = {978-0-7695-3807-5},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\CLH8CU3P\mochForensicImageGenerator2009.pdf}
}

@article{montasariRoadMapDigital2019,
  title = {A Road Map for Digital Forensics Research: A Novel Approach for Establishing the Design Science Research Process in Digital Forensics},
  shorttitle = {A Road Map for Digital Forensics Research},
  author = {Montasari, Reza and Carpenter, Victoria and Hill, Richard},
  date = {2019},
  journaltitle = {International Journal of Electronic Security and Digital Forensics},
  shortjournal = {IJESDF},
  volume = {11},
  number = {2},
  pages = {194},
  issn = {1751-911X, 1751-9128},
  doi = {10.1504/IJESDF.2019.098784},
  url = {http://www.inderscience.com/link.php?id=98784},
  urldate = {2023-12-02},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\MS5CV2XF\montasariRoadMapDigital2019.pdf}
}

@inproceedings{nagowahNovelApproachAutomation2012,
  title = {A Novel Approach of Automation Testing on Mobile Devices},
  booktitle = {2012 {{International Conference}} on {{Computer}} \& {{Information Science}} ({{ICCIS}})},
  author = {Nagowah, Leckraj and Sowamber, Gayeree},
  date = {2012-06},
  volume = {2},
  pages = {924--930},
  doi = {10.1109/ICCISci.2012.6297158},
  url = {https://ieeexplore.ieee.org/document/6297158},
  urldate = {2025-02-10},
  abstract = {Mobile phones and mobile applications have now become an integral part of our everyday life. Mobile application testing plays a pivotal role in making the mobile applications more reliable and defect free. Existing test automation tools have been tailored to perform mobile test automation through mobile emulators. Other tools require the mobile device where the application is installed, to be connected to a computer so that the tests can be run. Obviously, the results obtained from emulators often differ from those obtained on actual mobile devices. To our best knowledge only a few solutions for creating automated tests of mobile applications exist and their functionality is very limited. In this paper, we introduce the idea of implementing a mobile test automation framework MobTAF which performs mobile test automation on the mobile device where connection to a computer is not required. The framework moves the testing infrastructure to the phone, to support test situations that cannot easily be replicated with an emulator. A prototype application was then implemented to test the mobile automation framework, MobTAF. The results prove that MobTAF framework is an efficient way of performing mobile application tests directly on the mobile devices.},
  eventtitle = {2012 {{International Conference}} on {{Computer}} \& {{Information Science}} ({{ICCIS}})},
  keywords = {Automation,Generators,Layout,mobile application testing,Mobile communication,mobile device test automation,mobile test automation framework,mobile testing,Robustness,software testing,Testing,XML},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\WDY4ZQAJ\\nagowahNovelApproachAutomation2012.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\D6PBGTDW\\6297158.html}
}

@inproceedings{nanceDigitalForensicsDefining2009,
  title = {Digital {{Forensics}}: {{Defining}} a {{Research Agenda}}},
  shorttitle = {Digital {{Forensics}}},
  booktitle = {2009 42nd {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Nance, Kara and Hay, Brian and Bishop, Matt},
  date = {2009},
  pages = {1--6},
  publisher = {IEEE},
  location = {Waikoloa, Hawaii, USA},
  doi = {10.1109/HICSS.2009.160},
  url = {http://ieeexplore.ieee.org/document/4755787/},
  urldate = {2023-11-26},
  eventtitle = {2009 42nd {{Hawaii International Conference}} on {{System Sciences}}},
  isbn = {978-0-7695-3450-3},
  keywords = {research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\P5BSME2P\DigitalForensicsDefining2009.pdf}
}

@inproceedings{nanceDigitalForensicsDefining2010,
  title = {Digital {{Forensics}}: {{Defining}} an {{Education Agenda}}},
  shorttitle = {Digital {{Forensics}}},
  booktitle = {2010 43rd {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Nance, Kara and Armstrong, Helen and Armstrong, Colin},
  date = {2010-01},
  pages = {1--10},
  issn = {1530-1605},
  doi = {10.1109/HICSS.2010.151},
  url = {https://ieeexplore.ieee.org/document/5428493},
  urldate = {2023-11-27},
  abstract = {While many fields have well-defined education agendas, this is not the case for digital forensics. A unique characteristic of the evolution of digital forensics is that it has been largely driven by practitioners in the field. As a result, the majority of the educational experiences have been developed in response to identified weaknesses in the system or to train individuals on the use of a specific tool or technique, rather than as a result of educational needs assessments based on an accepted common body of knowledge. In June, 2008 a group of digital forensics researchers, educators and practitioners met as a working group at the Colloquium for Information Systems Security Education (CISSE 2008) to brainstorm ideas for the development of a research, education, and outreach agenda for Digital Forensics. This paper presents the research in education needs that the group identified associated with the development of a digital forensics education agenda.},
  eventtitle = {2010 43rd {{Hawaii International Conference}} on {{System Sciences}}},
  keywords = {research/image-purpose,research/image-purpose/education},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\BRWC9BWD\\nanceDigitalForensicsDefining2010.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\JLPFBF8K\\5428493.html}
}

@online{nationalinstituteofstandardsandtechnologyCFReDSDataLeakage,
  title = {{{CFReDS}} - {{Data Leakage Case}}},
  author = {{National Institute of Standards and Technology}},
  url = {https://cfreds-archive.nist.gov/data_leakage_case/data-leakage-case.html},
  urldate = {2023-12-04},
  organization = {CFReDS Archive},
  file = {C:\Users\Kisun\Zotero\storage\H8S5NZ5M\data-leakage-case.html}
}

@online{nationalinstituteofstandardsandtechnologyCFReDSPortal,
  title = {{{CFReDS Portal}}},
  author = {{National Institute of Standards and Technology}},
  url = {https://cfreds.nist.gov/},
  urldate = {2023-12-04},
  file = {C:\Users\Kisun\Zotero\storage\D44C426A\cfreds.nist.gov.html}
}

@online{nationalinstituteofstandardsandtechnologyComputerForensicsTool2017,
  title = {Computer {{Forensics Tool Testing Program}} ({{CFTT}})},
  author = {{National Institute of Standards and Technology}},
  date = {2017-05-08T09:29-04:00},
  url = {https://www.nist.gov/itl/ssd/software-quality-group/computer-forensics-tool-testing-program-cftt},
  urldate = {2023-12-04},
  abstract = {Welcome to the Computer Forensics Tool Testing (CFTT) Project Web Site.},
  langid = {english},
  organization = {NIST},
  annotation = {Last Modified: 2019-11-15T19:42-05:00},
  file = {C:\Users\Kisun\Zotero\storage\LUKSF3Q2\computer-forensics-tool-testing-program-cftt.html}
}

@report{nationalinstituteofstandardsandtechnologyNISTCybersecurityFramework2024,
  title = {The {{NIST Cybersecurity Framework}} ({{CSF}}) 2.0},
  author = {{National Institute of Standards and Technology}},
  date = {2024-02-26},
  number = {NIST CSWP 29},
  pages = {NIST CSWP 29},
  institution = {{National Institute of Standards and Technology}},
  location = {Gaithersburg, MD},
  doi = {10.6028/NIST.CSWP.29},
  url = {https://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.29.pdf},
  urldate = {2025-03-16},
  abstract = {The NIST Cybersecurity Framework (CSF) 2.0 provides guidance to industry, government agencies, and other organizations to manage cybersecurity risks. It offers a taxonomy of high-level cybersecurity outcomes that can be used by any organization — regardless of its size, sector, or maturity — to better understand, assess, prioritize, and communicate its cybersecurity efforts. The CSF does not prescribe how outcomes should be achieved. Rather, it links to resources that provide additional guidance on practices and controls that could be used to achieve those outcomes. This document explains CSF 2.0 and its components and describes some of the many ways that it can be used.},
  file = {C:\Users\Kisun\Zotero\storage\BA9T3327\nationalinstituteofstandardsandtechnologyNISTCybersecurityFramework2024.pdf}
}

@inproceedings{neyazForensicAnalysisWear2018,
  title = {Forensic {{Analysis}} of {{Wear Leveling}} on {{Solid-State Media}}},
  booktitle = {2018 17th {{IEEE International Conference On Trust}}, {{Security And Privacy In Computing And Communications}}/ 12th {{IEEE International Conference On Big Data Science And Engineering}} ({{TrustCom}}/{{BigDataSE}})},
  author = {Neyaz, Ashar and Shashidhar, Narasimha and Karabiyik, Umit},
  date = {2018-08},
  pages = {1706--1710},
  issn = {2324-9013},
  doi = {10.1109/TrustCom/BigDataSE.2018.00256},
  url = {https://ieeexplore.ieee.org/document/8456124},
  urldate = {2025-02-05},
  abstract = {Traditional hard drives are slowly becoming things of the past as newer technologies are constantly demanding lighter, faster, and more reliable alternatives. Solid-state media have started to permeate the market in an effort to satisfy this demand. Some tech giants have already started to use solid-state media in their products but are facing substantial price and storage capacity penalties. When it comes to performing forensic analysis on these solid-state media, the autonomous behavior of the media does not look promising as it has serious reliability issues compared to traditional media. With wear-leveling always enabled, the persistence of deleted data is always in question. The deleted data can stay on the media either partially or wholly and is dependent on various factors like the file system used on the media, capacity, manufacturer, software level TRIM functionality and also on the type of the operating system used. In this research, we analyzed different types of flash and solid-state media by filling them up with different types of files an conducted exhaustive experiments to identify the probability of recovering and file-carving once these files are deleted. The aim of this paper is to give a detailed analysis that will provide a benchmark for digital forensics investigators who are constantly troubled by the thought of analyzing solid-state media.},
  eventtitle = {2018 17th {{IEEE International Conference On Trust}}, {{Security And Privacy In Computing And Communications}}/ 12th {{IEEE International Conference On Big Data Science And Engineering}} ({{TrustCom}}/{{BigDataSE}})},
  keywords = {Computer science,Digital forensics,Drives,file carving,file recovery,Media,Operating systems,Reliability,Solid State Drive,SSD Forensics,TRIM function,wear leveling},
  file = {C:\Users\Kisun\Zotero\storage\D6RVUYWZ\neyazForensicAnalysisWear2018.pdf}
}

@software{OllamaOllama2025,
  title = {Ollama/Ollama},
  date = {2025-03-24T23:20:04Z},
  origdate = {2023-06-26T19:39:32Z},
  url = {https://github.com/ollama/ollama},
  urldate = {2025-03-24},
  abstract = {Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, and other large language models.},
  organization = {Ollama},
  keywords = {deepseek,gemma,gemma2,gemma3,go,golang,llama,llama2,llama3,llava,llm,llms,mistral,ollama,phi3,phi4,qwen}
}

@online{openaiComputerUsingAgent2025,
  title = {Computer-{{Using Agent}}},
  author = {{OpenAI}},
  date = {2025-01-23},
  url = {https://openai.com/index/computer-using-agent/},
  urldate = {2025-02-10},
  abstract = {A universal interface for AI to interact with the digital world.},
  langid = {american},
  organization = {OpenAI},
  file = {C:\Users\Kisun\Zotero\storage\DJTJ3UC5\computer-using-agent.html}
}

@online{openaiIntroducingOperator2025,
  title = {Introducing {{Operator}}},
  author = {{OpenAI}},
  date = {2025-01-23},
  url = {https://openai.com/index/introducing-operator/},
  urldate = {2025-02-10},
  abstract = {A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.},
  langid = {american},
  organization = {OpenAI},
  file = {C:\Users\Kisun\Zotero\storage\E7LNYDUJ\introducing-operator.html}
}

@article{ouyangEmpiricalStudyNonDeterminism2025,
  title = {An {{Empirical Study}} of the {{Non-Determinism}} of {{ChatGPT}} in {{Code Generation}}},
  author = {Ouyang, Shuyin and Zhang, Jie M. and Harman, Mark and Wang, Meng},
  date = {2025-01-22},
  journaltitle = {ACM Trans. Softw. Eng. Methodol.},
  volume = {34},
  number = {2},
  pages = {42:1--42:28},
  issn = {1049-331X},
  doi = {10.1145/3697010},
  url = {https://dl.acm.org/doi/10.1145/3697010},
  urldate = {2025-02-10},
  abstract = {There has been a recent explosion of research on Large Language Models (LLMs) for software engineering tasks, in particular code generation. However, results from LLMs can be highly unstable; non-deterministically returning very different code for the same prompt. Such non-determinism affects the correctness and consistency of the generated code, undermines developers’ trust in LLMs, and yields low reproducibility in LLM-based papers. Nevertheless, there is no work investigating how serious this non-determinism threat is.To fill this gap, this article conducts an empirical study on the non-determinism of ChatGPT in code generation. We chose to study ChatGPT because it is already highly prevalent in the code generation research literature. We report results from a study of 829 code generation problems across three code generation benchmarks (i.e., CodeContests, APPS and HumanEval) with three aspects of code similarities: semantic similarity, syntactic similarity, and structural similarity. Our results reveal that ChatGPT exhibits a high degree of non-determinism under the default setting: the ratio of coding tasks with zero equal test output across different requests is 75.76\%, 51.00\% and 47.56\% for three different code generation datasets (i.e., CodeContests, APPS and HumanEval), respectively. In addition, we find that setting the temperature to 0 does not guarantee determinism in code generation, although it indeed brings less non-determinism than the default configuration (temperature  \textbackslash (=\textbackslash )  1). In order to put LLM-based research on firmer scientific foundations, researchers need to take into account non-determinism in drawing their conclusions.},
  file = {C:\Users\Kisun\Zotero\storage\D9G8WL2B\ouyangEmpiricalStudyNonDeterminism2025.pdf}
}

@inproceedings{palmerRoadMapDigital2001,
  title = {A {{Road Map}} for {{Digital Forensic Research}}},
  booktitle = {The {{Digital Forensic Research Conference}}},
  author = {Palmer, Gary and {The MITRE Corporation}},
  date = {2001-11-06},
  location = {Utica, NY},
  url = {https://dfrws.org/wp-content/uploads/2019/06/2001_USA_a_road_map_for_digital_forensic_research.pdf},
  urldate = {2023-12-02},
  eventtitle = {{{DFRWS}} 2001 {{USA}}},
  file = {C:\Users\Kisun\Zotero\storage\6AF68JSP\palmerRoadMapDigital2001.pdf}
}

@article{parkTREDEVMPOPCultivating2018,
  title = {{{TREDE}} and {{VMPOP}}: {{Cultivating}} Multi-Purpose Datasets for Digital Forensics – {{A Windows}} Registry Corpus as an Example},
  shorttitle = {{{TREDE}} and {{VMPOP}}},
  author = {Park, Jungheum},
  date = {2018-09},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {26},
  pages = {3--18},
  issn = {17422876},
  doi = {10.1016/j.diin.2018.04.025},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287617303614},
  urldate = {2023-09-17},
  langid = {english},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\MBUN7T26\parkTREDEVMPOPCultivating2018.pdf}
}

@article{pessolanoForensicAnalysisNintendo2019,
  title = {Forensic {{Analysis}} of the {{Nintendo 3DS NAND}}},
  author = {Pessolano, Gus and Read, Huw O.L. and Sutherland, Iain and Xynos, Konstantinos},
  date = {2019-07},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  volume = {29},
  pages = {S61-S70},
  issn = {17422876},
  doi = {10.1016/j.diin.2019.04.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1742287619301641},
  urldate = {2023-12-04},
  abstract = {Games consoles present a particular challenge to the forensics investigator due to the nature of the hardware and the inaccessibility of the file system. Many protection measures are put in place to make it deliberately difficult to access raw data in order to protect intellectual property, enhance digital rights management of software and, ultimately, to protect against piracy. History has shown that many such protections on game consoles are circumvented with exploits leading to jailbreaking/rooting and allowing unauthorized software to be launched on the games system. This paper details methods that enable the investigator to extract system activity, deleted images, Internet history items, relevant friends list information, the console's serial number and plaintext WiFi access point passwords. This is all possible with the use of publicly available, open-source security circumvention techniques that perform a non-invasive physical dump of the internal NAND storage of the Nintendo 3DS handheld device. It will also be shown that forensic integrity is maintained and a detailed analysis is possible without altering original evidence.},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\4CWIQBAZ\pessolanoForensicAnalysisNintendo2019.pdf}
}

@online{podellSDXLImprovingLatent2023,
  title = {{{SDXL}}: {{Improving Latent Diffusion Models}} for {{High-Resolution Image Synthesis}}},
  shorttitle = {{{SDXL}}},
  author = {Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and Müller, Jonas and Penna, Joe and Rombach, Robin},
  date = {2023-07-04},
  eprint = {2307.01952},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.01952},
  url = {http://arxiv.org/abs/2307.01952},
  urldate = {2025-03-24},
  abstract = {We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. In the spirit of promoting open research and fostering transparency in large model training and evaluation, we provide access to code and model weights at https://github.com/Stability-AI/generative-models},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\K7YMT2GG\\podellSDXLImprovingLatent2023.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\ACDAYSYD\\2307.html}
}

@incollection{pollittHistoryDigitalForensics2010,
  title = {A {{History}} of {{Digital Forensics}}},
  booktitle = {Advances in {{Digital Forensics VI}}},
  author = {Pollitt, Mark},
  editor = {Chow, Kam-Pui and Shenoi, Sujeet},
  date = {2010},
  volume = {337},
  pages = {3--15},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15506-2_1},
  url = {http://link.springer.com/10.1007/978-3-642-15506-2_1},
  urldate = {2023-12-03},
  isbn = {978-3-642-15505-5 978-3-642-15506-2},
  file = {C:\Users\Kisun\Zotero\storage\AZIT7SQV\pollittHistoryDigitalForensics2010.pdf}
}

@online{pshenichkinYouThinkYou2024,
  title = {So You Think You Want to Write a Deterministic Hypervisor?},
  author = {Pshenichkin, Alex},
  date = {2024-03-20},
  url = {https://antithesis.com/blog/deterministic_hypervisor/},
  urldate = {2025-02-22},
  abstract = {What is a deterministic hypervisor and why do we need one anyhow?},
  langid = {english},
  organization = {Antithesis},
  file = {C:\Users\Kisun\Zotero\storage\2ENYUSTU\deterministic_hypervisor.html}
}

@software{Py4n6Pytsk2025,
  title = {Py4n6/Pytsk},
  date = {2025-02-25T09:44:55Z},
  origdate = {2014-12-22T06:54:49Z},
  url = {https://github.com/py4n6/pytsk},
  urldate = {2025-02-26},
  abstract = {Python bindings for The Sleuth Kit (libtsk)},
  organization = {py4n6}
}

@software{PyCQAFlake82025,
  title = {{{PyCQA}}/Flake8},
  date = {2025-03-06T10:58:02Z},
  origdate = {2014-09-13T17:06:24Z},
  url = {https://github.com/PyCQA/flake8},
  urldate = {2025-03-08},
  abstract = {flake8 is a python tool that glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of some python code.},
  organization = {Python Code Quality Authority},
  keywords = {complexity-analysis,flake8,linter,linter-flake8,pep8,python,python3,static-analysis,static-code-analysis,style-guide,styleguide,stylelint}
}

@software{PyCQAIsort2025,
  title = {{{PyCQA}}/Isort},
  date = {2025-03-07T23:33:22Z},
  origdate = {2013-09-02T22:22:53Z},
  url = {https://github.com/PyCQA/isort},
  urldate = {2025-03-08},
  abstract = {A Python utility / library to sort imports.},
  organization = {Python Code Quality Authority},
  keywords = {auto-formatter,cleaner,cli,formatter,hacktoberfest,isort,linter,python,python-utility,python3,sorting-imports}
}

@software{PyFilesystemPyfilesystem22025,
  title = {{{PyFilesystem}}/Pyfilesystem2},
  date = {2025-03-04T07:12:39Z},
  origdate = {2016-10-14T15:05:27Z},
  url = {https://github.com/PyFilesystem/pyfilesystem2},
  urldate = {2025-03-05},
  abstract = {Python's Filesystem abstraction layer},
  organization = {pyFilesystem},
  keywords = {filesystem,filesystem-library,ftp,pyfilesystem,pyfilesystem2,python,tar,zip}
}

@software{PyinstallerPyinstaller2025,
  title = {Pyinstaller/Pyinstaller},
  date = {2025-02-21T16:25:55Z},
  origdate = {2011-11-23T11:05:56Z},
  url = {https://github.com/pyinstaller/pyinstaller},
  urldate = {2025-02-22},
  abstract = {Freeze (package) Python programs into stand-alone executables},
  organization = {PyInstaller},
  keywords = {bundle,package,py2app,py2exe,pyinstaller,python,python-3,python-to-exe}
}

@software{PythonMypy2025,
  title = {Python/Mypy},
  date = {2025-03-08T05:08:11Z},
  origdate = {2012-12-07T13:30:23Z},
  url = {https://github.com/python/mypy},
  urldate = {2025-03-08},
  abstract = {Optional static typing for Python},
  organization = {Python},
  keywords = {linter,python,typechecker,types,typing}
}

@article{rahmanNewWebForensic2020,
  title = {A New Web Forensic Framework for Bot Crime Investigation},
  author = {Rahman, Rizwan Ur and Tomar, Deepak Singh},
  date = {2020-06-01},
  journaltitle = {Forensic Science International: Digital Investigation},
  shortjournal = {Forensic Science International: Digital Investigation},
  volume = {33},
  pages = {300943},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2020.300943},
  url = {https://www.sciencedirect.com/science/article/pii/S2666281720300718},
  urldate = {2023-08-31},
  abstract = {Bots are automated programs that robotically navigate the website, upload the data on servers and scrape the data from websites. According to numerous bot traffic reports nearly fifty percent of the website traffic is coming from automated programs. In recent years we have seen a rise in cyber crimes such as illegal web scraping using automated bots. Facebook filed and won a case against Power.com for illegally scraping the Facebook data. Recently in one of the biggest online ticketing scams, a man was arrested for illegally booking tickets using automated bots. While mitigating cyber crime, web forensic investigators face numerous challenges and issues dealing with bot crimes. Most of the existing research is based on web access logs which contain very basic and limited information. In this paper, we propose four phase web forensic framework to guide forensic examiners in their expedition to verify if the crime is done using automated bots. In order to evaluate the proposed framework, we applied it to the real web application and experimental case scenario. For this case study, a bot crime scenario is developed in an investigation environment. Subsequently, we present in depth forensic procedures and technical reports for bot crime investigation.},
  keywords = {Cyber crime,Forensic framework,research/image-sources,Spam bot,Web bot,Web forensic,Web scrapping},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8CU55B8B\\rahmanNewWebForensic2020.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\5KH74GY9\\S2666281720300718.html}
}

@online{Requests31Documentation,
  title = {Requests 2.31.0 Documentation},
  url = {https://requests.readthedocs.io/en/latest/},
  urldate = {2023-12-05},
  file = {C:\Users\Kisun\Zotero\storage\LG22AJL8\latest.html}
}

@inproceedings{ricanekMORPHLongitudinalImage2006,
  title = {{{MORPH}}: A Longitudinal Image Database of Normal Adult Age-Progression},
  shorttitle = {{{MORPH}}},
  booktitle = {7th {{International Conference}} on {{Automatic Face}} and {{Gesture Recognition}} ({{FGR06}})},
  author = {Ricanek, K. and Tesafaye, T.},
  date = {2006-04},
  pages = {341--345},
  doi = {10.1109/FGR.2006.78},
  url = {https://ieeexplore.ieee.org/document/1613043},
  urldate = {2025-03-05},
  abstract = {This paper details MORPH a longitudinal face database developed for researchers investigating all facets of adult age-progression, e.g. face modeling, photo-realistic animation, face recognition, etc. This database contributes to several active research areas, most notably face recognition, by providing: the largest set of publicly available longitudinal images; longitudinal spans from a few months to over twenty years; and, the inclusion of key physical parameters that affect aging appearance. The direct contribution of this data corpus for face recognition is highlighted in the evaluation of a standard face recognition algorithm, which illustrates the impact that age-progression, has on recognition rates. Assessment of the efficacy of this algorithm is evaluated against the variables of gender and racial origin. This work further concludes that the problem of age-progression on face recognition (FR) is not unique to the algorithm used in this work.},
  eventtitle = {7th {{International Conference}} on {{Automatic Face}} and {{Gesture Recognition}} ({{FGR06}})},
  keywords = {Aging,Biometrics,Computer science,Cranial,Face recognition,Facial animation,Humans,Image databases,Morphology,Skin},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\BIEIHR4S\\ricanekMORPHLongitudinalImage2006.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\NAYPYGXG\\1613043.html}
}

@report{robertkominskiComputerUseUnited1988,
  type = {Current Population Reports},
  title = {Computer {{Use}} in the {{United States}}: 1984},
  author = {{Robert Kominski}},
  date = {1988-03},
  number = {155},
  institution = {U.S. Bureau of the Census},
  location = {Washington, D.C.},
  url = {https://www.census.gov/history/pdf/computerusage1984.pdf},
  file = {C:\Users\Kisun\Zotero\storage\SR5VE4XK\robertkominskiComputerUseUnited1988.pdf}
}

@report{robertkominskiComputerUseUnited1991,
  type = {Current Population Reports},
  title = {Computer {{Use}} in the {{United States}}: 1989},
  author = {{Robert Kominski}},
  date = {1991-02},
  number = {171},
  institution = {U.S. Bureau of the Census},
  location = {Washington, D.C.},
  url = {https://www.census.gov/history/pdf/computerusage1984.pdf},
  file = {C:\Users\Kisun\Zotero\storage\8LAX9HYB\robertkominskiComputerUseUnited1991.pdf}
}

@article{rooseAIgeneratedPictureWon2022,
  entrysubtype = {newspaper},
  title = {An {{AI-generated}} Picture Won an Art Prize. {{Artists}} Aren’t Happy},
  author = {Roose, Kevin},
  date = {2022-09-02},
  journaltitle = {The New York Times},
  url = {https://cs.uwaterloo.ca/~jhoey/teaching/cogsci600/papers/Roose2022.pdf},
  file = {C:\Users\Kisun\Zotero\storage\SYZJK5IK\rooseAIgeneratedPictureWon2022.pdf}
}

@article{russellForensicImageDescription2012,
  title = {A {{Forensic Image Description Language}} for {{Generating Test Images}}},
  author = {Russell, Dr Gordon and Macfarlane, Rich and Ludwiniak, Robert},
  date = {2012},
  abstract = {Digital Forensics is a fast developing job market, as well as being topical and interesting, and as such is an area in which University students are keen to develop and study. At Edinburgh Napier University this topic has been taught with flexible and distance learning students in mind, and to promote accessibility the practical exercises have been formed around the use of cloud-based technologies. This approach has highlighted a key issue, in that cost-effective cloud-based resources struggle to provide adequate CPU and IO capabilities to drive large simultaneous student numbers when performing forensic exercises on disk images created using physical disk acquisition techniques obtained from real systems. This paper considers the issue, and proposes a simplistic and easily reconfigurable image creation technique specifically designed to support digital forensic practical sessions.},
  langid = {english},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\57MYGQDE\russellForensicImageDescription2012.pdf}
}

@article{scanlonEviPlantEfficientDigital2017,
  title = {{{EviPlant}}: {{An}} Efficient Digital Forensic Challenge Creation, Manipulation and Distribution Solution},
  shorttitle = {{{EviPlant}}},
  author = {Scanlon, Mark and Du, Xiaoyu and Lillis, David},
  date = {2017-03-01},
  journaltitle = {Digital Investigation},
  shortjournal = {Digital Investigation},
  series = {{{DFRWS}} 2017 {{Europe}}},
  volume = {20},
  pages = {S29-S36},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2017.01.010},
  url = {https://www.sciencedirect.com/science/article/pii/S1742287617300397},
  urldate = {2023-08-31},
  abstract = {Education and training in digital forensics requires a variety of suitable challenge corpora containing realistic features including regular wear-and-tear, background noise, and the actual digital traces to be discovered during investigation. Typically, the creation of these challenges requires overly arduous effort on the part of the educator to ensure their viability. Once created, the challenge image needs to be stored and distributed to a class for practical training. This storage and distribution step requires significant time and resources and may not even be possible in an online/distance learning scenario due to the data sizes involved. As part of this paper, we introduce a more capable methodology and system as an alternative to current approaches. EviPlant is a system designed for the efficient creation, manipulation, storage and distribution of challenges for digital forensics education and training. The system relies on the initial distribution of base disk images, i.e., images containing solely base operating systems. In order to create challenges for students, educators can boot the base system, emulate the desired activity and perform a “diffing” of resultant image and the base image. This diffing process extracts the modified artefacts and associated metadata and stores them in an “evidence package”. Evidence packages can be created for different personae, different wear-and-tear, different emulated crimes, etc., and multiple evidence packages can be distributed to students and integrated into the base images. A number of additional applications in digital forensic challenge creation for tool testing and validation, proficiency testing, and malware analysis are also discussed as a result of using EviPlant.},
  keywords = {Digital forensic challenges,Digital forensics education,Evidence injection,Forensic corpora,research/synthesizer-details,Tool testing and validation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\UQ5CNFNK\\scanlonEviPlantEfficientDigital2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\T82A8JQS\\S1742287617300397.html}
}

@software{SeleniumHQSelenium2025,
  title = {{{SeleniumHQ}}/Selenium},
  date = {2025-03-05T03:30:14Z},
  origdate = {2013-01-14T21:40:56Z},
  url = {https://github.com/SeleniumHQ/selenium},
  urldate = {2025-03-05},
  abstract = {A browser automation framework and ecosystem.},
  organization = {Selenium},
  keywords = {dotnet,java,javascript,python,ruby,rust,selenium,webdriver}
}

@software{SleuthkitSleuthkit2025,
  title = {Sleuthkit/Sleuthkit},
  date = {2025-02-26T06:13:22Z},
  origdate = {2011-10-12T14:26:49Z},
  url = {https://github.com/sleuthkit/sleuthkit},
  urldate = {2025-02-26},
  abstract = {The Sleuth Kit® (TSK) is a library and collection of command line digital forensics tools that allow you to investigate volume and file system data. The library can be incorporated into larger digital forensics tools and the command line tools can be directly used to find evidence.},
  organization = {The Sleuth Kit},
  keywords = {forensics,incident-response,ntfs,sleuthkit,tct}
}

@online{songGoodBadGreedy2024,
  title = {The {{Good}}, {{The Bad}}, and {{The Greedy}}: {{Evaluation}} of {{LLMs Should Not Ignore Non-Determinism}}},
  shorttitle = {The {{Good}}, {{The Bad}}, and {{The Greedy}}},
  author = {Song, Yifan and Wang, Guoyin and Li, Sujian and Lin, Bill Yuchen},
  date = {2024-07-15},
  eprint = {2407.10457},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.10457},
  url = {http://arxiv.org/abs/2407.10457},
  urldate = {2025-02-10},
  abstract = {Current evaluations of large language models (LLMs) often overlook non-determinism, typically focusing on a single output per example. This limits our understanding of LLM performance variability in real-world applications. Our study addresses this issue by exploring key questions about the performance differences between greedy decoding and sampling, identifying benchmarks' consistency regarding non-determinism, and examining unique model behaviors. Through extensive experiments, we observe that greedy decoding generally outperforms sampling methods for most evaluated tasks. We also observe consistent performance across different LLM sizes and alignment methods, noting that alignment can reduce sampling variance. Moreover, our best-of-N sampling approach demonstrates that smaller LLMs can match or surpass larger models such as GPT-4-Turbo, highlighting the untapped potential of smaller LLMs. This research shows the importance of considering non-determinism in LLM evaluations and provides insights for future LLM development and evaluation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\7N2ZMTZJ\\songGoodBadGreedy2024.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\2MP7XDCX\\2407.html}
}

@article{srinivasanDigitalForensicsCurriculum2013,
  title = {Digital Forensics Curriculum in Security Education},
  author = {Srinivasan, S},
  date = {2013},
  journaltitle = {Journal of Information Technology Education. Innovations in Practice},
  volume = {12},
  pages = {147},
  publisher = {Informing Science Institute},
  file = {C:\Users\Kisun\Zotero\storage\Z6N6IKC8\srinivasanDigitalForensicsCurriculum2013.pdf}
}

@article{sutiknoCapabilitiesCellebriteUniversal2024,
  title = {Capabilities of Cellebrite Universal Forensics Extraction Device in Mobile Device Forensics},
  author = {Sutikno, Tole and Busthomi, Iqbal},
  date = {2024-11-01},
  journaltitle = {Computer Science and Information Technologies},
  volume = {5},
  number = {3},
  pages = {254--264},
  issn = {2722-3221},
  doi = {10.11591/csit.v5i3.p254-264},
  url = {https://www.iaesprime.com/index.php/csit/article/view/459},
  urldate = {2025-02-10},
  abstract = {The powerful digital forensics tool cellebrite universal forensics extraction device (UFED) extracts and analyzes mobile device data, helping investigators solve criminal and cybersecurity cases. Advanced methods and algorithms allow Cellebrite UFED to recover data from erased or obscured devices. Cellebrite UFED can pull data from call logs, texts, emails, and social media, providing valuable evidence for investigations. The use of smartphones and tablets in personal and professional settings has spurred the development of mobile device forensics. The intuitive user interface speeds up data extraction and analysis, revealing crucial information. It can decrypt encrypted data, recover deleted files, and extract data from multiple devices. The sector's best data extraction functionality, Cellebrite UFED, helps forensic analysts gather crucial evidence for investigations. Legal and ethical considerations are crucial in mobile device forensics. Legal considerations include allowing access to data, protecting privacy, and adhering to chain of custody protocols. Ethics include transparency, defamation, and information exploitation protection. Using Cellebrite UFED, researchers can navigate complex data on mobile devices more efficiently and precisely. Artificial intelligence (AI) and machine learning (ML) algorithms may automate data extraction in future tools. Examiners must train, maintain, and establish clear protocols for using Cellebrite UFED in forensic investigations.},
  issue = {3},
  langid = {english},
  keywords = {Cellebrite universal forensics extraction device,Cybersecurity,Digital forensics,Forensic analysts,Forensic investigation,Mobile device forensics},
  file = {C:\Users\Kisun\Zotero\storage\JRHZJZJ6\sutiknoCapabilitiesCellebriteUniversal2024.pdf}
}

@software{sweigartAsweigartPyautogui2025,
  title = {Asweigart/Pyautogui},
  author = {Sweigart, Al},
  date = {2025-03-05T05:43:11Z},
  origdate = {2014-07-17T23:30:38Z},
  url = {https://github.com/asweigart/pyautogui},
  urldate = {2025-03-05},
  abstract = {A cross-platform GUI automation Python module for human beings. Used to programmatically control the mouse \& keyboard.}
}

@software{sweigartAsweigartPyautogui2025a,
  title = {Asweigart/Pyautogui},
  author = {Sweigart, Al},
  date = {2025-03-27T19:47:43Z},
  origdate = {2014-07-17T23:30:38Z},
  url = {https://github.com/asweigart/pyautogui},
  urldate = {2025-03-28},
  abstract = {A cross-platform GUI automation Python module for human beings. Used to programmatically control the mouse \& keyboard.}
}

@online{TheoryOperationRPyC,
  title = {Theory of {{Operation}} — {{RPyC}}},
  url = {https://rpyc.readthedocs.io/en/latest/docs/theory.html#theory},
  urldate = {2025-02-06},
  file = {C:\Users\Kisun\Zotero\storage\FVVJP4K3\theory.html}
}

@software{TomerfilibaorgRpyc2025,
  title = {Tomerfiliba-Org/Rpyc},
  date = {2025-02-05T06:56:20Z},
  origdate = {2009-03-08T11:23:29Z},
  url = {https://github.com/tomerfiliba-org/rpyc},
  urldate = {2025-02-05},
  abstract = {RPyC (Remote Python Call) - A transparent and symmetric RPC library for python},
  organization = {tomerfiliba-org}
}

@software{UcoProjectUCO2025,
  title = {{{ucoProject}}/{{UCO}}},
  date = {2025-02-16T20:37:51Z},
  origdate = {2016-04-14T17:38:13Z},
  url = {https://github.com/ucoProject/UCO},
  urldate = {2025-03-09},
  abstract = {This repository is for development of the Unified Cyber Ontology.},
  organization = {ucoProject}
}

@software{UcoProjectUCODevelop2002025,
  title = {{{ucoProject}}/{{UCO}}:Develop-2.0.0},
  date = {2025-02-16T20:37:51Z},
  origdate = {2016-04-14T17:38:13Z},
  url = {https://github.com/ucoProject/UCO/tree/develop-2.0.0},
  urldate = {2025-03-06},
  abstract = {This repository is for development of the Unified Cyber Ontology.},
  organization = {ucoProject}
}

@incollection{vistiAutomaticCreationComputer2015,
  title = {Automatic {{Creation}} of {{Computer Forensic Test Images}}},
  booktitle = {Computational {{Forensics}}},
  author = {Visti, Hannu and Tohill, Sean and Douglas, Paul},
  editor = {Garain, Utpal and Shafait, Faisal},
  date = {2015},
  volume = {8915},
  pages = {163--175},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-20125-2_14},
  url = {https://link.springer.com/10.1007/978-3-319-20125-2_14},
  urldate = {2023-09-17},
  isbn = {978-3-319-20124-5 978-3-319-20125-2},
  langid = {english},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\T3LUHK5Z\vistiAutomaticCreationComputer2015.pdf}
}

@software{VmwarePyvmomi2025,
  title = {Vmware/Pyvmomi},
  date = {2025-02-07T20:11:50Z},
  origdate = {2013-12-13T17:30:30Z},
  url = {https://github.com/vmware/pyvmomi},
  urldate = {2025-02-10},
  abstract = {VMware vSphere API Python Bindings},
  organization = {VMware}
}

@software{volatilityfoundationVolatility32025,
  title = {Volatility 3},
  author = {{Volatility Foundation}},
  date = {2025-03-06T01:56:26Z},
  origdate = {2014-01-26T18:09:20Z},
  url = {https://github.com/volatilityfoundation/volatility3},
  urldate = {2025-03-06},
  abstract = {Volatility 3.0 development}
}

@software{waglerWandmalfarbePandoclatextemplate2025,
  title = {Wandmalfarbe/Pandoc-Latex-Template},
  author = {Wagler, Pascal},
  date = {2025-03-14T22:03:44Z},
  origdate = {2017-02-20T14:17:22Z},
  url = {https://github.com/Wandmalfarbe/pandoc-latex-template},
  urldate = {2025-03-15},
  abstract = {A pandoc LaTeX template to convert markdown files to PDF or LaTeX.},
  keywords = {eisvogel,koma-script,latex,latex-template,markdown,markdown-to-pdf,pandoc,pandoc-template,pandoc-templates,pdf,pdf-generation,tex}
}

@article{williamCloudbasedDigitalForensics2011,
  title = {Cloud-Based Digital Forensics Evaluation Test ({{D-FET}}) Platform.},
  author = {William, Prof and Buchanan, William and Macfarlane, Richard and Flandrin, Flavien and Graves, Jamie and Buchanan, Bill and Computers, Dell and Lu, Dr and Ekonomou, Elias and Bose, Niladri and Ludwiniak, Robert},
  date = {2011-01-01},
  abstract = {This paper outlines the specification of the Cloud-based D-FET platform which is used to evaluate the performance of digital foren-sics tools, which aim to detect the presence of trails of evidence, such as for the presence of illicit images and determination of user accounts from a host. Along with measuring key quality metrics, such as true-positives, and false-positives, it also measures operational performance, such as for the speed of success, CPU utilization and memory usage. This is used to determine the basic footprint of the package-under-test. The paper presents a proof-of-concept of the system using the VMware vSphere Hypervisor (ESXi) within the vCenter Cloud management in-frastructure, which provides a cluster environment, and supports the cre-ation and instantiation of a well-defined virtual test operation system. The infrastructure has been used within a teaching environment for two semesters, and has been shown to cope well in terms of performance and administration. Two key evaluation points related to whether a cloud-based infrastructure will provide improvement on existing stand-alone and workstation-based virtualisation are related to the improvement in energy consumption and in the CPU utilization footprint for each virtual machine. Thus the results show some metrics related to the energy and CPU consumptions of the created digital forensics instances, which can be used to justify the improvements in energy consumption, as opposed to stand-alone instances, and in the scalability of the infrastructure.},
  keywords = {research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\S6483Q2Q\William et al. - 2011 - Cloud-based digital forensics evaluation test (D-F.pdf}
}

@article{withersj.ElectronicallyStoredInformation2006,
  title = {Electronically {{Stored Information}}: {{The December}} 2006 {{Amendments}} to the {{Federal Rules}} of {{Civil Procedure}}},
  author = {Withers J., Kenneth},
  date = {2006},
  journaltitle = {Northwestern Journal of Technology and Intellectual Property},
  volume = {4},
  number = {2},
  pages = {171},
  url = {https://web.archive.org/web/20120321221012/http://www.law.northwestern.edu/journals/njtip/v4/n2/3/},
  file = {C:\Users\Kisun\Zotero\storage\3XSI9JBC\withersj.ElectronicallyStoredInformation2006.pdf}
}

@software{wittPoorBillionaireWindowsPrefetchParser2025,
  title = {{{PoorBillionaire}}/{{Windows-Prefetch-Parser}}},
  author = {Witt, Adam},
  date = {2025-01-27T16:33:48Z},
  origdate = {2015-11-12T07:05:19Z},
  url = {https://github.com/PoorBillionaire/Windows-Prefetch-Parser},
  urldate = {2025-03-28},
  abstract = {Parse Windows Prefetch files: Supports XP - Windows 10 Prefetch files}
}

@article{woodsCreatingRealisticCorpora2011,
  title = {Creating {{Realistic Corpora}} for {{Security}} and {{Forensic Education}}},
  author = {Woods, Kam and Lee, Christopher and Garfinkel, Simson and Dittrich, David and Russell, Adam and Kearton, Kris},
  date = {2011-01-01},
  journaltitle = {Proceedings of the ADFSL Conference on Digital Forensics Security and Law},
  shortjournal = {Proceedings of the ADFSL Conference on Digital Forensics Security and Law},
  abstract = {We present work on the design, implementation, distribution, and use of realistic forensic datasets to support digital forensics and security education. We describe in particular the "M57-Patents" scenario, a multi-modal corpus consisting of hard drive images, RAM images, network captures, and images from other devices typically found in forensics investigations such as USB drives and cellphones. Corpus creation has been performed as part of a scripted scenario; subsequently it is less "noisy" than real-world data but retains the complexity necessary to support a wide variety of forensic education activities. Realistic forensic corpora allow direct comparison of approaches and tools across classrooms and institutions, reduce the time required to prepare useful educational materials, and eliminate concerns of exposing students to privacy-sensitive or illegal digital materials. The "M57-Patents" corpus can be freely redistributed without rights-restricted materials, and is available with disk images packaged in both open (Advanced Forensic Format) and commercial (EnCase) formats.},
  keywords = {research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\LF9G9FS9\woodsCreatingRealisticCorpora2011.pdf}
}

@online{xieOSWorldBenchmarkingMultimodal2024,
  title = {{{OSWorld}}: {{Benchmarking Multimodal Agents}} for {{Open-Ended Tasks}} in {{Real Computer Environments}}},
  shorttitle = {{{OSWorld}}},
  author = {Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh Jing and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and Liu, Yitao and Xu, Yiheng and Zhou, Shuyan and Savarese, Silvio and Xiong, Caiming and Zhong, Victor and Yu, Tao},
  date = {2024-05-30},
  eprint = {2404.07972},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.07972},
  url = {http://arxiv.org/abs/2404.07972},
  urldate = {2025-02-10},
  abstract = {Autonomous agents that accomplish complex computer tasks with minimal human interventions have the potential to transform human-computer interaction, significantly enhancing accessibility and productivity. However, existing benchmarks either lack an interactive environment or are limited to environments specific to certain applications or domains, failing to reflect the diverse and complex nature of real-world computer use, thereby limiting the scope of tasks and agent scalability. To address this issue, we introduce OSWorld, the first-of-its-kind scalable, real computer environment for multimodal agents, supporting task setup, execution-based evaluation, and interactive learning across various operating systems such as Ubuntu, Windows, and macOS. OSWorld can serve as a unified, integrated computer environment for assessing open-ended computer tasks that involve arbitrary applications. Building upon OSWorld, we create a benchmark of 369 computer tasks involving real web and desktop apps in open domains, OS file I/O, and workflows spanning multiple applications. Each task example is derived from real-world computer use cases and includes a detailed initial state setup configuration and a custom execution-based evaluation script for reliable, reproducible evaluation. Extensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld reveals significant deficiencies in their ability to serve as computer assistants. While humans can accomplish over 72.36\% of the tasks, the best model achieves only 12.24\% success, primarily struggling with GUI grounding and operational knowledge. Comprehensive analysis using OSWorld provides valuable insights for developing multimodal generalist agents that were not possible with previous benchmarks. Our code, environment, baseline models, and data are publicly available at https://os-world.github.io.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\BHYZ94EC\\xieOSWorldBenchmarkingMultimodal2024.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\C4UBDASZ\\2404.html}
}

@inproceedings{xuDesigningSharedDigital2022,
  title = {Towards {{Designing Shared Digital Forensics Instructional Materials}}},
  booktitle = {2022 {{IEEE}} 46th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  author = {Xu, Weifeng and Deng, Lin and Xu, Dianxiang},
  date = {2022-06},
  pages = {117--122},
  issn = {0730-3157},
  doi = {10.1109/COMPSAC54236.2022.00025},
  url = {https://ieeexplore.ieee.org/document/9842462},
  urldate = {2023-11-27},
  abstract = {This paper presents a systematic approach to designing a series of digital forensics instructional materials to address the severe shortage of active learning materials in the digital forensics community. The materials include real-world scenario-based case studies, a set of hands-on problem-driven labs for each case study, and an integrated forensic investigation environment. In this paper, we first clarify some fundamental concepts related to digital forensics, such as digital forensic artifacts, artifact generators, and evidence. We then re-categorize knowledge units of digital forensics based on the artifact generators for measuring the coverage of learning outcomes and topics. Finally, we utilize a real-world cybercrime scenario to demonstrate how knowledge units, digital forensics topics, concepts, artifacts, and investigation tools can be infused into each lab through active learning. The repository of the instructional materials is publicly available on GitHub. It has gained nearly 600 stars and 22k views within several months.},
  eventtitle = {2022 {{IEEE}} 46th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  keywords = {research/image-purpose,research/image-purpose/education},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\LQPESEMY\\xuDesigningSharedDigital2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\4DBTMYX2\\9842462.html}
}

@inproceedings{yannikosDataCorporaDigital2014,
  title = {Data {{Corpora}} for {{Digital Forensics Education}} and {{Research}}},
  booktitle = {Advances in {{Digital Forensics X}}},
  author = {Yannikos, York and Graner, Lukas and Steinebach, Martin and Winter, Christian},
  editor = {Peterson, Gilbert and Shenoi, Sujeet},
  date = {2014},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {309--325},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-44952-3_21},
  abstract = {Data corpora are very important for digital forensics education and research. Several corpora are available to academia; these range from small manually-created data sets of a few megabytes to many terabytes of real-world data. However, different corpora are suited to different forensic tasks. For example, real data corpora are often desirable for testing forensic tool properties such as effectiveness and efficiency, but these corpora typically lack the ground truth that is vital to performing proper evaluations. Synthetic data corpora can support tool development and testing, but only if the methodologies for generating the corpora guarantee data with realistic properties.},
  isbn = {978-3-662-44952-3},
  langid = {english},
  keywords = {Forensic data corpora,model-based simulation,research/image-purpose,research/image-sources,research/synthesizer-details,synthetic disk images},
  file = {C:\Users\Kisun\Zotero\storage\IM7Y7AW2\yannikosDataCorporaDigital2014.pdf}
}

@inproceedings{yitbarekColdBootAttacks2017,
  title = {Cold {{Boot Attacks}} Are {{Still Hot}}: {{Security Analysis}} of {{Memory Scramblers}} in {{Modern Processors}}},
  shorttitle = {Cold {{Boot Attacks}} Are {{Still Hot}}},
  booktitle = {2017 {{IEEE International Symposium}} on {{High Performance Computer Architecture}} ({{HPCA}})},
  author = {Yitbarek, Salessawi Ferede and Aga, Misiker Tadesse and Das, Reetuparna and Austin, Todd},
  date = {2017-02},
  pages = {313--324},
  issn = {2378-203X},
  doi = {10.1109/HPCA.2017.10},
  url = {https://ieeexplore.ieee.org/document/7920835},
  urldate = {2025-02-11},
  abstract = {Previous work has demonstrated that systems with unencrypted DRAM interfaces are susceptible to cold boot attacks - where the DRAM in a system is frozen to give it sufficient retention time and is then re-read after reboot, or is transferred to an attacker's machine for extracting sensitive data. This method has been shown to be an effective attack vector for extracting disk encryption keys out of locked devices. However, most modern systems incorporate some form of data scrambling into their DRAM interfaces making cold boot attacks challenging. While first added as a measure to improve signal integrity and reduce power supply noise, these scramblers today serve the added purpose of obscuring the DRAM contents. It has previously been shown that scrambled DDR3 systems do not provide meaningful protection against cold boot attacks. In this paper, we investigate the enhancements that have been introduced in DDR4 memory scramblers in the 6th generation Intel Core (Skylake) processors. We then present an attack that demonstrates these enhanced DDR4 scramblers still do not provide sufficient protection against cold boot attacks. We detail a proof-of-concept attack that extracts memory resident AES keys, including disk encryption keys. The limitations of memory scramblers we point out in this paper motivate the need for strong yet low-overhead fullmemory encryption schemes. Existing schemes such as Intel's SGX can effectively prevent such attacks, but have overheads that may not be acceptable for performance-sensitive applications. However, it is possible to deploy a memory encryption scheme that has zero performance overhead by forgoing integrity checking and replay attack protections afforded by Intel SGX. To that end, we present analyses that confirm modern stream ciphers such as ChaCha8 are sufficiently fast that it is now possible to completely overlap keystream generation with DRAM row buffer access latency, thereby enabling the creation of strongly encrypted DRAMs with zero exposed latency. Adopting such low-overhead measures in future generation of products can effectively shut down cold boot attacks in systems where the overhead of existing memory encryption schemes is unacceptable. Furthermore, the emergence of non-volatile DIMMs that fit into DDR4 buses is going to exacerbate the risk of cold boot attacks. Hence, strong full memory encryption is going to be even more crucial on such systems.},
  eventtitle = {2017 {{IEEE International Symposium}} on {{High Performance Computer Architecture}} ({{HPCA}})},
  keywords = {Capacitors,cold boot attack,cryptography,Data mining,DRAM,Encryption,memory,Program processors,Random access memory,Registers,security},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\FLWQJJXV\\yitbarekColdBootAttacks2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\2DVIFHAK\\7920835.html}
}

@online{zhouWebArenaRealisticWeb2024,
  title = {{{WebArena}}: {{A Realistic Web Environment}} for {{Building Autonomous Agents}}},
  shorttitle = {{{WebArena}}},
  author = {Zhou, Shuyan and Xu, Frank F. and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and Alon, Uri and Neubig, Graham},
  date = {2024-04-16},
  eprint = {2307.13854},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.13854},
  url = {http://arxiv.org/abs/2307.13854},
  urldate = {2025-02-10},
  abstract = {With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41\%, significantly lower than the human performance of 78.24\%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\N7ZXL7AP\\zhouWebArenaRealisticWeb2024.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\4EX3TM9S\\2307.html}
}

@online{zimmermanEricZimmermansTools,
  title = {Eric {{Zimmerman}}'s Tools},
  author = {Zimmerman, Eric},
  url = {https://ericzimmerman.github.io/#!index.md},
  urldate = {2025-03-28},
  file = {C:\Users\Kisun\Zotero\storage\M89QPIKJ\ericzimmerman.github.io.html}
}

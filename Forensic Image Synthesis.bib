@inproceedings{abbottAutomatedRecognitionEvent2006,
  title = {Automated Recognition of Event Scenarios for Digital Forensics},
  booktitle = {Proceedings of the 2006 {{ACM}} Symposium on {{Applied}} Computing},
  author = {Abbott, Jonathon and Bell, Jim and Clark, Andrew and De Vel, Olivier and Mohay, George},
  year = {2006},
  month = apr,
  series = {{{SAC}} '06},
  pages = {293--300},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1141277.1141346},
  urldate = {2023-08-30},
  abstract = {The authors have previously developed the ECF (Event Correlation for Forensics) framework for scenario matching in the forensic investigation of activity manifested in digital transactional logs. ECF incorporated a suite of log parsers to reduce event records from heterogeneous logs to a canonical form for lodging in an SQL database. This paper presents work since then, the Auto-ECF system, which represents significant advances on ECF. The paper reports on the development and implementation of the new event abstraction and scenario specification methodology and on the development of the Auto-ECF system which builds on that to achieve the automated recognition of event scenarios. The paper also reports on the evaluation of Auto-ECF using three scenarios including one from the well known DARPA test data.},
  isbn = {978-1-59593-108-5},
  keywords = {computer forensics,event correlation,events,heterogeneous event logs,logs,research/image-sources,research/synthesizer-details},
  file = {C:\Users\Kisun\Zotero\storage\ZJ3ZZDJH\abbottAutomatedRecognitionEvent2006.pdf}
}

@inproceedings{adelsteinAutomaticallyCreatingRealistic2005,
  title = {Automatically {{Creating Realistic Targets}} for {{Digital Forensics Investigation}}},
  booktitle = {Digital {{Forensic Research Workshop}}},
  author = {Adelstein, F. and Gao, Yun and Richard, G.},
  year = {2005},
  urldate = {2023-11-28},
  abstract = {The need for computer forensics education continues to grow, as digital evidence is present in more crimes, whether the crimes directly involve computers or not. An essential component of training in computer forensics is hands-on, realistic laboratory assignments. Creating detailed, realistic lab assignments, however, is a difficult task. The ``crime'' must be played out on the machine, often in real-time, since timestamps present in numerous places in the system, such as files and logs, must be discovered and examined by students. Developing, running, and evaluating the labs can be labor intensive and instructors have limited time to spend on creating and grading laboratory experiments. We are developing FALCON (Framework for Laboratory Exercises Conducted Over Networks), an extensible framework that addresses the problem of creating, running, and evaluating detailed, realistic computer laboratory assignments in computer forensics. FALCON includes a component that enables instructors to set up scenarios on virtual target machines for the students to investigate. Existing tools for both ``live'' and ``dead'' machine investigations can be integrated into FALCON. In addition, FALCON logs all student activity for automated assessment of student performance. Currently, FALCON is a work in progress and some tasks remain manual. The goal is to automatically transform high-level descriptions of digital forensics scenarios into detailed investigative targets which contain activities derived from the scenarios, as well as historical activity (timestamps, logs, history, etc.). While the initial version of FALCON focuses on computer forensics, it will be extensible to other areas, such as incident response, as well as general computer security instruction.},
  file = {C:\Users\Kisun\Zotero\storage\6URIIW8P\adelsteinAutomaticallyCreatingRealistic2005.pdf}
}

@inproceedings{andersonComparativeStudyTeaching2006,
  title = {A {{Comparative Study}} of {{Teaching Forensics}} at a {{University Degree Level}}.},
  author = {Anderson, Philip and Dornseif, Maximillian and Freiling, Felix and Holz, Thorsten and Irons, Alastair and Laing, Christopher and Mink, Martin},
  year = {2006},
  month = jan,
  pages = {116--127},
  abstract = {Computer forensics is a relatively young University disci- pline which has developed strongly in the United States and the United Kingdom but is still in its infancy in continental Europe. The national programmes and courses offered therefore differ in many ways. We report on two recently established degree programmes from two European coun- tries: Great Britain and Germany. We present and compare the design of both programmes and conclude that they cover two complementary and orthogonal aspects of computer forensics education: (a) rigorous practical skills and (b) competence for fundamental research discoveries.},
  keywords = {research/image-purpose,research/image-purpose/education,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\99TULM3R\andersonComparativeStudyTeaching2006.pdf}
}

@misc{avrahamiOwnershipCreativityGenerative2021,
  title = {Ownership and {{Creativity}} in {{Generative Models}}},
  author = {Avrahami, Omri and Tamir, Bar},
  year = {2021},
  month = dec,
  number = {arXiv:2112.01516},
  eprint = {2112.01516},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2112.01516},
  urldate = {2023-12-04},
  abstract = {Machine learning generated content such as image artworks, textual poems and music become prominent in recent years. These tools attract much attention from the media, artists, researchers, and investors. Because these tools are data-driven, they are inherently different than the traditional creative tools which arises the question - who may own the content that is generated by these tools? In this paper we aim to address this question, we start by providing a background to this problem, raising several candidates that may own the content and arguments for each one of them. Then we propose a possible algorithmic solution in the vision-based model's regime. Finally, we discuss the broader implications of this problem.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8H7YFUDD\\avrahamiOwnershipCreativityGenerative2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\49FUZQG8\\2112.html}
}

@inproceedings{baggiliDataSourcesAdvancing2015,
  title = {Data Sources for Advancing Cyber Forensics: {{What}} the Social World Has to Offer},
  author = {Baggili, Ibrahim and Breitinger, Frank},
  year = {2015},
  month = mar,
  series = {{{AAAI Spring Symposium}} - {{Technical Report}}},
  keywords = {research/image-gaps,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\4FUUX3TQ\baggiliDataSourcesAdvancing2015.pdf}
}

@article{bruecknerAutomatedComputerForensics2008,
  title = {Automated Computer Forensics Training in a Virtualized Environment},
  author = {Brueckner, Stephen and Guaspari, David and Adelstein, Frank and Weeks, Joseph},
  year = {2008},
  month = sep,
  journal = {Digital Investigation},
  series = {The {{Proceedings}} of the {{Eighth Annual DFRWS Conference}}},
  volume = {5},
  pages = {S105-S111},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2008.05.009},
  urldate = {2023-08-31},
  abstract = {The CYber DEfenSe Trainer (CYDEST) is a virtualized training platform for network defense and computer forensics. It uses virtual machines to provide tactical level exercises for personnel such as network administrators, first responders, and digital forensics investigators. CYDEST incorporates a number of features to reduce instructor workload and to improve training realism, including: (1) automated assessment of trainee performance, (2) automated attacks that respond dynamically to the student's actions, (3) a full fidelity training environment, (4) an unrestricted user interface incorporating real tools, and (5) continuous, remote accessibility via the Web.},
  keywords = {Automated assessment,Automated evaluation,Computer training,Digital forensic training,research/synthesizer-details,Virtualized training},
  note = {Root},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\9MVY78M9\\bruecknerAutomatedComputerForensics2008.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\6XP3APTW\\S1742287608000406.html}
}

@misc{bureauoflaborstatisticsu.s.departmentoflaborInformationSecurityAnalysts2023,
  title = {Information {{Security Analysts}}},
  shorttitle = {Information {{Security Analysts}}},
  author = {{Bureau of Labor Statistics, U.S. Department of Labor}},
  year = {2023},
  month = sep,
  journal = {Occupational Outlook Handbook},
  urldate = {2023-12-03},
  abstract = {Information security analysts plan and carry out security measures to protect an organization's computer networks and systems.},
  howpublished = {https://www.bls.gov/ooh/computer-and-information-technology/information-security-analysts.htm\#tab-1},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\JTQDTKPQ\information-security-analysts.html}
}

@misc{CaseworkCASEMappingPython,
  title = {Casework/{{CASE-Mapping-Python}}},
  urldate = {2024-12-14},
  howpublished = {https://github.com/casework/CASE-Mapping-Python},
  file = {C:\Users\Kisun\Zotero\storage\Y97NLSGI\CASE-Mapping-Python.html}
}

@article{caseyAdvancingCoordinatedCyberinvestigations2017,
  title = {Advancing Coordinated Cyber-Investigations and Tool Interoperability Using a Community Developed Specification Language},
  author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan and Snyder, Jonathan and {van Beek}, Harm and Nelson, Alex},
  year = {2017},
  month = sep,
  journal = {Digital Investigation},
  volume = {22},
  pages = {14--45},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2017.08.002},
  urldate = {2024-12-03},
  abstract = {Any investigation can have a digital dimension, often involving information from multiple data sources, organizations and jurisdictions. Existing approaches to representing and exchanging cyber-investigation information are inadequate, particularly when combining data sources from numerous organizations or dealing with large amounts of data from various tools. To conduct investigations effectively, there is a pressing need to harmonize how this information is represented and exchanged. This paper addresses this need for information exchange and tool interoperability with an open community-developed specification language called Cyber-investigation Analysis Standard Expression (CASE). To further promote a common structure, CASE aligns with and extends the Unified Cyber Ontology (UCO) construct, which provides a format for representing information in all cyber domains. This ontology abstracts objects and concepts that are not CASE-specific, so that they can be used across other cyber disciplines that may extend UCO. This work is a rational evolution of the Digital Forensic Analysis eXpression (DFAX) for representing digital forensic information and provenance. CASE is more flexible than DFAX and can be utilized in any context, including criminal, corporate and intelligence. CASE also builds on the Hansken data model developed and implemented by the Netherlands Forensic Institute (NFI). CASE enables the fusion of information from different organizations, data sources, and forensic tools to foster more comprehensive and cohesive analysis. This paper includes illustrative examples of how CASE can be implemented and used to capture information in a structured form to advance sharing, interoperability and analysis in cyber-investigations. In addition to capturing technical details and relationships between objects, CASE provides structure for representing and sharing details about how cyber-information was handled, transferred, processed, analyzed, and interpreted. CASE also supports data marking for sharing information at different levels of trust and classification, and for protecting sensitive and private information. Furthermore, CASE supports the sharing of knowledge related to cyber-investigations, including distinctive patterns of activity/behavior that are common across cases. This paper features a proof-of-concept Application Program Interface (API) to facilitate implementation of CASE in tools. Community members are encouraged to participate in the development and implementation of CASE and UCO.},
  keywords = {Cyber-investigation,CybOX,DFAX,DFXML,Digital evidence exchange,Digital forensics,Evidence provenance,Information sharing,Specification language,Standard representation,Unified cyber ontology},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\QQ2FLVE4\\caseyAdvancingCoordinatedCyberinvestigations2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\93M23W87\\S1742287617301007.html}
}

@article{caseyLeveragingCybOXStandardize2015,
  title = {Leveraging {{CybOX}}™ to Standardize Representation and Exchange of Digital Forensic Information},
  author = {Casey, Eoghan and Back, Greg and Barnum, Sean},
  year = {2015},
  month = mar,
  journal = {Digital Investigation},
  series = {{{DFRWS}} 2015 {{Europe}}},
  volume = {12},
  pages = {S102-S110},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2015.01.014},
  urldate = {2024-12-03},
  abstract = {With the growing number of digital forensic tools and the increasing use of digital forensics in various contexts, including incident response and cyber threat intelligence, there is a pressing need for a widely accepted standard for representing and exchanging digital forensic information. Such a standard representation can support correlation between different data sources, enabling more effective and efficient querying and analysis of digital evidence. This work summarizes the strengths and weaknesses of existing schemas, and proposes the open-source CybOX schema as a foundation for storing and sharing digital forensic information. The suitability of CybOX for representing objects and relationships that are common in forensic investigations is demonstrated with examples involving digital evidence. The capability to represent provenance by leveraging CybOX is also demonstrated, including specifics of the tool used to process digital evidence and the resulting output. An example is provided of an ongoing project that uses CybOX to record the state of a system before and after an event in order to capture cause and effect information that can be useful for digital forensics. An additional open-source schema and associated ontology called Digital Forensic Analysis eXpression (DFAX) is proposed that provides a layer of domain specific information overlaid on CybOX. DFAX extends the capability of CybOX to represent more abstract forensic-relevant actions, including actions performed by subjects and by forensic examiners, which can be useful for sharing knowledge and supporting more advanced forensic analysis. DFAX can be used in combination with other existing schemas for representing identity information (CIQ), and location information (KML). This work also introduces and leverages initial steps of a Unified Cyber Ontology (UCO) effort to abstract and express concepts/constructs that are common across the cyber domain.},
  keywords = {CybOX,DFAX,DFXML,Digital forensic ontology,Digital forensic XML,Digital forensics,Standard representation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8AD2Y9L2\\caseyLeveragingCybOXStandardize2015.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\CM74AFDJ\\S1742287615000158.html}
}

@article{ceballosdelgadoFADEForensicImage2022,
  title = {{{FADE}}: {{A}} Forensic Image Generator for Android Device Education},
  shorttitle = {{{FADE}}},
  author = {Ceballos Delgado, Alberto A. and Glisson, William B. and Grispos, George and Choo, Kim-Kwang Raymond},
  year = {2022},
  journal = {WIREs Forensic Science},
  volume = {4},
  number = {2},
  pages = {e1432},
  issn = {2573-9468},
  doi = {10.1002/wfs2.1432},
  urldate = {2024-02-13},
  abstract = {Realistic case studies are essential to training successful digital forensics examiners. However, the generation of realistic datasets is time-consuming and resource taxing. This paper presents a technical solution that populates Android emulators with realistic mobile forensic data. The emulator's data can be extracted into a raw disk image that is usable in mobile forensic training scenarios. In addition, the tool allows a user to populate the Android emulators with custom text messages, phone contacts, phone calls, and files. This population task is achieved by utilizing the Android Debug Bridge, Android Content Providers, SQLite databases, and the NodeJS runtime environment. This paper presents the software design and development, the requirements and limitations, and the testing process implemented in this research. The contribution of this paper is twofold. First, it identifies potential data and mechanisms to generate Android mobile forensic datasets using customized data population. Second, it creates a foundation for future research on the topic of mobile forensic emulators for training purposes. This article is categorized under: Digital and Multimedia Science {$>$} Mobile Forensics Crime Scene Investigation {$>$} Education and Formation},
  copyright = {{\copyright} 2021 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {Android forensics,data generation,mobile forensics},
  file = {C:\Users\Kisun\Zotero\storage\HI7L88TZ\ceballosdelgadoFADEForensicImage2022.pdf}
}

@article{changFbHashNewSimilarity2019,
  title = {{{FbHash}}: {{A New Similarity Hashing Scheme}} for {{Digital Forensics}}},
  shorttitle = {{{FbHash}}},
  author = {Chang, Donghoon and Ghosh, Mohona and Sanadhya, Somitra Kumar and Singh, Monika and White, Douglas R.},
  year = {2019},
  month = jul,
  journal = {Digital Investigation},
  volume = {29},
  pages = {S113-S123},
  issn = {17422876},
  doi = {10.1016/j.diin.2019.04.006},
  urldate = {2023-12-04},
  abstract = {With the rapid growth of the World Wide Web and Internet of Things, a huge amount of digital data is being produced every day. Digital forensics investigators face an uphill task when they have to manually screen through and examine tons of such data during a crime investigation. To expedite this process, several automated techniques have been proposed and are being used in practice. Among which tools based on Approximate Matching algorithms have gained prominence, e.g., ssdeep, sdhash, mvHash etc. These tools produce hash signatures for all the files to be examined, compute a similarity score and then compare it with a known reference set to filter out known good as well as bad files. In this way, exact as well as similar matches can be screened out. However, all of these schemes have been shown to be prone to active adversary attack, whereby an attacker, by making feasible changes in the content of the file, intelligently modifies the final hash signature produced to evade detection. Thus, an alternate hashing scheme is required which can resist this attack. In this work, we propose a new Approximate Matching scheme termed as - FbHash. We show that our scheme is secure against active attacks and detects similarity with 98\% accuracy. We also provide a detailed comparative analysis with other existing schemes and show that our scheme has a 28\% higher accuracy rate than other schemes for uncompressed file format (e.g., text files) and 50\% higher accuracy rate for compressed file format (e.g., docx etc.). Our proposed scheme is able to correlate a fragment as small as 1\% to the source file with 100\% detection rate and able to detect commonality as small as 1\% between two documents with appropriate similarity score. Further, our scheme also produces the least false negatives in comparison to other schemes.},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\I9I3KC6D\changFbHashNewSimilarity2019.pdf}
}

@misc{colvinPydantic2024,
  title = {Pydantic},
  author = {Colvin, Samuel and Jolibois, Eric and Ramezani, Hasan and Garcia Badaracco, Adrian and Dorsey, Terrence and Montague, David and Matveenko, Serge and Trylesinski, Marcelo and Runkle, Sydney and Hewitt, David and Hall, Alex and Plot, Victorien},
  year = {2024},
  month = dec,
  urldate = {2024-12-07},
  abstract = {Data validation using Python type hints},
  copyright = {MIT}
}

@incollection{conklinComputerForensics2022,
  title = {Computer {{Forensics}}},
  booktitle = {Principles of {{Computer Security}}: {{CompTIA Security}}+ and {{Beyond}} ({{Exam SY0-601}})},
  author = {Conklin, Wm. Arthur and White, Gregory and Cothren, Chuck and Davis, Roger L. and Williams, Dwayne},
  year = {2022},
  edition = {6th Edition},
  publisher = {McGraw-Hill Education},
  address = {New York},
  isbn = {978-1-260-47431-2},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\MSUZNL82\conklinComputerForensics2022b.pdf}
}

@article{conlanAntiforensicsFurtheringDigital2016,
  title = {Anti-Forensics: {{Furthering}} Digital Forensic Science through a New Extended, Granular Taxonomy},
  shorttitle = {Anti-Forensics},
  author = {Conlan, Kevin and Baggili, Ibrahim and Breitinger, Frank},
  year = {2016},
  month = aug,
  journal = {Digital Investigation},
  volume = {18},
  pages = {S66-S75},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2016.04.006},
  urldate = {2023-11-27},
  abstract = {Anti-forensic tools, techniques and methods are becoming a formidable obstacle for the digital forensic community. Thus, new research initiatives and strategies must be formulated to address this growing problem. In this work we first collect and categorize 308 anti-digital forensic tools to survey the field. We then devise an extended anti-forensic taxonomy to the one proposed by Rogers (2006) in order to create a more comprehensive taxonomy and facilitate linguistic standardization. Our work also takes into consideration anti-forensic activity which utilizes tools that were not originally designed for anti-forensic purposes, but can still be used with malicious intent. This category was labeled as Possible indications of anti-forensic activity, as certain software, scenarios, and digital artifacts could indicate anti-forensic activity on a system. We also publicly share our data sets, which includes categorical data on 308 collected anti-forensic tools, as well as 2780 unique hash values related to the installation files of 191 publicly available anti-forensic tools. As part of our analysis, the collected hash set was ran against the National Institute of Standards and Technology's 2016 National Software Reference Library, and only 423 matches were found out of the 2780 hashes. Our findings indicate a need for future endeavors in creating and maintaining exhaustive anti-forensic hash data sets.},
  keywords = {Anti-digital forensics,Anti-forensics,Anti-forensics taxonomy,Categorical data set,Computer crime,Digital forensics,Formalizing digital forensics,research/anti-forensics},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\EAUHHMAL\\conlanAntiforensicsFurtheringDigital2016.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\WDSDSHRH\\S1742287616300378.html}
}

@inproceedings{cooperStandardsDigitalForensics2010,
  title = {Towards Standards in Digital Forensics Education},
  booktitle = {Proceedings of the 2010 {{ITiCSE}} Working Group Reports},
  author = {Cooper, Peter and Finley, Gail T. and Kaskenpalo, Petteri},
  year = {2010},
  month = jun,
  pages = {87--95},
  publisher = {ACM},
  address = {Ankara Turkey},
  doi = {10.1145/1971681.1971688},
  urldate = {2023-11-26},
  isbn = {978-1-4503-0677-5},
  langid = {english},
  keywords = {research/image-purpose,research/image-purpose/education},
  note = {Referrent: (Nance et al., 2010)
\par
The primary contribution here seems to be a good definition of the needs of the various groups involved in digital forensics, ranging from the legal profession and law enforcement to educators and industry workers. ~It does also briefly go over the logistical needs for general digital forensics education at a high level, which a synthesizer could contribute to. ~},
  file = {C:\Users\Kisun\Zotero\storage\G8ULX727\cooperStandardsDigitalForensics2010.pdf}
}

@inproceedings{dafoulasOverviewDigitalForensics2019,
  title = {An Overview of {{Digital Forensics Education}}},
  booktitle = {2019 2nd {{International Conference}} on New {{Trends}} in {{Computing Sciences}} ({{ICTCS}})},
  author = {Dafoulas, Georgios A. and Neilson, David},
  year = {2019},
  month = oct,
  pages = {1--7},
  publisher = {IEEE},
  address = {Amman, Jordan},
  doi = {10.1109/ICTCS.2019.8923101},
  urldate = {2024-03-30},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-7281-2882-5},
  file = {C:\Users\Kisun\Zotero\storage\DNDE9DPQ\dafoulasOverviewDigitalForensics2019.pdf}
}

@article{demmelDataSynthesisGoing2024,
  title = {Data {{Synthesis Is Going Mobile}}---{{On Community-Driven Dataset Generation}} for {{Android Devices}}},
  author = {Demmel, Markus and G{\"o}bel, Thomas and Gon{\c c}alves, Patrik and Baier, Harald},
  year = {2024},
  month = oct,
  journal = {Digital Threats},
  volume = {5},
  number = {3},
  pages = {30:1--30:19},
  doi = {10.1145/3688807},
  urldate = {2024-12-29},
  abstract = {Personal electronic devices such as smartphones and smartwatches have become indispensable daily companions, collecting a multitude of personal and sensitive data. As a result, they are of paramount importance in digital forensic examinations. However, there is a lack of publicly available and ready-to-use digital forensic datasets, especially in mobile forensics. This work presents a concept and an open-source proof-of-concept implementation, which simplifies and automates the creation of mobile forensic datasets within the scope of the Android operating system. In contrast to previous approaches, which populate the most common databases of an Android device, our concept is based on community-driven playbooks and makes use of interaction with the actual smartphone GUI. Hence, we are able to generate coherent and realistic traces as they occur in real-world human usage. Our proof-of-concept implementation is based on the standard Android emulation environment and borrows tools from the user interface testing community. Our evaluation shows that our approach actually generates realistic Android datasets. For instance, we can generate traces that cannot be simulated by gestures (e.g., changing the GPS position or triggering incoming phone calls). Recording the actual data synthesis process allows users to either create and share their own playbooks (i.e., the exact instructions for the data synthesis process rather than having to share the full image) or reproduce Android images with different scenarios using playbooks previously created and shared by the community.},
  file = {C:\Users\Kisun\Zotero\storage\8ZP3PIDL\demmelDataSynthesisGoing2024.pdf}
}

@article{duTraceGenUserActivity2021,
  title = {{{TraceGen}}: {{User}} Activity Emulation for Digital Forensic Test Image Generation},
  shorttitle = {{{TraceGen}}},
  author = {Du, Xiaoyu and Hargreaves, Christopher and Sheppard, John and Scanlon, Mark},
  year = {2021},
  month = oct,
  journal = {Forensic Science International: Digital Investigation},
  volume = {38},
  pages = {301133},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2021.301133},
  urldate = {2024-12-30},
  abstract = {Digital forensic test images are commonly used across a variety of digital forensic use cases including education and training, tool testing and validation, proficiency testing, malware analysis, and research and development. Using real digital evidence for these purposes is often not viable or permissible, especially when factoring in the ethical and in some cases legal considerations of working with individuals' personal data. Furthermore, when using real data it is not usually known what actions were performed when, i.e., what was the `ground truth'. The creation of synthetic digital forensic test images typically involves an arduous, time-consuming process of manually performing a list of actions, or following a `story' to generate artefacts in a subsequently imaged disk. Besides the manual effort and time needed in executing the relevant actions in the scenario, there is often little room to build a realistic volume of non-pertinent wear-and-tear or `background noise' on the suspect device, meaning the resulting disk images are inherently limited and to a certain extent simplistic. This work presents the TraceGen framework, an automated system focused on the emulation of user actions to create realistic and comprehensive artefacts in an auditable and reproducible manner. The framework consists of a series of actions contained within scripts that are executed both externally and internally to a target virtual machine. These actions use existing automation APIs to emulate a real user's behaviour on a Windows system to generate realistic and comprehensive artefacts. These actions can be quickly scripted together to form complex stories or to emulate wear-and-tear on the test image. In addition to the development of the framework, evaluation is also performed in terms of the ability to produce background artefacts at scale, and also the realism of the artefacts compared with their human-generated counterparts.},
  keywords = {Evidence planting,Forensic disk image creation,Forensic education,Tool testing and validation,User emulation},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\NE7US37Y\\duTraceGenUserActivity2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\I3WY2FEZ\\S2666281721000317.html}
}

@article{eshraghianHumanOwnershipArtificial2020,
  title = {Human Ownership of Artificial Creativity},
  author = {Eshraghian, Jason K.},
  year = {2020},
  month = mar,
  journal = {Nat Mach Intell},
  volume = {2},
  number = {3},
  pages = {157--160},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-0161-x},
  urldate = {2023-12-04},
  abstract = {Advances in generative algorithms have enhanced the quality and accessibility of artificial intelligence (AI) as a tool in building synthetic datasets. By generating photorealistic images and videos, these networks can pose a major technological disruption to a broad range of industries from medical imaging to virtual reality. However, as artwork developed by generative algorithms and cognitive robotics enters the arena, the notion of human-driven creativity has been thoroughly tested. When creativity is automated by the programmer, in a style determined by the trainer, using features from information available in public and private datasets, who is the proprietary owner of the rights in AI-generated artworks and designs? This Perspective seeks to provide an answer by systematically exploring the key issues in copyright law that arise at each phase of artificial creativity, from programming to deployment. Ultimately, four guiding actions are established for artists, programmers and end users that utilize AI as a tool such that they may be appropriately awarded the necessary proprietary rights.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Law},
  file = {C:\Users\Kisun\Zotero\storage\T6XCDWTA\eshraghianHumanOwnershipArtificial2020.pdf}
}

@article{garfinkelBringingScienceDigital2009,
  title = {Bringing Science to Digital Forensics with Standardized Forensic Corpora},
  author = {Garfinkel, Simson and Farrell, Paul and Roussev, Vassil and Dinolt, George},
  year = {2009},
  month = sep,
  journal = {Digital Investigation},
  volume = {6},
  pages = {S2-S11},
  issn = {17422876},
  doi = {10.1016/j.diin.2009.06.016},
  urldate = {2023-11-26},
  langid = {english},
  keywords = {research/image-purpose,research/public-datasets},
  note = {Referrent: (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\B87VH8VI\garfinkelBringingScienceDigital2009.pdf}
}

@article{garfinkelBringingScienceDigital2009a,
  title = {Bringing Science to Digital Forensics with Standardized Forensic Corpora},
  author = {Garfinkel, Simson and Farrell, Paul and Roussev, Vassil and Dinolt, George},
  year = {2009},
  month = sep,
  journal = {Digital Investigation},
  series = {The {{Proceedings}} of the {{Ninth Annual DFRWS Conference}}},
  volume = {6},
  pages = {S2-S11},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2009.06.016},
  urldate = {2025-02-08},
  abstract = {Progress in computer forensics research has been limited by the lack of a standardized data sets---corpora---that are available for research purposes. We explain why corpora are needed to further forensic research, present a taxonomy for describing corpora, and announce the availability of several forensic data sets.},
  keywords = {Corpora,Forensics,Human subjects research,Real data corpus,Realistic data},
  file = {C:\Users\Kisun\Zotero\storage\65V4PHSB\S1742287609000346.html}
}

@article{garfinkelForensicCorporaChallenge2007,
  title = {Forensic {{Corpora}}: {{A Challenge}} for {{Forensic Research}}},
  shorttitle = {Forensic {{Corpora}}},
  author = {Garfinkel, Simson},
  year = {2007},
  month = jan,
  volume = {2007},
  abstract = {Research in the field of computer forensics is hobbled by the lack of realistic data. Academics are not developing automated techniques and tools because they lack the raw data necessary to develop and validate algorithms. Investigators that have access to real data operate under legal and practical restraints that prevent the data from being used in research. To make progress, we must "prime the pump" by collecting or creating forensic corpora that can be used by researchers. We must also pursue targeted technical developments in forensic file formats, knowledge representation, inference techniques, and the presentation of forensic results.},
  keywords = {research/image-gaps,research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\ITBMI4BV\Garfinkel - 2007 - Forensic Corpora A Challenge for Forensic Researc.pdf}
}

@article{geigerEvaluatingCommercialCounterForensic2005,
  title = {Evaluating {{Commercial Counter-Forensic Tools}}},
  author = {Geiger, Matthew},
  year = {2005},
  abstract = {Digital forensic analysts may find their task complicated by any of more than a dozen commercial software packages designed to irretrievably erase files and records of computer activity. These counter-forensic tools have been used to eliminate evidence in criminal and civil legal proceedings and represent an area of continuing concern for forensic investigators. In this paper, we review the performance of six counter-forensic tools and highlight operational shortfalls that could permit the recovery of significant evidentiary data. In addition, each tool creates a distinct operational fingerprint that an analyst may use to identify the application used and, thus, guide the search for residual data. These operational fingerprints may also help demonstrate the use of a tool in cases where such action has legal ramifications.},
  langid = {english},
  keywords = {research/anti-forensics},
  note = {Referrent: (Conlan et al., 2016)},
  file = {C:\Users\Kisun\Zotero\storage\Q5LXE38H\Geiger - 2005 - Evaluating Commercial Counter-Forensic Tools.pdf}
}

@article{gobelForTraceHolisticForensic2022,
  title = {{{ForTrace}} - {{A}} Holistic Forensic Data Set Synthesis Framework},
  author = {G{\"o}bel, Thomas and Maltan, Stephan and T{\"u}rr, Jan and Baier, Harald and Mann, Florian},
  year = {2022},
  month = apr,
  journal = {Forensic Science International: Digital Investigation},
  series = {Selected {{Papers}} of the {{Ninth Annual DFRWS Europe Conference}}},
  volume = {40},
  pages = {301344},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2022.301344},
  urldate = {2023-08-31},
  abstract = {Digital forensic experts are confronted with a wide variety of investigation objectives, e.g., to deal with an infected IT system. The same holds for digital forensic tools. Mostly different sources of digital traces have to be inspected including persistent storage devices (e.g., SSDs, SD cards, USB drives), volatile main memory snapshots, and network captures, respectively. In order to train experts and tools and keep their knowledge and capabilities up-to-date, a capacious amount of realistic, timely training data is necessary. However, due to different reasons like privacy, secrecy, or intellectual property rights there is a large gap in digital forensic training data. In recent years different synthesis frameworks to generate realistic digital forensic data sets have been proposed. However, none of these frameworks provides a holistic approach to generate realistic digital forensic relevant traces of different sources. In this paper we introduce ForTrace, a holistic framework for the simultaneous generation of persistent, volatile and network traces. Our approach is based on the data synthesis framework hystck. We explain our extension of hystck by defining properties of a holistic data set synthesis framework and by discussing different forensically relevant scenarios and their implementation in ForTrace. We then successfully evaluate ForTrace with respect to diverse realistic and complex scenarios. ForTrace is open source and may be adapted or extended with respect to individual needs.},
  keywords = {Data synthesis,Digital forensic corpora,Forensic data set,Forensic education,Forensic image generation,Forensic tool testing,research/synthesizer-details,User simulation},
  note = {Consider this the ``root''.},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\67KLSECY\\gobelForTraceHolisticForensic2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\JBBHY8Z2\\S2666281722000130.html}
}

@incollection{gobelNovelApproachGenerating2020,
  title = {A {{Novel Approach}} for {{Generating Synthetic Datasets}} for {{Digital Forensics}}},
  booktitle = {Advances in {{Digital Forensics XVI}}},
  author = {G{\"o}bel, Thomas and Sch{\"a}fer, Thomas and Hachenberger, Julien and T{\"u}rr, Jan and Baier, Harald},
  editor = {Peterson, Gilbert and Shenoi, Sujeet},
  year = {2020},
  volume = {589},
  pages = {73--93},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-56223-6_5},
  urldate = {2023-09-17},
  isbn = {978-3-030-56222-9 978-3-030-56223-6},
  langid = {english},
  keywords = {research/synthesizer-details},
  note = {Referred to by (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\359G4TQ6\gobelNovelApproachGenerating2020.pdf}
}

@article{grajedaAvailabilityDatasetsDigital2017,
  title = {Availability of Datasets for Digital Forensics -- {{And}} What Is Missing},
  author = {Grajeda, Cinthya and Breitinger, Frank and Baggili, Ibrahim},
  year = {2017},
  month = aug,
  journal = {Digital Investigation},
  volume = {22},
  pages = {S94-S105},
  issn = {17422876},
  doi = {10.1016/j.diin.2017.06.004},
  urldate = {2023-11-06},
  langid = {english},
  keywords = {research/image-gaps,research/image-sources,research/manual-motivation,research/public-datasets},
  note = {Referrent: (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\UEHWSGEW\grajedaAvailabilityDatasetsDigital2017.pdf}
}

@inproceedings{guptaDigitalForensicsLab2022,
  title = {Digital {{Forensics Lab Design}}: {{A}} Framework},
  shorttitle = {Digital {{Forensics Lab Design}}},
  booktitle = {2022 10th {{International Symposium}} on {{Digital Forensics}} and {{Security}} ({{ISDFS}})},
  author = {Gupta, Khushi and Neyaz, Ashar and Shashidhar, Narasimha and Varol, Cihan},
  year = {2022},
  month = jun,
  pages = {1--6},
  doi = {10.1109/ISDFS55398.2022.9800799},
  urldate = {2023-11-27},
  abstract = {Internet connectivity and digital technologies have experienced exponential growth in the past few years. This explosion has spurred a significant increase in crime while also creating a new definition of cybercriminals. Digital Forensics plays an important role in crime reconstruction and thus the need for skilled forensics experts has multiplied. As a result, digital forensics education and training has also experienced radical growth. Teaching digital forensics has always been a challenge as the creation of suitable hands-on digital forensics labs has always been the core of these training programs. There are several challenges faced by both the educators and the students when it comes to the creation and implementation of digital forensics labs. This paper aims to address some of these issues by providing a framework that can be used by educators to establish educational hands-on labs for digital forensics. Firstly, we identify all the challenges faced by digital examiners, educators, and training professionals to deliver high-quality forensic labs. Secondly, we identify specific common technical pitfalls that professionals run into when designing digital forensics labs such as the creation of large image files. We thus, offer tips and tricks to make the process of creating digital forensic labs easier. Finally, we also provide a data set of small-sized image files that can be used by educators for the creation of a digital forensic lab infrastructure.},
  keywords = {research/image-purpose,research/image-purpose/education},
  note = {Root, found when looking for (Lawrence and Chi, 2009)},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\7EKX2QKT\\guptaDigitalForensicsLab2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\VHAK9BZ8\\9800799.html}
}

@incollection{hargreavesDigitalForensicsEducation2017,
  title = {Digital {{Forensics Education}}: {{A New Source}} of {{Forensic Evidence}}},
  shorttitle = {Digital {{Forensics Education}}},
  booktitle = {Forensic {{Science Education}} and {{Training}}},
  author = {Hargreaves, Christopher},
  editor = {Williams, Anna and Cassella, John P. and Maskell, Peter D.},
  year = {2017},
  month = may,
  edition = {1},
  pages = {73--85},
  publisher = {Wiley},
  doi = {10.1002/9781118689196.ch6},
  urldate = {2024-02-13},
  isbn = {978-1-118-68923-3 978-1-118-68919-6},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\C2UQ36WE\hargreavesDigitalForensicsEducation2017.pdf}
}

@article{harrisArrivingAntiforensicsConsensus2006,
  title = {Arriving at an Anti-Forensics Consensus: {{Examining}} How to Define and Control the Anti-Forensics Problem},
  shorttitle = {Arriving at an Anti-Forensics Consensus},
  author = {Harris, Ryan},
  year = {2006},
  month = sep,
  journal = {Digital Investigation},
  volume = {3},
  pages = {44--49},
  issn = {17422876},
  doi = {10.1016/j.diin.2006.06.005},
  urldate = {2023-11-27},
  abstract = {There are no general frameworks with which we may analyze the anti-forensics situation. Solving anti-forensic issues requires that we create a consensus view of the problem itself. This paper attempts to arrive at a standardized method of addressing anti-forensics by defining the term, categorizing the anti-forensics techniques and outlining general guidelines to protect forensic integrity.},
  langid = {english},
  keywords = {research/anti-forensics},
  note = {Referrent: (Conlan et al., 2016)},
  file = {C:\Users\Kisun\Zotero\storage\4HFGL2P3\Harris - 2006 - Arriving at an anti-forensics consensus Examining.pdf}
}

@article{horsmanDatasetConstructionChallenges2021,
  title = {Dataset Construction Challenges for Digital Forensics},
  author = {Horsman, Graeme and Lyle, James R.},
  year = {2021},
  month = sep,
  journal = {Forensic Science International: Digital Investigation},
  volume = {38},
  pages = {301264},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2021.301264},
  urldate = {2024-12-30},
  abstract = {As the digital forensic field develops, taking steps towards ensuring a level of reliability in the processes implemented by its practitioners, emphasis on the need for effective testing has increased. In order to test, test datasets are required, but creating these is not a straightforward task. A poorly constructed and documented test dataset undermines any testing which has taken place using it, eroding the reliability of any subsequent test results. In essence, given the time, effort and knowledge required to generate datasets, the field must guide those carrying out this task to ensure that it is done right at the first instance without wasting resources. Yet, there are currently few standards and best practices defined for dataset creation in digital forensics. This work defines three categories of dataset which typically exist in digital forensic - tool/process evaluation datasets, actions datasets and scenario-based datasets, where the minimum requirements for their creation are outlined and discussed to support those creating them and to help ensure that where datasets are created, they offer maximum value to the field.},
  keywords = {Datasets,Digital forensics,Testing,Tool-testing},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\W8A44WDJ\\horsmanDatasetConstructionChallenges2021.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\G6LPUVLG\\S2666281721001815.html}
}

@article{janickiObstaclesOpportunitiesDeploying2012,
  title = {Obstacles and Opportunities in Deploying Model-Based {{GUI}} Testing of Mobile Software: A Survey},
  shorttitle = {Obstacles and Opportunities in Deploying Model-Based {{GUI}} Testing of Mobile Software},
  author = {Janicki, Marek and Katara, Mika and P{\"a}{\"a}kk{\"o}nen, Tuula},
  year = {2012},
  journal = {Software Testing, Verification and Reliability},
  volume = {22},
  number = {5},
  pages = {313--341},
  issn = {1099-1689},
  doi = {10.1002/stvr.460},
  urldate = {2024-12-30},
  abstract = {Model-based testing has not been widely deployed in industry yet. There seem to be both technical and non-technical reasons for this situation. A survey among mobile software testing professions in Finland was conducted that aimed at investigating possible obstacles and opportunities towards wider deployment of this technology. This paper discusses the results and provides conclusions that indicate that at least in this context, there is much interest among practitioners towards the technology. However, more research is needed to make model creation and maintenance as easy as possible. In addition, metrics should be developed that can be used to report test results in the same manner as using existing testing techniques, enabling comparison between different approaches. Special emphasis should also be placed on enabling quick bug localization. Furthermore, it seems that successful pilot projects are a key to wider industrial adoption. Based on the survey findings, an agenda for the future model-based testing research is outlined. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {GUI testing,model-based testing,survey},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\LRLN5PIJ\\janickiObstaclesOpportunitiesDeploying2012.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\G8INDWME\\stvr.html}
}

@incollection{jonesInsightDigitalForensics2022,
  title = {An {{Insight}} into {{Digital Forensics}}: {{History}}, {{Frameworks}}, {{Types}} and {{Tools}}},
  shorttitle = {An {{Insight}} into {{Digital Forensics}}},
  booktitle = {Cyber {{Security}} and {{Digital Forensics}}},
  author = {Jones, G Maria and Winster, S Godfrey},
  editor = {Ghonge, Mangesh M. and Pramanik, Sabyasachi and Mangrulkar, Ramchandra and Le, Dac-Nhuong},
  year = {2022},
  month = feb,
  edition = {1},
  pages = {105--125},
  publisher = {Wiley},
  doi = {10.1002/9781119795667.ch6},
  urldate = {2023-11-27},
  isbn = {978-1-119-79563-6 978-1-119-79566-7},
  langid = {english},
  keywords = {research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\44YYJNZ3\jonesInsightDigitalForensics2022.pdf}
}

@inproceedings{lawrenceFrameworkDesignWebbased2009,
  title = {Framework for the Design of Web-Based Learning for Digital Forensics Labs},
  booktitle = {Proceedings of the 47th {{Annual Southeast Regional Conference}}},
  author = {Lawrence, Kevin R. and Chi, Hongmei},
  year = {2009},
  month = mar,
  series = {{{ACM-SE}} 47},
  pages = {1--4},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1566445.1566546},
  urldate = {2023-11-27},
  abstract = {Digital forensic education and training has been experiencing radical growth in the past ten years. The core of these training and academic programs is to develop a set of suitable hands-on digital forensic labs. To do this we first must familiarize ourselves with the tools of the trade. The main step to training students, who are preparing to be computer forensic professionals, lies in creating a comprehensive hands-on approach to computer forensics. The goal of this project work is to establish a series of hands-on computer forensic labs, which help students prepare to accede seamlessly into the law enforcement workforce and to make these labs available online by exploiting technologies of Web-based learning and future web developments, one of this includes the Semantic Web. The Semantic Web will enable intelligent services by several methods which all work towards making information machine-understandable [3]. With this we hope to develop an intelligent Web-based educational system which is capable of demonstrating some form of knowledge-based reasoning in lab sequencing, in analysis of the student's answers combining with students' background, and in providing interactive problem-solving support to the student, all adapted to the Web technology [3].},
  isbn = {978-1-60558-421-8},
  keywords = {digital forensics,e-learning,forensics tools,hand-on labs,information systems,research/image-purpose,research/image-purpose/education,semantic web,web-based},
  file = {C:\Users\Kisun\Zotero\storage\Z4EY4A4C\lawrenceFrameworkDesignWebbased2009.pdf}
}

@article{linAutomatedForensicAnalysis2018,
  title = {Automated Forensic Analysis of Mobile Applications on {{Android}} Devices},
  author = {Lin, Xiaodong and Chen, Ting and Zhu, Tong and Yang, Kun and Wei, Fengguo},
  year = {2018},
  month = jul,
  journal = {Digital Investigation},
  volume = {26},
  pages = {S59-S66},
  doi = {10.1016/j.diin.2018.04.012},
  abstract = {It is not uncommon that mobile phones are involved in criminal activities, e.g., the surreptitious collection of credit card information. Forensic analysis of mobile applications plays a crucial part in order to gather evidences against criminals. However, traditional forensic approaches, which are based on manual investigation, are not scalable to the large number of mobile applications. On the other hand, dynamic analysis is hard to automate due to the burden of setting up the proper runtime environment to accommodate OS differences and dependent libraries and activate all feasible program paths. We propose a fully automated tool, Fordroid for the forensic analysis of mobile applications on Android. Fordroid conducts inter-component static analysis on Android APKs and builds control flow and data dependency graphs. Furthermore, Fordroid identifies what and where information written in local storage with taint analysis. Data is located by traversing the graphs. This addresses several technique challenges, which include inter-component string propagation, string operations (e.g., append) and API invocations. Also, Fordroid identifies how the information is stored by parsing SQL commands, i.e., the structure of database tables. Finally, we selected 100 random Android applications consisting of 2841 components from four categories for evaluation. Analysis of all apps took 64 h. Fordroid discovered 469 paths in 36 applications that wrote sensitive information (e.g., GPS) to local storage. Furthermore, Fordroid successfully located where the information was written for 458 (98\%) paths and identified the structure of all (22) database tables.},
  file = {C:\Users\Kisun\Zotero\storage\PIYYAZ6J\linAutomatedForensicAnalysis2018.pdf}
}

@inproceedings{lucianoDigitalForensicsNext2018,
  title = {Digital {{Forensics}} in the {{Next Five Years}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Luciano, Laoise and Baggili, Ibrahim and Topor, Mateusz and Casey, Peter and Breitinger, Frank},
  year = {2018},
  month = aug,
  series = {{{ARES}} '18},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3230833.3232813},
  urldate = {2024-03-30},
  abstract = {Cyber forensics has encountered major obstacles over the last decade and is at a crossroads. This paper presents data that was obtained during the National Workshop on Redefining Cyber Forensics (NWRCF) on May 23-24, 2017 supported by the National Science Foundation and organized by the University of New Haven. Qualitative and quantitative data were analyzed from twenty-four cyber forensics expert panel members. This work identified important themes that need to be addressed by the community, focusing on (1) where the domain currently is; (2) where it needs to go and; (3) steps needed to improve it. Furthermore, based on the results, we articulate (1) the biggest anticipated challenges the domain will face in the next five years; (2) the most important cyber forensics research opportunities in the next five years and; (3) the most important job-ready skills that need to be addressed by higher education curricula over the next five years. Lastly, we present the key issues and recommendations deliberated by the expert panel. Overall results indicated that a more active and coherent group needs to be formed in the cyber forensics community, with opportunities for continuous reassessment and improvement processes in place.},
  isbn = {978-1-4503-6448-5},
  keywords = {Computer forensics,Cyber Forensics,Digital Forensics,Forensics,Needs analysis,Policy,Research,Tools,Workshop},
  file = {C:\Users\Kisun\Zotero\storage\L52YEH27\lucianoDigitalForensicsNext2018.pdf}
}

@misc{maxfraggMaxfraggForGeOSI2023,
  title = {Maxfragg/{{ForGeOSI}}},
  author = {{maxfragg}},
  year = {2023},
  month = jun,
  urldate = {2025-02-06},
  abstract = {Forensic Generator that automates disk image generation with virtualbox in python. Uses pyvbox as basis.},
  copyright = {BSD-2-Clause}
}

@inproceedings{meffertForensicStateAcquisition2017,
  title = {Forensic {{State Acquisition}} from {{Internet}} of {{Things}} ({{FSAIoT}}): {{A}} General Framework and Practical Approach for {{IoT}} Forensics through {{IoT}} Device State Acquisition},
  shorttitle = {Forensic {{State Acquisition}} from {{Internet}} of {{Things}} ({{FSAIoT}})},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Meffert, Christopher and Clark, Devon and Baggili, Ibrahim and Breitinger, Frank},
  year = {2017},
  month = aug,
  series = {{{ARES}} '17},
  pages = {1--11},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3098954.3104053},
  urldate = {2023-08-30},
  abstract = {IoT device forensics is a difficult problem given that manufactured IoT devices are not standardized, many store little to no historical data, and are always connected; making them extremely volatile. The goal of this paper was to address these challenges by presenting a primary account for a general framework and practical approach we term Forensic State Acquisition from Internet of Things (FSAIoT). We argue that by leveraging the acquisition of the state of IoT devices (e.g. if an IoT lock is open or locked), it becomes possible to paint a clear picture of events that have occurred. To this end, FSAIoT consists of a centralized Forensic State Acquisition Controller (FSAC) employed in three state collection modes: controller to IoT device, controller to cloud, and controller to controller. We present a proof of concept implementation using openHAB -- a device agnostic open source IoT device controller -- and self-created scripts, to resemble a FSAC implementation. Our proof of concept employed an Insteon IP Camera as a controller to device test, an Insteon Hub as a controller to controller test, and a nest thermostat for a a controller to cloud test. Our findings show that it is possible to practically pull forensically relevant state data from IoT devices. Future work and open research problems are shared.},
  isbn = {978-1-4503-5257-4},
  keywords = {Internet of Things,IoT controllers,IoT forensic challenges,IoT forensics framework,IoT research,IoT State acquisition,research/image-sources},
  file = {C:\Users\Kisun\Zotero\storage\WM97Q72I\meffertForensicStateAcquisition2017.pdf}
}

@article{micheletAutomationDigitalForensics2023,
  title = {Automation for Digital Forensics: {{Towards}} a Definition for the Community},
  shorttitle = {Automation for Digital Forensics},
  author = {Michelet, Ga{\"e}tan and Breitinger, Frank and Horsman, Graeme},
  year = {2023},
  month = aug,
  journal = {Forensic Science International},
  volume = {349},
  pages = {111769},
  issn = {0379-0738},
  doi = {10.1016/j.forsciint.2023.111769},
  urldate = {2024-12-03},
  abstract = {Automation is crucial for managing the increasing volume of~digital~evidence. However, the absence of a clear foundation comprising a definition, classification, and common terminology has led to a fragmented landscape where diverse interpretations of automation exist.~This resembles the wild west: some consider keyword searches or file carving as automation while others do not. We, therefore, reviewed automation literature (in the domain of digital forensics and other domains), performed three practitioner interviews, and discussed the topic with domain experts from academia. On this basis, we propose a definition and then showcase several considerations concerning automation for digital forensics, e.g., what we classify as no/basic automation or full automation (autonomous). We conclude that it requires these foundational discussions to promote and progress the discipline through a common understanding.},
  keywords = {Automation,Definition,Digital Forensic investigation,Investigative task,Practitioner interviews},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\Q6TNK592\\micheletAutomationDigitalForensics2023.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\MCBTE9XQ\\S0379073823002190.html}
}

@misc{MicrosoftPlaywrightpython2025,
  title = {Microsoft/Playwright-Python},
  year = {2025},
  month = feb,
  urldate = {2025-02-05},
  abstract = {Python version of the Playwright testing and automation library.},
  copyright = {Apache-2.0},
  howpublished = {Microsoft},
  keywords = {chromium,firefox,playwright,webkit}
}

@incollection{mochEvaluatingForensicImage2012,
  title = {Evaluating the {{Forensic Image Generator Generator}}},
  booktitle = {Digital {{Forensics}} and {{Cyber Crime}}},
  author = {Moch, Christian and Freiling, Felix C.},
  editor = {Gladyshev, Pavel and Rogers, Marcus K.},
  year = {2012},
  volume = {88},
  pages = {238--252},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-35515-8_20},
  urldate = {2023-11-26},
  isbn = {978-3-642-35514-1 978-3-642-35515-8},
  keywords = {research/synthesizer-details},
  note = {Referred to by (Park, 2018)},
  file = {C:\Users\Kisun\Zotero\storage\2GS7GZPS\mochEvaluatingForensicImage2012.pdf}
}

@inproceedings{mochForensicImageGenerator2009,
  title = {The {{Forensic Image Generator Generator}} ({{Forensig2}})},
  booktitle = {2009 {{Fifth International Conference}} on {{IT Security Incident Management}} and {{IT Forensics}}},
  author = {Moch, Christian and Freiling, Felix C.},
  year = {2009},
  pages = {78--93},
  publisher = {IEEE},
  address = {Stuttgart, Germany},
  doi = {10.1109/IMF.2009.8},
  urldate = {2023-09-17},
  isbn = {978-0-7695-3807-5},
  keywords = {research/synthesizer-details},
  note = {Referrent: (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\CLH8CU3P\mochForensicImageGenerator2009.pdf}
}

@article{montasariRoadMapDigital2019,
  title = {A Road Map for Digital Forensics Research: A Novel Approach for Establishing the Design Science Research Process in Digital Forensics},
  shorttitle = {A Road Map for Digital Forensics Research},
  author = {Montasari, Reza and Carpenter, Victoria and Hill, Richard},
  year = {2019},
  journal = {IJESDF},
  volume = {11},
  number = {2},
  pages = {194},
  issn = {1751-911X, 1751-9128},
  doi = {10.1504/IJESDF.2019.098784},
  urldate = {2023-12-02},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\MS5CV2XF\montasariRoadMapDigital2019.pdf}
}

@inproceedings{nanceDigitalForensicsDefining2009,
  title = {Digital {{Forensics}}: {{Defining}} a {{Research Agenda}}},
  shorttitle = {Digital {{Forensics}}},
  booktitle = {2009 42nd {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Nance, Kara and Hay, Brian and Bishop, Matt},
  year = {2009},
  pages = {1--6},
  publisher = {IEEE},
  address = {Waikoloa, Hawaii, USA},
  doi = {10.1109/HICSS.2009.160},
  urldate = {2023-11-26},
  isbn = {978-0-7695-3450-3},
  keywords = {research/image-purpose},
  note = {Root},
  file = {C:\Users\Kisun\Zotero\storage\P5BSME2P\DigitalForensicsDefining2009.pdf}
}

@inproceedings{nanceDigitalForensicsDefining2010,
  title = {Digital {{Forensics}}: {{Defining}} an {{Education Agenda}}},
  shorttitle = {Digital {{Forensics}}},
  booktitle = {2010 43rd {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Nance, Kara and Armstrong, Helen and Armstrong, Colin},
  year = {2010},
  month = jan,
  pages = {1--10},
  issn = {1530-1605},
  doi = {10.1109/HICSS.2010.151},
  urldate = {2023-11-27},
  abstract = {While many fields have well-defined education agendas, this is not the case for digital forensics. A unique characteristic of the evolution of digital forensics is that it has been largely driven by practitioners in the field. As a result, the majority of the educational experiences have been developed in response to identified weaknesses in the system or to train individuals on the use of a specific tool or technique, rather than as a result of educational needs assessments based on an accepted common body of knowledge. In June, 2008 a group of digital forensics researchers, educators and practitioners met as a working group at the Colloquium for Information Systems Security Education (CISSE 2008) to brainstorm ideas for the development of a research, education, and outreach agenda for Digital Forensics. This paper presents the research in education needs that the group identified associated with the development of a digital forensics education agenda.},
  keywords = {research/image-purpose,research/image-purpose/education},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\BRWC9BWD\\nanceDigitalForensicsDefining2010.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\JLPFBF8K\\5428493.html}
}

@misc{nationalinstituteofstandardsandtechnologyCFReDSDataLeakage,
  title = {{{CFReDS}} - {{Data Leakage Case}}},
  author = {{National Institute of Standards and Technology}},
  journal = {CFReDS Archive},
  urldate = {2023-12-04},
  howpublished = {https://cfreds-archive.nist.gov/data\_leakage\_case/data-leakage-case.html},
  file = {C:\Users\Kisun\Zotero\storage\H8S5NZ5M\data-leakage-case.html}
}

@misc{nationalinstituteofstandardsandtechnologyCFReDSPortal,
  title = {{{CFReDS Portal}}},
  author = {{National Institute of Standards and Technology}},
  urldate = {2023-12-04},
  howpublished = {https://cfreds.nist.gov/},
  file = {C:\Users\Kisun\Zotero\storage\D44C426A\cfreds.nist.gov.html}
}

@misc{nationalinstituteofstandardsandtechnologyComputerForensicsTool2017,
  title = {Computer {{Forensics Tool Testing Program}} ({{CFTT}})},
  author = {{National Institute of Standards and Technology}},
  year = {2017},
  month = may,
  journal = {NIST},
  urldate = {2023-12-04},
  abstract = {Welcome to the Computer Forensics Tool Testing (CFTT) Project Web Site.},
  howpublished = {https://www.nist.gov/itl/ssd/software-quality-group/computer-forensics-tool-testing-program-cftt},
  langid = {english},
  annotation = {Last Modified: 2019-11-15T19:42-05:00},
  file = {C:\Users\Kisun\Zotero\storage\LUKSF3Q2\computer-forensics-tool-testing-program-cftt.html}
}

@inproceedings{neyazForensicAnalysisWear2018,
  title = {Forensic {{Analysis}} of {{Wear Leveling}} on {{Solid-State Media}}},
  booktitle = {2018 17th {{IEEE International Conference On Trust}}, {{Security And Privacy In Computing And Communications}}/ 12th {{IEEE International Conference On Big Data Science And Engineering}} ({{TrustCom}}/{{BigDataSE}})},
  author = {Neyaz, Ashar and Shashidhar, Narasimha and Karabiyik, Umit},
  year = {2018},
  month = aug,
  pages = {1706--1710},
  issn = {2324-9013},
  doi = {10.1109/TrustCom/BigDataSE.2018.00256},
  urldate = {2025-02-05},
  abstract = {Traditional hard drives are slowly becoming things of the past as newer technologies are constantly demanding lighter, faster, and more reliable alternatives. Solid-state media have started to permeate the market in an effort to satisfy this demand. Some tech giants have already started to use solid-state media in their products but are facing substantial price and storage capacity penalties. When it comes to performing forensic analysis on these solid-state media, the autonomous behavior of the media does not look promising as it has serious reliability issues compared to traditional media. With wear-leveling always enabled, the persistence of deleted data is always in question. The deleted data can stay on the media either partially or wholly and is dependent on various factors like the file system used on the media, capacity, manufacturer, software level TRIM functionality and also on the type of the operating system used. In this research, we analyzed different types of flash and solid-state media by filling them up with different types of files an conducted exhaustive experiments to identify the probability of recovering and file-carving once these files are deleted. The aim of this paper is to give a detailed analysis that will provide a benchmark for digital forensics investigators who are constantly troubled by the thought of analyzing solid-state media.},
  keywords = {Computer science,Digital forensics,Drives,file carving,file recovery,Media,Operating systems,Reliability,Solid State Drive,SSD Forensics,TRIM function,wear leveling},
  file = {C:\Users\Kisun\Zotero\storage\D6RVUYWZ\neyazForensicAnalysisWear2018.pdf}
}

@techreport{nistNISTCybersecurityFramework2023,
  title = {The {{NIST Cybersecurity Framework}} 2.0},
  author = {Nist, Gaithersburg Md},
  year = {2023},
  number = {NIST CSWP 29 ipd},
  pages = {NIST CSWP 29 ipd},
  address = {Gaithersburg, MD},
  institution = {{National Institute of Standards and Technology}},
  doi = {10.6028/NIST.CSWP.29.ipd},
  urldate = {2023-12-03},
  file = {C:\Users\Kisun\Zotero\storage\3DRHA2ND\nistNISTCybersecurityFramework2023.pdf}
}

@inproceedings{palmerRoadMapDigital2001,
  title = {A {{Road Map}} for {{Digital Forensic Research}}},
  booktitle = {The {{Digital Forensic Research Conference}}},
  author = {Palmer, Gary and {The MITRE Corporation}},
  year = {2001},
  month = nov,
  address = {Utica, NY},
  urldate = {2023-12-02},
  file = {C:\Users\Kisun\Zotero\storage\6AF68JSP\palmerRoadMapDigital2001.pdf}
}

@article{parkTREDEVMPOPCultivating2018,
  title = {{{TREDE}} and {{VMPOP}}: {{Cultivating}} Multi-Purpose Datasets for Digital Forensics -- {{A Windows}} Registry Corpus as an Example},
  shorttitle = {{{TREDE}} and {{VMPOP}}},
  author = {Park, Jungheum},
  year = {2018},
  month = sep,
  journal = {Digital Investigation},
  volume = {26},
  pages = {3--18},
  issn = {17422876},
  doi = {10.1016/j.diin.2018.04.025},
  urldate = {2023-09-17},
  langid = {english},
  keywords = {research/synthesizer-details},
  note = {Referred to by (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\MBUN7T26\parkTREDEVMPOPCultivating2018.pdf}
}

@article{pessolanoForensicAnalysisNintendo2019,
  title = {Forensic {{Analysis}} of the {{Nintendo 3DS NAND}}},
  author = {Pessolano, Gus and Read, Huw O.L. and Sutherland, Iain and Xynos, Konstantinos},
  year = {2019},
  month = jul,
  journal = {Digital Investigation},
  volume = {29},
  pages = {S61-S70},
  issn = {17422876},
  doi = {10.1016/j.diin.2019.04.015},
  urldate = {2023-12-04},
  abstract = {Games consoles present a particular challenge to the forensics investigator due to the nature of the hardware and the inaccessibility of the file system. Many protection measures are put in place to make it deliberately difficult to access raw data in order to protect intellectual property, enhance digital rights management of software and, ultimately, to protect against piracy. History has shown that many such protections on game consoles are circumvented with exploits leading to jailbreaking/rooting and allowing unauthorized software to be launched on the games system. This paper details methods that enable the investigator to extract system activity, deleted images, Internet history items, relevant friends list information, the console's serial number and plaintext WiFi access point passwords. This is all possible with the use of publicly available, open-source security circumvention techniques that perform a non-invasive physical dump of the internal NAND storage of the Nintendo 3DS handheld device. It will also be shown that forensic integrity is maintained and a detailed analysis is possible without altering original evidence.},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\4CWIQBAZ\pessolanoForensicAnalysisNintendo2019.pdf}
}

@incollection{pollittHistoryDigitalForensics2010,
  title = {A {{History}} of {{Digital Forensics}}},
  booktitle = {Advances in {{Digital Forensics VI}}},
  author = {Pollitt, Mark},
  editor = {Chow, Kam-Pui and Shenoi, Sujeet},
  year = {2010},
  volume = {337},
  pages = {3--15},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15506-2_1},
  urldate = {2023-12-03},
  isbn = {978-3-642-15505-5 978-3-642-15506-2},
  file = {C:\Users\Kisun\Zotero\storage\AZIT7SQV\pollittHistoryDigitalForensics2010.pdf}
}

@article{rahmanNewWebForensic2020,
  title = {A New Web Forensic Framework for Bot Crime Investigation},
  author = {Rahman, Rizwan Ur and Tomar, Deepak Singh},
  year = {2020},
  month = jun,
  journal = {Forensic Science International: Digital Investigation},
  volume = {33},
  pages = {300943},
  issn = {2666-2817},
  doi = {10.1016/j.fsidi.2020.300943},
  urldate = {2023-08-31},
  abstract = {Bots are automated programs that robotically navigate the website, upload the data on servers and scrape the data from websites. According to numerous bot traffic reports nearly fifty percent of the website traffic is coming from automated programs. In recent years we have seen a rise in cyber crimes such as illegal web scraping using automated bots. Facebook filed and won a case against Power.com for illegally scraping the Facebook data. Recently in one of the biggest online ticketing scams, a man was arrested for illegally booking tickets using automated bots. While mitigating cyber crime, web forensic investigators face numerous challenges and issues dealing with bot crimes. Most of the existing research is based on web access logs which contain very basic and limited information. In this paper, we propose four phase web forensic framework to guide forensic examiners in their expedition to verify if the crime is done using automated bots. In order to evaluate the proposed framework, we applied it to the real web application and experimental case scenario. For this case study, a bot crime scenario is developed in an investigation environment. Subsequently, we present in depth forensic procedures and technical reports for bot crime investigation.},
  keywords = {Cyber crime,Forensic framework,research/image-sources,Spam bot,Web bot,Web forensic,Web scrapping},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\8CU55B8B\\rahmanNewWebForensic2020.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\5KH74GY9\\S2666281720300718.html}
}

@misc{Requests31Documentation,
  title = {Requests 2.31.0 Documentation},
  urldate = {2023-12-05},
  howpublished = {https://requests.readthedocs.io/en/latest/},
  file = {C:\Users\Kisun\Zotero\storage\LG22AJL8\latest.html}
}

@techreport{robertkominskiComputerUseUnited1988,
  type = {Current {{Population Reports}}},
  title = {Computer {{Use}} in the {{United States}}: 1984},
  author = {{Robert Kominski}},
  year = {1988},
  month = mar,
  number = {155},
  address = {Washington, D.C.},
  institution = {U.S. Bureau of the Census},
  file = {C:\Users\Kisun\Zotero\storage\SR5VE4XK\robertkominskiComputerUseUnited1988.pdf}
}

@techreport{robertkominskiComputerUseUnited1991,
  type = {Current {{Population Reports}}},
  title = {Computer {{Use}} in the {{United States}}: 1989},
  author = {{Robert Kominski}},
  year = {1991},
  month = feb,
  number = {171},
  address = {Washington, D.C.},
  institution = {U.S. Bureau of the Census},
  file = {C:\Users\Kisun\Zotero\storage\8LAX9HYB\robertkominskiComputerUseUnited1991.pdf}
}

@article{rooseAIgeneratedPictureWon2022,
  title = {An {{AI-generated}} Picture Won an Art Prize. {{Artists}} Aren't Happy},
  author = {Roose, Kevin},
  year = {2022},
  month = sep,
  journal = {The New York Times},
  file = {C:\Users\Kisun\Zotero\storage\SYZJK5IK\rooseAIgeneratedPictureWon2022.pdf}
}

@article{russellForensicImageDescription2012,
  title = {A {{Forensic Image Description Language}} for {{Generating Test Images}}},
  author = {Russell, Dr Gordon and Macfarlane, Rich and Ludwiniak, Robert},
  year = {2012},
  abstract = {Digital Forensics is a fast developing job market, as well as being topical and interesting, and as such is an area in which University students are keen to develop and study. At Edinburgh Napier University this topic has been taught with flexible and distance learning students in mind, and to promote accessibility the practical exercises have been formed around the use of cloud-based technologies. This approach has highlighted a key issue, in that cost-effective cloud-based resources struggle to provide adequate CPU and IO capabilities to drive large simultaneous student numbers when performing forensic exercises on disk images created using physical disk acquisition techniques obtained from real systems. This paper considers the issue, and proposes a simplistic and easily reconfigurable image creation technique specifically designed to support digital forensic practical sessions.},
  langid = {english},
  keywords = {research/synthesizer-details},
  note = {Referred to by (Park, 2018)},
  file = {C:\Users\Kisun\Zotero\storage\57MYGQDE\russellForensicImageDescription2012.pdf}
}

@article{scanlonEviPlantEfficientDigital2017,
  title = {{{EviPlant}}: {{An}} Efficient Digital Forensic Challenge Creation, Manipulation and Distribution Solution},
  shorttitle = {{{EviPlant}}},
  author = {Scanlon, Mark and Du, Xiaoyu and Lillis, David},
  year = {2017},
  month = mar,
  journal = {Digital Investigation},
  series = {{{DFRWS}} 2017 {{Europe}}},
  volume = {20},
  pages = {S29-S36},
  issn = {1742-2876},
  doi = {10.1016/j.diin.2017.01.010},
  urldate = {2023-08-31},
  abstract = {Education and training in digital forensics requires a variety of suitable challenge corpora containing realistic features including regular wear-and-tear, background noise, and the actual digital traces to be discovered during investigation. Typically, the creation of these challenges requires overly arduous effort on the part of the educator to ensure their viability. Once created, the challenge image needs to be stored and distributed to a class for practical training. This storage and distribution step requires significant time and resources and may not even be possible in an online/distance learning scenario due to the data sizes involved. As part of this paper, we introduce a more capable methodology and system as an alternative to current approaches. EviPlant is a system designed for the efficient creation, manipulation, storage and distribution of challenges for digital forensics education and training. The system relies on the initial distribution of base disk images, i.e., images containing solely base operating systems. In order to create challenges for students, educators can boot the base system, emulate the desired activity and perform a ``diffing'' of resultant image and the base image. This diffing process extracts the modified artefacts and associated metadata and stores them in an ``evidence package''. Evidence packages can be created for different personae, different wear-and-tear, different emulated crimes, etc., and multiple evidence packages can be distributed to students and integrated into the base images. A number of additional applications in digital forensic challenge creation for tool testing and validation, proficiency testing, and malware analysis are also discussed as a result of using EviPlant.},
  keywords = {Digital forensic challenges,Digital forensics education,Evidence injection,Forensic corpora,research/synthesizer-details,Tool testing and validation},
  note = {Referrent: (G{\"o}bel et al., 2022)},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\UQ5CNFNK\\scanlonEviPlantEfficientDigital2017.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\T82A8JQS\\S1742287617300397.html}
}

@misc{SeleniumBrowserAutomation,
  title = {The {{Selenium Browser Automation Project}}},
  journal = {Selenium},
  urldate = {2023-12-05},
  abstract = {Selenium automates browsers. That's it!},
  howpublished = {https://www.selenium.dev/documentation/},
  langid = {english},
  file = {C:\Users\Kisun\Zotero\storage\39NW9LWE\documentation.html}
}

@misc{SeleniumPythonBindings,
  title = {Selenium {{Python Bindings}} 2 Documentation},
  urldate = {2023-12-05},
  howpublished = {https://selenium-python.readthedocs.io/},
  file = {C:\Users\Kisun\Zotero\storage\RP5IU42A\selenium-python.readthedocs.io.html}
}

@article{srinivasanDigitalForensicsCurriculum2013,
  title = {Digital Forensics Curriculum in Security Education},
  author = {Srinivasan, S},
  year = {2013},
  journal = {Journal of Information Technology Education. Innovations in Practice},
  volume = {12},
  pages = {147},
  publisher = {Informing Science Institute},
  file = {C:\Users\Kisun\Zotero\storage\Z6N6IKC8\srinivasanDigitalForensicsCurriculum2013.pdf}
}

@article{tervoortSolutionsMitigatingCybersecurity2020,
  title = {Solutions for {{Mitigating Cybersecurity Risks Caused}} by {{Legacy Software}} in {{Medical Devices}}: {{A Scoping Review}}},
  shorttitle = {Solutions for {{Mitigating Cybersecurity Risks Caused}} by {{Legacy Software}} in {{Medical Devices}}},
  author = {Tervoort, Tom and De Oliveira, Marcela Tuler and Pieters, Wolter and Van Gelder, Pieter and Olabarriaga, Silvia Delgado and Marquering, Henk},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {84352--84361},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2984376},
  urldate = {2024-09-13},
  abstract = {Cyberattacks against healthcare institutions threaten patient care. The risk of being targeted by a damaging attack is increased when medical devices are used which rely on unmaintained legacy software that cannot be replaced and may have publicly known vulnerabilities. This review aims to provide insight into solutions presented in the literature that mitigate risks caused by legacy software on medical devices. We performed a scoping review by categorising and analysing the contributions of a selection of articles, taken from a literature set discovered through bidirectional citation searching. We found 18 solutions, each fitting at least one of the categories of intrusion detection and prevention, communication tunnelling or hardware protections. Approaches taken include proxying Bluetooth communication through smartphones, behaviour-specification based anomaly detection and authenticating signals based on physical characteristics. These solutions are applicable to various use-cases, ranging from securing pacemakers to medical sensor networks. Most of the solutions are based on intrusion detection and on tunnelling insecure wireless communications. These technologies have distinct application areas, and the decision which one is most appropriate will depend on the type of medical device.},
  keywords = {Computer security,Healthcare,Intrusion detection,legacy software,medical devices,Medical devices,Medical services,Performance evaluation,security,Software},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\UWTEXE4A\\tervoortSolutionsMitigatingCybersecurity2020.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\FNZY3DE6\\9050776.html}
}

@misc{TheoryOperationRPyC,
  title = {Theory of {{Operation}} --- {{RPyC}}},
  urldate = {2025-02-06},
  howpublished = {https://rpyc.readthedocs.io/en/latest/docs/theory.html\#theory},
  file = {C:\Users\Kisun\Zotero\storage\FVVJP4K3\theory.html}
}

@misc{TomerfilibaorgRpyc2025,
  title = {Tomerfiliba-Org/Rpyc},
  year = {2025},
  month = feb,
  urldate = {2025-02-05},
  abstract = {RPyC (Remote Python Call) - A transparent and symmetric RPC library for python},
  howpublished = {tomerfiliba-org}
}

@incollection{vistiAutomaticCreationComputer2015,
  title = {Automatic {{Creation}} of {{Computer Forensic Test Images}}},
  booktitle = {Computational {{Forensics}}},
  author = {Visti, Hannu and Tohill, Sean and Douglas, Paul},
  editor = {Garain, Utpal and Shafait, Faisal},
  year = {2015},
  volume = {8915},
  pages = {163--175},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-20125-2_14},
  urldate = {2023-09-17},
  isbn = {978-3-319-20124-5 978-3-319-20125-2},
  langid = {english},
  keywords = {research/synthesizer-details},
  note = {Referrent: (G{\"o}bel et al., 2022)},
  file = {C:\Users\Kisun\Zotero\storage\T3LUHK5Z\vistiAutomaticCreationComputer2015.pdf}
}

@article{williamCloudbasedDigitalForensics2011,
  title = {Cloud-Based Digital Forensics Evaluation Test ({{D-FET}}) Platform.},
  author = {William, Prof and Buchanan, William and Macfarlane, Richard and Flandrin, Flavien and Graves, Jamie and Buchanan, Bill and Computers, Dell and Lu, Dr and Ekonomou, Elias and Bose, Niladri and Ludwiniak, Robert},
  year = {2011},
  month = jan,
  abstract = {This paper outlines the specification of the Cloud-based D-FET platform which is used to evaluate the performance of digital foren-sics tools, which aim to detect the presence of trails of evidence, such as for the presence of illicit images and determination of user accounts from a host. Along with measuring key quality metrics, such as true-positives, and false-positives, it also measures operational performance, such as for the speed of success, CPU utilization and memory usage. This is used to determine the basic footprint of the package-under-test. The paper presents a proof-of-concept of the system using the VMware vSphere Hypervisor (ESXi) within the vCenter Cloud management in-frastructure, which provides a cluster environment, and supports the cre-ation and instantiation of a well-defined virtual test operation system. The infrastructure has been used within a teaching environment for two semesters, and has been shown to cope well in terms of performance and administration. Two key evaluation points related to whether a cloud-based infrastructure will provide improvement on existing stand-alone and workstation-based virtualisation are related to the improvement in energy consumption and in the CPU utilization footprint for each virtual machine. Thus the results show some metrics related to the energy and CPU consumptions of the created digital forensics instances, which can be used to justify the improvements in energy consumption, as opposed to stand-alone instances, and in the scalability of the infrastructure.},
  keywords = {research/synthesizer-details},
  note = {Referred to by (Park, 2018)},
  file = {C:\Users\Kisun\Zotero\storage\S6483Q2Q\William et al. - 2011 - Cloud-based digital forensics evaluation test (D-F.pdf}
}

@article{withersj.ElectronicallyStoredInformation2006,
  title = {Electronically {{Stored Information}}: {{The December}} 2006 {{Amendments}} to the {{Federal Rules}} of {{Civil Procedure}}},
  author = {Withers J., Kenneth},
  year = {2006},
  journal = {Northwestern Journal of Technology and Intellectual Property},
  volume = {4},
  number = {2},
  pages = {171},
  file = {C:\Users\Kisun\Zotero\storage\3XSI9JBC\withersj.ElectronicallyStoredInformation2006.pdf}
}

@article{woodsCreatingRealisticCorpora2011,
  title = {Creating {{Realistic Corpora}} for {{Security}} and {{Forensic Education}}},
  author = {Woods, Kam and Lee, Christopher and Garfinkel, Simson and Dittrich, David and Russell, Adam and Kearton, Kris},
  year = {2011},
  month = jan,
  journal = {Proceedings of the ADFSL Conference on Digital Forensics Security and Law},
  abstract = {We present work on the design, implementation, distribution, and use of realistic forensic datasets to support digital forensics and security education. We describe in particular the "M57-Patents" scenario, a multi-modal corpus consisting of hard drive images, RAM images, network captures, and images from other devices typically found in forensics investigations such as USB drives and cellphones. Corpus creation has been performed as part of a scripted scenario; subsequently it is less "noisy" than real-world data but retains the complexity necessary to support a wide variety of forensic education activities. Realistic forensic corpora allow direct comparison of approaches and tools across classrooms and institutions, reduce the time required to prepare useful educational materials, and eliminate concerns of exposing students to privacy-sensitive or illegal digital materials. The "M57-Patents" corpus can be freely redistributed without rights-restricted materials, and is available with disk images packaged in both open (Advanced Forensic Format) and commercial (EnCase) formats.},
  keywords = {research/image-purpose},
  file = {C:\Users\Kisun\Zotero\storage\LF9G9FS9\woodsCreatingRealisticCorpora2011.pdf}
}

@inproceedings{xuDesigningSharedDigital2022,
  title = {Towards {{Designing Shared Digital Forensics Instructional Materials}}},
  booktitle = {2022 {{IEEE}} 46th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  author = {Xu, Weifeng and Deng, Lin and Xu, Dianxiang},
  year = {2022},
  month = jun,
  pages = {117--122},
  issn = {0730-3157},
  doi = {10.1109/COMPSAC54236.2022.00025},
  urldate = {2023-11-27},
  abstract = {This paper presents a systematic approach to designing a series of digital forensics instructional materials to address the severe shortage of active learning materials in the digital forensics community. The materials include real-world scenario-based case studies, a set of hands-on problem-driven labs for each case study, and an integrated forensic investigation environment. In this paper, we first clarify some fundamental concepts related to digital forensics, such as digital forensic artifacts, artifact generators, and evidence. We then re-categorize knowledge units of digital forensics based on the artifact generators for measuring the coverage of learning outcomes and topics. Finally, we utilize a real-world cybercrime scenario to demonstrate how knowledge units, digital forensics topics, concepts, artifacts, and investigation tools can be infused into each lab through active learning. The repository of the instructional materials is publicly available on GitHub. It has gained nearly 600 stars and 22k views within several months.},
  keywords = {research/image-purpose,research/image-purpose/education},
  note = {Root, found when looking for (Lawrence and Chi, 2009)},
  file = {C\:\\Users\\Kisun\\Zotero\\storage\\LQPESEMY\\xuDesigningSharedDigital2022.pdf;C\:\\Users\\Kisun\\Zotero\\storage\\4DBTMYX2\\9842462.html}
}

@inproceedings{yannikosDataCorporaDigital2014,
  title = {Data {{Corpora}} for {{Digital Forensics Education}} and {{Research}}},
  booktitle = {Advances in {{Digital Forensics X}}},
  author = {Yannikos, York and Graner, Lukas and Steinebach, Martin and Winter, Christian},
  editor = {Peterson, Gilbert and Shenoi, Sujeet},
  year = {2014},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {309--325},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-44952-3_21},
  abstract = {Data corpora are very important for digital forensics education and research. Several corpora are available to academia; these range from small manually-created data sets of a few megabytes to many terabytes of real-world data. However, different corpora are suited to different forensic tasks. For example, real data corpora are often desirable for testing forensic tool properties such as effectiveness and efficiency, but these corpora typically lack the ground truth that is vital to performing proper evaluations. Synthetic data corpora can support tool development and testing, but only if the methodologies for generating the corpora guarantee data with realistic properties.},
  isbn = {978-3-662-44952-3},
  langid = {english},
  keywords = {Forensic data corpora,model-based simulation,research/image-purpose,research/image-sources,research/synthesizer-details,synthetic disk images},
  file = {C:\Users\Kisun\Zotero\storage\IM7Y7AW2\yannikosDataCorporaDigital2014.pdf}
}

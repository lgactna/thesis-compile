This chapter addresses the mechanisms through which AKF generates and
documents its outputs, depicted in the partial architectural diagram
below.

!\textbf{39.5 - Output and validation 2025-02-08 17.13.11.excalidraw}

This chapter addresses the role of the output and validation library in
providing several services to AKF, including a centralized logging
system, the use of CASE objects, and invoking various commands to
generate and export outputs such as disk images, network captures, and
volatile memory dumps. It also describes high-level reporting and
validation functionalities, both those as part of the framework itself
and options available through external tools.

\section{Overview}\label{overview}

Whether generating artifacts through physical or logical means, these
artifacts must ultimately be exported and documented. In most cases,
this involves generating disk images, volatile memory captures, or
network captures; additionally, specific artifacts, such as browser
artifacts, may be selectively copied from a filesystem. Disk, memory,
and network captures will be referred to as ``core outputs'' for
brevity, as well as to distinguish them from ``standalone'' artifacts;
both of these are simply ``outputs''.

In either case, the contents and details of these artifacts, as well as
the means through which they were generated, should be documented in
some format. The term ``ground truth'' describes the contents of a
single specific dataset in full. That is, it ideally provides a
reference for every artifact that can be discovered within a dataset, as
well as every action taken to plant those artifacts. This metadata, in
addition to core outputs and standalone artifacts, comprises a forensic
dataset.

From an educational perspective, the ground truth represents an ``answer
key'' to the dataset; it details every artifact of interest that an
analyst could be expected to discover. For research, it allows for
well-labeled datasets that can be used for tool development, validation,
and testing. Importantly, this should be generated in a manner
independent of the input script used to construct the scenario, allowing
\emph{all} artifacts to be documented, including those not explicitly
declared or deemed important by the scenario creator.

The remainder of this chapter describes the mechanisms through which
outputs are exported from the synthesizer and the mechanisms that allow
for real-time logging and documentation.

\section{Core outputs}\label{core-outputs}

In the same way that artifacts can be generated through logical and
physical means, outputs can also be generated through logical and
physical means. Some of these are analogous to techniques used by
real-world investigators to extract forensically sound evidence that is
valid in a court of law, while others are less suitable in a court
setting but still have valid use cases.

Logical output generation refers to any technique in which software is
used inside a running virtual machine to generate these outputs. This
includes using software such as FTK Imager, booted from a removable
drive, to capture the volatile memory of a device or construct a
\emph{logical} disk image. Similarly, network captures can be done by
simply running Wireshark on the target device and network interface, and
individual artifacts can be copied off of the device by hand and sent to
a network or removable drive.

Physical output generation refers to techniques in which the operating
system is unaware of the technique being used, and therefore leave few
or no traces in the resulting outputs. In practice, this involves using
tools such as hardware write blockers to extract complete disk images
(which also contain standalone artifacts), as well as using network taps
and sniffers (or another traffic mirroring solution) to capture traffic
over a particular interface. Although difficult, it is also possible to
perform a physical extraction of RAM by performing a ``cold boot
attack'', in which the RAM sticks are cooled to low temperatures before
removing them from a running machine, slowing the process of memory
decay as a result of the DRAM cells being unpowered
\cite{yitbarekColdBootAttacks2017}.

AKF directly supports physical output generation for all three core
outputs, and indirectly supports logical output generation for core
outputs and standalone artifacts. Physical output generation for virtual
machines is generally achieved through direct interaction with the
hypervisor itself.

\begin{itemize}
\tightlist
\item
  For disk images, the output can simply be the virtual hard drive used
  by the hypervisor on the host machine (such as VDIs for VirtualBox).
  If an ``actual'' disk image is desired, the command-line tool
  VBoxManage supports converting various virtual drive formats to raw
  disk images using the \passthrough{\lstinline!vboxmanage clonemedium!}
  command, which also expands the compressed virtual drive to the
  ``declared'' size of the drive as seen by the operating system.\\
\item
  For network captures, VirtualBox allows the user to enable network
  tracing over multiple interfaces, dumping network traffic as a .pcap
  file on the host machine. This can be enabled or disabled at any time
  without affecting network connectivity or the state of the virtual
  machine.\\
\item
  For volatile memory dumps, VBoxManage provides the command `vboxmanage
  debugvm \textless machine\_name
\end{itemize}

In most cases, these physical output options are sufficient to generate
suitable datasets. If only specific files are desired, the existing file
transfer utilities provided by AKF can be used to extract standalone
artifacts. Users can also manually perform the logical techniques
described above (such as running Wireshark or installing FTK Imager)
through a variety of means, such as pausing an AKF script until
instructed by the user to continue; during this time, a user can
manually run FTK imager to extract the contents of RAM, as an example.

\section{Metadata and ground
truth}\label{metadata-and-ground-truth}

\subsection{Overview}\label{overview-1}

There exists a gap in the ability of instructors and researchers to
perform bulk searches for specific forensic artifacts in public
datasets. For example, the NIST CFReDS repository
\cite{nationalinstituteofstandardsandtechnologyCFReDSPortal}, one of
the largest listings of forensic datasets, does not have a unified
standard for describing uploaded images. While it is possible for users
to search by keywords and human-applied tags, these are not presented in
a standardized format.

For most datasets, an analyst must read through a PDF answer key (if one
exists) or analyze the image themselves to determine if a particular
artifact is present. Such formats are not immediately machine-readable,
and are therefore difficult to use in bulk searches. Additionally, the
content of human-made reports may be limited to what the author believes
is significant, even if other artifacts of interest are present in the
image. In turn, it may be difficult to quickly determine if a dataset is
useful in demonstrating a particular technique to students, or in
validating a specific feature of a newly-developed tool.

A rigid, well-defined format for ground truth is invaluable to
researchers engaging in tool validation and development. It is easy to
write an automated converter for well-structured data into natural
language; it is likely more difficult to perform the reverse operation.
Perhaps the lack of labeled forensic datasets on major repositories may
be attributable to the lack of a need for one; Grajeda et
al.~demonstrated that few scenarios are shared between researchers to
begin with, so there is rarely a need to label them for general-purpose
usage. AKF has the opportunity to solve this issue by allowing for the
mass production of labeled datasets, adopting a single major standard.

Many forensic analysis tools support exporting case data in both
proprietary and language-agnostic formats. For example, Cellebrite's
UFED supports exporting to UFDR and XML files, Magnet Axiom supports
exporting to XML, and Autopsy supports a variety of formats including
Excel, STIX, and HTML. Each of these vary in structure and format, and
do not necessarily contain equivalent information for the same analyzed
disk image using default settings. This is the primary challenge with
using an existing format, especially a proprietary format that is
subject to vendor changes; certain details may be missing, and may
change at an arbitrary point in time.

There has been extensive work in other fields towards developing a
structured ontology that describes relationships and low-level details.
This includes the EVIDENCE project for criminal justice and the
Structured Threat Information Expression (STIX) format for conveying
cyber threat intelligence
\cite{caseyLeveragingCybOXStandardize2015}. For example, STIX
provides a standard set of objects that allows organizations to describe
observed attacker techniques and associate them with specific pieces of
malware, attack campaigns, or threat actors.

However, there is limited work that aims to document the contents of a
forensic scenario (disk images and related metadata) in a vendor-neutral
manner. Besides their lack of adoption, Casey et al.~found that existing
formats lacked features such as parent-child relationships, user
actions, and non-technical case information such as a chain of custody.
In response, the same authors introduced the Digital Forensic Analysis
eXpression, or DFAX, a language extending CybOX (the predecessor to
STIX) for use in the digital forensics community. DFAX eventually
evolved to become the Cyber-investigation Analysis Standard Expression
(CASE) \cite{caseyAdvancingCoordinatedCyberinvestigations2017},
which we leverage as \emph{fastlabel}'s standard output format. CASE is
perhaps the most comprehensive and actively supported ontology available
for digital forensics; contributors include NIST with support from the
Linux Foundation.

\subsection{CASE and Python
bindings}\label{case-and-python-bindings}

CASE is a vendor-neutral format designed to document both technical and
non-technical information about a digital forensics case
\cite{caseyAdvancingCoordinatedCyberinvestigations2017}. It aims to
cover as many OS-specific and application-specific artifacts as
possible, while still providing the flexibility to describe artifacts
from uncommon applications. In theory, data exported from any major
vendor, such as Cellebrite, Magnet, or FTK, can be converted into a
valid CASE file. CASE is an extension of the Unified Cyber Ontology, or
UCO, which simply provides basic objects that are not specific to
digital forensics (such as applications or users). Consistent with the
CASE project's documentation, CASE and CASE/UCO are one and the same.

CASE is built on the Resource Description Framework (RDF), a model for
describing information using relationships. Two objects are linked using
relationships, each of which is described as a ``triple''. This pattern
allows for directed, labeled graphs to be expressed using RDF. The
ontology of CASE objects is defined using the Terse RDF Triple Language,
or Turtle, which allows these triples to be written in a simple text
format. In many ways, the Turtle definitions can be seen as the class
definitions for CASE objects; instances of these CASE objects can be
expressed in JSON-LD, an extension of JSON for linked data. A collection
of CASE objects is known as a bundle; applications can add instantiated
CASE objects to a bundle as needed.

Because the CASE format itself is language-agnostic, it is necessary to
write language-specific libraries that allow for instantiating CASE
objects. As of writing, the CASE project provides Python bindings for
UCO/CASE version 1.4 \cite{CaseworkCASEMappingPython}, in which each
unique object is represented as a Python class, which can be
instantiated to produce individual objects. However, this library has
several limitations due to its design. For example, CASE objects are
internally represented as dictionary of strings, rather than a set of
instance variables. While this makes it easier to serialize these
objects to JSON-LD dictionaries, it also makes it extremely difficult to
work with these objects after they have been instantiated.

It is also worth noting that each of the objects in the CASE ontology
appear to have been manually translated to their corresponding Python
class definitions. This is slow and time-consuming, especially given the
context that a significant overhaul of UCO/CASE to version 2.0 is
underway, with new object definitions; there appears to be no active
effort to update the 1.4 bindings to 2.0.

\begin{itemize}
\tightlist
\item[$\square$]
  \#task Citation to the 2.0 branch of CASE/UCO, not the original branch
\end{itemize}

AKF leverages (and contributes, though not the direct result of this
thesis) Pydantic-based bindings for CASE. The foundation for this system
will be the Pydantic library for Python, which allows developers to
quickly define classes (referred to as ``Pydantic models'', or simply
``models'') with built-in schema validation and serialization based on
Python type hints \cite{colvinPydantic2024}. More broadly, it allows
us to simplify the declaration of individual objects while providing
runtime type validation and automatic casting.

Examples of CASE-related definitions, as well as a detailed comparison
of AKF's bindings compared to the existing CASE bindings, can be found
in \autoref{case-python-bindings}. One notable
example from this section is the simplification of a CASE object
declaration from 43 lines in the existing CASE bindings to only three
lines in AKF. These simple declarations are largely possible because the
conversion of instance variables to valid JSON-LD keys is deferred until
serialization, rather than converting them to dictionaries immediately
upon instantiation. This design choice allows us to centralize the
serialization logic in a single parent class, which all CASE objects
inherit from. In exchange for slightly increasing the complexity of
converting \passthrough{\lstinline!numberOfLaunches!} to a dictionary
with the correct key name, we can massively simplify the logic for
declaring CASE objects.

A script is provided with AKF's CASE bindings to automatically parse the
RDF files and convert them to valid Pydantic models. It automatically
converts XSD datatypes to their native Python types (or a custom wrapper
type if a native type does not exist), correctly inherits classes, and
automatically generates docstrings and Pydantic fields as applicable.
Additionally, the script also topologically sorts dependencies in the
same file; the parent class of an RDF object may be declared
\emph{after} its child class, which is disallowed in Python. This
greatly simplifies the process of maintaining Python bindings for
UCO/CASE, as well as the overall design of the library for future needs.

\subsection{CASE integration in
AKF}\label{case-integration-in-akf}

With these Python bindings, we can integrate them throughout
artifact-generating libraries in AKF. There are two options for
generating and attaching CASE artifacts to a scenario - during scenario
generation, and after scenario generation.

Various functions and classes throughout the AKF core libraries and
agent API accept an optional CASE bundle when invoked or instantiated.
As users call CASE-compatible functions, these functions can
automatically add CASE objects that correspond to the artifacts
generated as part of their execution. For example, if the agent
subservice API for automating Chromium browser actions is instantiated
with a CASE bundle, navigating to a page using the API will
automatically generate a CASE object describing the page visit and add
it to the bundle. This process can occur entirely within the host,
allowing CASE-related logic to remain out of the agent where desirable.

However, recall that the use of RPyC for agent communication allows AKF
to pass complex objects between the agent and the host machine. This
includes CASE bundles and objects, as well. For example, suppose that a
CASE object must be made for a file downloaded from the internet that
frequently changes in location, size, and content. This can only be
accurately constructed using some form of agent-side analysis as the
action is taking place. Once constructed, the object can be returned to
the host machine to append to a larger CASE bundle.

Some CASE ontology objects, such as those describing Windows prefetch
files, are best constructed at the time disk images and other core
outputs are created. For example, it is possible to create CASE prefetch
objects during the execution of a scenario. However, these objects are
likely to become outdated if their corresponding applications are run
again later in the scenario, thus changing the content of the prefetch
files and making the existing CASE objects inaccurate.

In turn, to make the generation of such objects more efficient and
accurate, certain CASE objects must be discovered ``after the fact'';
that is, they cannot be automatically generated as part of AKF
automation routines. This can be achieved by analyzing core outputs
(such as disk images) using independent tooling. This includes
general-purpose DFIR tools that support CASE objects (such as Autopsy),
as well as tools with an explicit focus on constructing CASE objects
(such as those that depend on the official or AKF Python bindings for
CASE).

However, ``after the fact'' analysis can also be achieved on live
virtual machines using existing AKF design patterns. In particular, it
is possible to write RPyC subservices whose sole purpose is to generate
CASE objects. For example, the agent could be instructed to collect the
contents of prefetch files immediately after a disk image is created,
allowing it to construct CASE prefetch objects that are reflective of
the disk image without the need for independent tooling. CASE-oriented
behavior can also be implemented in existing subservices as well, such
as including a function in the Chromium subservice dedicated to
identifying and creating CASE objects for all Chrome/Edge-related
artifacts.

The flexibility of these two approaches -- largely enabled by their deep
integration into AKF -- makes it possible to construct CASE objects in a
manner that requires little additional effort by scenario developers. In
many cases, scenario developers do not need to be concerned with
constructing their own CASE objects when using high-level APIs, so long
as an AKF library developer has written support for automatic CASE
object construction. This significantly reduces the need for scenario
developers to construct artifact-specific ground truth through manual
analysis of synthesizer-created outputs.

By extension, this means that the detailed documentation of AKF outputs
is innate to many scenarios constructed using AKF. By lowering the
effort required to document an AKF-generated scenario, this improves the
likelihood that any public AKF scenario can be immediately useful (or
determined to be useful) to researchers and educators. This
significantly contributes to AKF's goal of supporting a larger ecosystem
around its images, as the CASE bundles of many scenarios can be queried
in bulk to identify datasets that might be useful for a specific purpose
without having to download the dataset itself. This information can also
be used to identify and analyze broader trends across scenarios, such as
the frequency of a particular artifact appearing in all Windows
datasets.

While this machine-readable reporting significantly improves the ability
of the forensic community to locate useful datasets, it is also verbose
and not suitable as a human-readable summary. Human-readable reporting
is particularly relevant in a classroom setting, where the distribution
of simplified answer keys to graders and students focusing on key
artifacts is preferable to the exhaustive reporting provided by a CASE
bundle. This leads us into the following section, which briefly
addresses the conversion of AKF-generated metadata into human-readable
reports.

\section{Human readable reporting}\label{human-readable-reporting}

\section{Distribution and community
reproducibility}\label{distribution-and-community-reproducibility}

After generating the scenario itself and any metadata that should be
included with the dataset, there is still the challenge of distributing
this information in a manner that makes it suitable for broad reuse. A
key challenge identified by Grajeda et al.~was the difficulty in
reproducing results in the field of digital forensics. While this is
largely attributed to the \emph{availability} of forensic datasets in
general, it can also be attributed to challenges in \emph{reproducible
constructions} of synthetic datasets.

Before addressing the low-level use of AKF as part of \autoref{chapter-six}, we briefly discuss the infrastructure needed to
support community usage of not only the outputs of AKF scenarios, but
synthetic datasets as a whole. Note that for the remainder of this
section, scenarios and datasets are both implied to be synthetic, as the
principles of reproducibility are less applicable to real-world
datasets.

To make results from a synthetic scenario reproducible, there are four
elements that must be distributed with the scenario:

\begin{itemize}
\tightlist
\item
  Any core outputs or individual artifacts generated from the virtual
  machine.
\item
  Any metadata, ground truth, or other reporting that describes the
  scenario.
\item
  The OS-specific ``base image'' used to create the dataset, typically a
  virtual machine with a newly-installed operating system on which all
  synthesizer actions are performed.
\item
  The precise instructions required to build the scenario from the
  provided base image, whether human- or machine-readable instructions.
\end{itemize}

Forensic datasets have long included core outputs and individual
artifacts, well before the development of AKF and other synthesizers;
there is limited value in a forensic scenario without anything to
analyze. Various forms of ground truth have also long been a part of
forensic datasets in various forms; some educational datasets include
PDF answer keys, while some research datasets have been labeled to
include metadata about the dataset.

However, less common are detailed instructions to build the overall
scenario. Manually constructed datasets rarely describe the actions
taken to build a scenario in detail; for example, the educational
M57-Patents scenario built by Woods et al.
\cite{woodsCreatingRealisticCorpora2011} provides an instructor PDF
with a high-level timeline of actions taken in English. This detail is
sufficient for educational purposes, but is too imprecise to guarantee
that researchers following this timeline will construct the image in the
same manner as intended. As described in \autoref{challenges-in-developing-synthetic-datasets},
non-determinism can be acceptable and even desirable in educational
contexts, but is less desirable for tool validation and research.

Even rarer in manually constructed datasets is the inclusion of the base
image before any actions are performed. This may be attributable to both
copyright concerns and a perception that knowledge of the operating
system alone is sufficient to rebuild the base image; while true that
setting up a base image is straightforward, any need for human
interpretation introduces a source of non-determinism that may not be
desired.

Synthesizers significantly improve on the lack of precise instructions;
their machine-readable scripts both document and execute the precise
instructions needed to reconstruct a scenario. However, this is
dependent on the availability of an OS- and synthesizer-specific base
image; again, many synthesizers expect their users to follow a set of
human-readable instructions to prepare a virtual machine for use.

Where copyright issues are not a concern, synthetic images should aim to
include a complete definition of a virtual machine to be used as the
base image. This may be a complete, hypervisor-specific virtual machine
(archiving and compressing the entirety of the associated virtual
machine folder), a hypervisor-independent virtual appliance (in a format
such as OVF), or another infrastructure-as-code solution to define and
build virtual machines, such as Vagrant.

AKF is designed to provide all four of these elements in every scenario
it creates; elements 1, 2, and 4 are inherent to all synthesizers, while
base images can be provided as Vagrantfiles as described in \autoref{setup-and-basic-usage}. This ensures that
results from AKF-generated scenarios are reproducible from both a
dataset creation and dataset usage perspective.

Although not explored as part of this thesis, the inclusion of all four
of these elements as part of a well-structured, standardized
distribution format could be used to build a distribution platform
similar to CFReDS, but with more powerful discovery and querying
functionality. While the contents of the scenario are largely described
by CASE, it may also be possible to perform queries based on the
contents of Vagrantfiles and AKF scripts. For example, a user may want
to search for all images that use the agent-based Chromium artifact
generation described in \autoref{the-akf-agent}, which can be achieved by searching for the inclusion of the
relevant AKF libraries in the scenario's scripts. This, however, does
not address the challenge of storing and distributing scenarios in an
efficient manner to support such a platform; this is partially discussed
in \autoref{distribution}.

With the reproducibility and value of AKF-generated scenarios
established, we now move to a discussion of how to invoke and leverage
the underlying technologies that provide these benefits.

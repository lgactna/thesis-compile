The chapter list, 2e.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This outline assumes that \emph{every} stretch goal is achieved,
including those that I have doubts about being able to implement.

\textbf{39.0 - Abstract}

\begin{itemize}
\tightlist
\item
  (Dedication)
\item
  (Acknowledgments)
\item
  (Abstract)
\end{itemize}

\autoref{chapter-one}

\begin{itemize}
\tightlist
\item
  \textbf{(1.1) History of digital forensics}: How did we get to the
  present state of the field? What are forensic images in the broader
  context of digital forensics as a whole?
\item
  \textbf{(1.2) Purpose of forensic images}: How are forensic images
  used in ``the real world'' -- that, is what do forensic analysts do
  when presented with a new scenario? How does this differ from how they
  are used in the education of new forensic analysts, and how does this
  differ from how they are used in research (often for tool validation
  and development)?
\item
  \textbf{(1.3) Real and synthetic datasets}: Where do researchers and
  instructors actually get these datasets from? What is the difference
  between ``real'' and ``synthetic'' datasets, and what are the issues
  of developing or using each type?
\item
  \textbf{(1.4) Research objectives}: What are the final goals of this
  thesis?

  \begin{itemize}
  \tightlist
  \item
    Goals are same as described in the abstract: describe and implement
    a modern architecture for building new forensic datasets, provide a
    mechanism for reporting on and searching through the contents of
    forensic images, and greatly streamline the overall process of
    constructing a scenario around which a forensic dataset can be
    built.
  \item
    ``by the conclusion of this thesis, readers will understand the
    value of synthetic images in forensic research and education, as
    supported by an evaluation of AKF in an actual classroom setting''
  \item
    blurry line with 1.5, might just write 1.4/1.5 as one section
  \end{itemize}
\item
  \textbf{(1.5) Contribution}: Who benefits from this? What are the
  specific contributions to the field that AKF makes?

  \begin{itemize}
  \tightlist
  \item
    Will be pretty similar to the abstract - in short, it gives a
    modernized framework that is designed to enable a larger ecosystem
    in which AKF-generated images. This thesis contributes a framework
    that can be used to not only vastly reduce the time spent developing
    new datasets for research and education, but also improve the
    discoverability of existing datasets and promote the long-term
    development of the framework based on new advances in technology. In
    turn, educators and researchers alike will have a greater variety in
    the scenarios available to them\ldots{}
  \end{itemize}
\end{itemize}

\autoref{chapter-two}

\begin{itemize}
\tightlist
\item
  \textbf{(2.1?) Existing datasets}: What datasets (or collections of
  datasets) for digital forensics currently exist? Where do they come
  from, and what are their drawbacks?

  \begin{itemize}
  \tightlist
  \item
    what's in here that isn't already part of 1.3? is this really
    necessary? should 2.2 just be the entire chapter, and have it
    further broken down?
  \end{itemize}
\item
  \textbf{(2.2) Prior synthesizers}: At a high level, what are the major
  synthesizers that have been developed in the past, and how did they
  work? Why are synthesizers used at all, and what challenges do/did
  they solve? What were their specific contributions?

  \begin{itemize}
  \tightlist
  \item
    do NOT go into low-level technical/implementation details here,
    that's for the future chapters
  \item
    should contain similar content to the \textbf{CS 650 paper}

    \begin{itemize}
    \tightlist
    \item
      however, the content of that paper's literature review will need
      to be distributed across a bunch of sections - this is because
      we're now sprinkling low-level technical details of older
      synthesizers within future sections
    \end{itemize}
  \end{itemize}
\end{itemize}

\autoref{chapter-three}

\begin{itemize}
\tightlist
\item
  \textbf{(3.1) Motivation:} Why reinvent the wheel (again)? (The answer
  is that none of the existing synthesizers make use of modern Python
  features or best practices, and lack the interfaces necessary to
  support a community-driven approach to maintaining the synthesizer. on
  top of that, they don't use CASE and use non-standardized output
  formats\ldots)

  \begin{itemize}
  \tightlist
  \item
    in other words, what qualities did we observe from existing
    synthesizers that made it difficult to simply adapt or modify them,
    and completely build a new one from scratch instead? why did these
    qualities make it difficult to achieve the goals outlined in
    1.4/1.5?
  \item
    can be merged with the literature review if necessary\ldots{}
  \item
    this is NOT ``what does this contribute'', it's the ``why bother
    reinventing the wheel?''
  \item
    this is also NOT ``what does AKF do better?'' - we're just
    introducing the deficiencies in existing synthesizers and explaining
    why they're a problem. the solutions to those problems, which are
    enabled by AKF, will be described in the following sections
  \end{itemize}
\item
  \textbf{(3.2) Overview} : At a high level, what modules (or group of
  modules) do we need to implement for a synthesizer to do what it is
  designed to do? What technologies, such as hypervisors, do we depend
  on? What is each of these modules' roles, and how do they feed into
  other roles?

  \begin{itemize}
  \tightlist
  \item
    in other words, explain the role of
    \passthrough{\lstinline!akflib!}, the output and validation modules,
    etc
  \end{itemize}
\end{itemize}

All following sections, except for \autoref{chapter-eight} and
\autoref{chapter-nine}, are grouped by major ``modules'' (or groups
of libraries) that are a part of AKF. They roughly correspond to one of
the big colored boxes in the \textbf{Architecture} diagram.

\autoref{chapter-four} (more generally,
\passthrough{\lstinline!akflib!}, hypervisors, and the agent system)

\begin{itemize}
\tightlist
\item
  \textbf{(4.1) Overview}: What options exist for generating artifacts
  as part of a scenario dataset? How do each of them work, at a
  high-level? What techniques have each of the synthesizers in
  \autoref{chapter-two} taken?
\item
  \textbf{(4.2) Agentless artifact generation}: What's the role of a
  hypervisor in AKF, and what features can it provide to help facilitate
  artifact generation when we don't want to use an agent?

  \begin{itemize}
  \tightlist
  \item
    important to note here that the current implementation will only use
    VirtualBox, even if Qemu has been used elsewhere before
  \item
    \textbf{Do hypervisors belong elsewhere?} seems like an odd place to
    introduce them, since we almost certainly will need to explain them
    a little bit in 3.2
  \end{itemize}
\item
  \textbf{(4.3) Agent-based artifact generation}: How do we use agents
  and existing automation frameworks to simplify application-specific
  actions? Why is the RPyC-based system so much better than other
  options, such as \textbf{ForTrace}? How does this enable us to do
  runtime introspection, so we know that particular artifacts are
  actually on the disk?
\item
  \textbf{(4.4) Physical artifact generation}: How do we
  deterministically stick things in the slack space of a file in a
  filesystem? More broadly, how do we ``poof'' data onto a disk?
\end{itemize}

\autoref{chapter-five}

\begin{itemize}
\tightlist
\item
  \textbf{(5.1) Overview:} Great, so we've figured out how to generate
  artifacts. What are the actual file outputs that need to be generated
  by the framework (both core outputs and metadata)? Why are these
  important, and what are their actual uses in industry?

  \begin{itemize}
  \tightlist
  \item
    for metadata, the usefulness is in developing a comprehensive
    ecosystem and making AKF-generated images machine searchable, so
    researchers know what things of interest are in their disk -- even
    if the original creator didn't think that stuff was significant, and
    therefore didn't include it in any human-generated data

    \begin{itemize}
    \tightlist
    \item
      this statement probably belongs in 5.3. this is briefly alluded to
      in the \textbf{60 - Classes/61 - Old/CS 704/Final Project/Final
      paper\textbar CS 704 Final paper}
    \end{itemize}
  \item
    in incident response, you're not getting the whole picture if you're
    just looking at disk images or just network captures! so you
    shouldn't be training on \emph{just} disk images, either!
  \end{itemize}
\item
  \textbf{(5.2) Core outputs}: How do we generate disk/network/volatile
  captures? Can we optimize these outputs for making distribution and
  storage more efficient, and how have synthesizers (particularly
  \textbf{EviPlant}) tackled this issue before?
\item
  \textbf{(5.3) Metadata and ground truth:} What is ground truth used
  for, and why is it significant? How do we achieve logging, metadata,
  and ground truth generation through CASE? How can this information be
  used to build a comprehensive ecosystem?
\item
  \textbf{(5.4?) Human-readable reporting}: idk if this will be its own
  section, or it might just end up being a mention in 5.3 or
  \autoref{chapter-eight}; what about human-readable answer keys,
  similar to the ones in CFReDS? should the work regarding \textbf{60 -
  Classes/61 - Old/CS 704/Final Project/Final paper\textbar fastlabel}
  be here?
\end{itemize}

\autoref{chapter-six} (ok, so now you have all of these
systems to manipulate a virtual machine into automating a bunch of user
actions in a deterministic manner with comprehensive logging. but how do
you actually invoke these systems? and how do you generate the artifacts
themselves, to be placed onto the device?)

\begin{itemize}
\tightlist
\item
  \textbf{(6.1) Overview/imperative usage}: What does basic (imperative)
  usage of AKF look like? How do you set up the Python library,
  hypervisor, and possibly the ``base'' image used to generate the
  scenario? Should the ``base'' image be publicly distributable (if so,
  how do we deal with copyright concerns)?
\item
  \textbf{(6.2) Declarative inputs}: How do we define a
  \textbf{Declarative to imperative translation\textbar declarative}
  format that acts as a simpler interface to the imperative format, so
  that instructors (who might just want \emph{an image} with some files
  in it) don't have to learn how to program?
\item
  \textbf{(6.3) Using LLMs to build high-level scenarios}: How can
  recent advancements in LLMs be used to write AKF scenarios using the
  simpler declarative syntax, which can then be converted into the full
  imperative syntax?
\item
  \textbf{(6.4) Using generative AI for individual artifacts:} Even if
  we can automate everything, this still doesn't solve the issue of
  things like images, email conversations, and other things that may be
  easy to automate, but difficult to make by hand (but we still want
  these in the image). How can generative AI help solve this issue?

  \begin{itemize}
  \tightlist
  \item
    for example: the Data Leakage case has \emph{very} brief email
    conversations, and not a lot of noise to go along with it. there
    should be more noise, possibly involving conversations with other
    people.
  \end{itemize}
\end{itemize}

\autoref{chapter-seven} (if we end up with datasets
that end up being usable in CS 252, we'll probably need another section
to describe observations. should follow
\cite{mochEvaluatingForensicImage2012} somewhat closely)

\begin{itemize}
\tightlist
\item
  \textbf{(7.1) Scenario}: What class was this used in, and elements of
  the class are worth mentioning? What was the scenario we gave
  students? What was the context provided to students about the dataset
  (for example, were they told this was a synthetic dataset? if so, what
  were they told about it being synthetic?)?
\item
  \textbf{(7.2) Student analysis:} How well were students able to
  analyze the scenario? If there were specific items that we expected
  students to find, how many of these items were identified in the
  reports that students created?

  \begin{itemize}
  \tightlist
  \item
    \emph{Extreme} stretch goal - this only covers the student side of
    things. What about the instructor side of things? Do they think AKF
    covers their use cases, and is it as easy to use as I claim it is?
  \item
    Wouldn't it be great to have a full ransomware incident response
    scenario, where all of network, memory, and disk images are
    relevant, and there's more than one machine involved, and there's a
    bunch of ``typical'' user files that get encrypted? wouldn't that be
    great ???
  \end{itemize}
\item
  \textbf{(7.3) Findings/observations}: Were there other things of note,
  like the students noticing traces (\textbf{Synthesis pollution}) of
  AKF being left behind? Did students like the alternative scenario
  compared to an existing, human-crafted scenario? What did students
  like or dislike?
\end{itemize}

\autoref{chapter-eight} (structure depends a lot on what i simply
don't get done)

\begin{itemize}
\item
  \textbf{(8.1) Integration of recent advancements}: stuff like Operator
  that has significant, material value and does something I don't, but
  still has some drawbacks (particularly, the non-determinism of LLMs?)
  that don't make it applicable in every use case; not to mention it's
  not like it's \emph{incompatible} with AKF
\item
  \textbf{(8.2) Framework limitations}: the ``smaller'' things described
  below
\item
  OpenAI's Operator is a thing now
\item
  The smaller things that don't deserve extensive focus

  \begin{itemize}
  \tightlist
  \item
    Mobile device support (though
    \cite{demmelDataSynthesisGoing2024} does some work towards this)
  \item
    Handling other operating systems (simply because there's no time,
    not because it's not possible with the current architecture and
    strategies)
  \item
    Describing volatile memory captures and network captures? We can
    generate CASE entries as we're acting on the machine, but the
    contents of volatile memory captures and network captures may
    require after-the-fact analysis, and they might not fit well into
    CASE. What kind of labels do researchers working on memory/network
    datasets need?
  \item
    Limitations (whatever they end up being)
  \end{itemize}
\item
  Any discussions with the folks over at CFReDS/Josh Brunty/Coach Morgan
\item
  The ``creator'' side of things - does AKF suck to use? (see 7.2)
\end{itemize}

\autoref{chapter-nine}

\begin{itemize}
\tightlist
\item
  I conclude that this took a lot of time, and it is valuable, and i
  hope it will be useful to the greater forensic community because x, y,
  and z
\end{itemize}

\textbf{39.A - Architectural diagrams} - The diagrams and explanations
section. Includes a full label-less detailed diagram, individual
sections of the detailed diagram (with a brief explanation and a link
back to the relevant chapters), and the simplified diagram

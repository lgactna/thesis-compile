This chapter addresses the modules responsible for allowing users to
invoke the framework, both through a standard Python script and through
a high-level YAML file. It also addresses the generative AI modules that
can assist a user in building a scenario, as depicted in the partial
architectural diagram below.

!\textbf{39.6 - Building scenarios 2025-02-08 17.23.40.excalidraw}

At this point, we have provided the implementations for automating
artifact generation in a near-deterministic manner with comprehensive
logging and reporting. However, there is still the challenge of exposing
this functionality in a user-friendly manner. At a high level, there are
currently two ways to define an input to a synthesizer:

\begin{itemize}
\tightlist
\item
  An \textbf{imperative} format, in which the synthesizer is provided
  instructions in an imperative language and the developer must provide
  the exact instructions for the synthesizer to take through some
  exposed API.
\item
  A \textbf{declarative} format, in which the synthesizer is provided a
  file that describes the desired elements of the result, and it is up
  to the synthesizer to execute the instructions necessary to achieve
  the result.
\end{itemize}

Even if the \emph{process} of placing artifacts or performing actions
can be simplified through imperative and declarative inputs, the
challenge of deciding what actions to perform still remains. It is still
largely the responsibility of instructors to provide the actual
background noise to populate the images with. Although the high-level
languages provided by many of these frameworks make it easy to place
files at desired locations or visit websites that are part of a
scenario, these must all be defined and created ahead of time.

This chapter addresses the challenges of creating background noise and
providing simple APIs for complex GUI-driven applications. More
precisely, we address two questions -- how do we invoke AKF's automation
systems, and how does AKF assist a user in building a scenario? Here, we
explore AKF's imperative and declarative syntaxes, as well as the
viability of using large language models (LLMs) to assist in building
individual files and complete scenario descriptions.

\section{Scripting background}\label{scripting-background}

We begin by analyzing how synthesizers accept instructions for execution
-- more precisely, how do users define the sequence of operations that
the synthesizer should take to form the image?

For many of the frameworks created in the last decade, users define
scenarios by using a Python library to interact with the framework,
setting up the virtualized environment and performing high-level actions
on the environment. This abstracts away the underlying calls to the
virtualized environment from the scenario developer. This code-based
approach represents an \emph{imperative} strategy to scenario creation,
where the user describes how the image should be created by describing
the exact order and methodology by which actions should be taken.

It is worth noting that, like many automation frameworks such as
Playwright \cite{MicrosoftPlaywrightpython2025}, the language used
to interact with the synthesizer's API does not need to match the
language used to implement the synthesizer itself (although this is
often the case). For example, Playwright itself is implemented in
TypeScript, and therefore began with a Node.JS API. Today, Playwright
provides APIs in Python, Java, and C\#.

In contrast, custom scenario formats provided by \emph{D-FET}
\cite{williamCloudbasedDigitalForensics2011}, \emph{SFX}
\cite{russellForensicImageDescription2012}, and Yannikos
\cite{yannikosDataCorporaDigital2014} follow a \emph{declarative}
strategy. Here, a custom high-level language describes what the final
state of the image should be, representing a \emph{declarative} strategy
to scenario creation. Instead of importing libraries and writing code,
users state the desired elements of the forensic dataset, allowing the
synthesizer to decide \emph{how} to achieve the desired state. The
specifics of state management and execution are delegated to the
synthesizer.

Consider the following declarative \emph{SFX} code taken from
\cite{russellForensicImageDescription2012}. Here, a Windows 7
partition is created, after which a user called ``Gordon'' uses Firefox
to browse the internet:

\begin{lstlisting}[language=XML]
<disk
    <partition index="p1" hidden="0" size="48M" type="ntfs"
        <base os="windows7x64"/
        <user username = "Gordon"
             <browserhistory browser="firefox"
                 <url link="[http://bbc.co.uk"](http://bbc.co.uk") time="13:14:00 1 Jan 2013"/
             </browserhistory
        </user
    </partition
</disk
\end{lstlisting}

The same might be partially expressed in \emph{ForTrace} as the
following, excluding additional overhead for ground truth generation:

\begin{lstlisting}[language=Python]
import logging

from fortrace.core.vmm import Vmm
from fortrace.utility.logger_helper import create_logger
from fortrace.core.vmm import GuestListener

logger = logging.getLogger(__name__)

if __name__ == "__main__":
    logger = create_logger('fortraceManager', logging.DEBUG)
    macsInUse = []
    guests = []
    
    guestListener = GuestListener(guests, logger)
    virtual_machine_monitor1 = Vmm(macsInUse, guests, logger)
    # boottime expressed as "%Y-%m-%d %H:%M:%S"
    guest = virtual_machine_monitor1.create_guest(guest_name="w-guest01", platform="windows", boottime="2013-01-01 13:14:00")

    browser_obj = guest.application("webBrowserFirefox", {'webBrowser': "firefox"})
    browser_obj.open(url="[http://bbc.co.uk")](http://bbc.co.uk"))
    while browser_obj.is_busy:
        time.sleep(2)
    browser_obj.close()
    
\end{lstlisting}

Observe that although these two code blocks have the same expressive
power (i.e., they achieve the same overall outcomes), there is a clear
difference in the complexity and length between the two. It is
significantly easier to read and write the declarative XML in the first
code block, as it abstracts away the need to instantiate various
synthesizer objects and call specific methods. By extension, this also
allows for a common declarative syntax to be used across multiple
synthesizers, since low-level details do not need to be exposed as part
of the declarative syntax.

The primary benefit of an imperative approach to generation is its
flexibility; on a Python-based synthesizer, one can simply import
another library to extend the functionality of the base scenario
definition. This flexibility naturally comes at the expense of a greater
learning curve; while true that many digital forensic specialists are
likely to have programming experience, it is far easier to learn a
restricted declarative specification (like XML) than an entire
programming language, which may entail additional setup (such as an IDE,
dependencies, and so on).

When accessibility is preferred over functionality, declarative syntaxes
are often more powerful than imperative syntaxes. Certain scenario
developers, such as classroom instructors, may not need the low-level
control provided by an imperative syntax or a full programming language
such as Python. It also takes time to learn about the functionality
exposed by the synthesizer's library, not to mention learning the
programming language itself. These are the primary motivators behind
supporting well-defined declarative syntaxes.

Of course, low-level control is still important, especially when
external libraries must be used to implement functionality not
inherently exposed by a synthesizer. For this reason, some synthesizers
support both declarative and imperative scripts to generate scenarios;
for example, the Python-based \emph{hystck} and \emph{ForTrace}
frameworks allow users to write YAML scripts to execute actions. This
highlights the fact that both declarative and imperative approaches can
be used simultaneously; in particular, it demonstrates that
declarative-to-imperative translators can be written to support
arbitrary declarative languages, such as those of both SFX and ForTrace.
(While not explored in this thesis, it is also worth noting the
GUI-based interfaces provided by \textbf{Yannikos et al.} and
\textbf{ForGe} for building scenarios.)

AKF supports both an imperative syntax (through its Python API) as well
as a declarative syntax. Unlike prior synthesizers, AKF's declarative
syntax supports both execution and declarative-to-imperative
translation, allowing users to quickly create and modify imperative
scripts from high-level declarative descriptions.

\section{Setup and basic usage}\label{setup-and-basic-usage}

Like many of its predecessors, AKF implements its functionality and
exposes its API in the same language, Python 3. There are numerous
advantages to a Python-based API; besides the relatively low difficulty
of setting up and using Python, its rich ecosystem allows scenarios to
be extended through the use of other libraries from the Python
ecosystem. For example, if a user wanted to conditionally execute
certain parts of a scenario by testing if a particular remote service is
currently online, a user could use the \emph{Requests} library
\cite{Requests31Documentation} to issue an HTTP request out-of-band
before performing the same action in a virtualized environment.

Users must have two foundational technologies for AKF to operate -- an
installation of Python 3.11 or later and a supported hypervisor. AKF
currently only supports VirtualBox, though QEMU/libvirt has also been
used in prior synthesizers. AKF uses
\passthrough{\lstinline!pyproject.toml!} to define Python library
dependencies, which can be installed into a virtual environment using a
package manager such as \emph{pip} or \emph{uv}.

At this point, a virtual machine must be prepared for use with AKF. As
with prior synthesizers, it is possible to manually configure a machine
by downloading a supported operating system and creating a new virtual
machine from scratch. The manual process, which is similar to that of
other synthesizers, is as follows:

\begin{itemize}
\tightlist
\item
  Download an ISO or pre-prepared virtual machine from a distributor
  with the desired operating system.
\item
  If necessary, create a new VM with that operating system image and
  install it.
\item
  Configure the virtual machine with the desired host resources,
  including two network interfaces - one connected to the NAT adapter
  for general internet usage, and one connected to the host-only adapter
  for agent communications.
\item
  Create an administrative user with known credentials. Configure the
  operating system as desired to reduce friction with the synthesizer
  (disabling UAC prompts, enabling auto-logon, etc.)
\item
  Build and copy the OS-specific AKF agent to the virtual machine,
  configuring it as a startup application. Add firewall rules to ensure
  that the host and agent are able to communicate.
\end{itemize}

After following this process, the virtual machine can now be cloned and
used as needed in AKF scripts. Although relatively straightforward, this
process is still time-consuming, especially when adapting this process
for new operating systems. While a prepared AKF virtual machine can
theoretically be distributed (in a virtual appliance format such as
OVF), this may run into legal issues if software on the underlying
operating system is copyrighted.

As a result, AKF makes use of modern infrastructure-as-code solutions to
vastly simplify the setup of new virtual machines. Vagrant, developed by
HashiCorp, is a tool for rapidly building development environments
\cite{HashicorpVagrant2025}. It allows users to define and build
virtual machines on a variety of virtualization platforms, such as
VirtualBox and VMWare. Virtual machines are built using a ``box'' as a
base image, which is then configured according to a Vagrantfile
describing hypervisor-specific configuration options as well as
instructions to provision the machine with applications. (A similar
approach of distributing the ``differences'' of base images is used to
reduce the size of distributed forensic datasets by \textbf{EviPlant},
as described in \autoref{distribution}.)

The AKF Windows agent includes a Vagrantfile for creating a new Windows
11 virtual machine with the agent installed and configured, which can
easily be adapted for other platforms and hypervisors. A robust
ecosystem of Vagrant boxes for varying Linux distributions and Windows
versions exists, many of which can be pulled from the Vagrant public
registry \cite{hashicorpHashiCorpCloudPlatform}. When combined with
the flexibility of Vagrant over multiple virtualization platforms, this
can significantly improve the reproducibility and usability of AKF
across many platforms. It should also be noted that Vagrant can be used
to configure and build larger environments with multiple machines. For
organizations that are able to express corporate environments as
Vagrantfiles, this could allow AKF to perform artifact generation at
scale, allowing for incident response scenarios reflecting real-world
networks.

Following setup, developers can build scenarios by using the AKF core
libraries (\passthrough{\lstinline!akflib!}) and the API of the
platform-specific agent installed onto the virtual machine. This
reflects typical imperative usage, in which environment setup, artifact
generation, and output generation is handled explicitly through a script
executed through the Python interpreter.

A simple AKF script achieving the same outcomes as the ForTrace and SFX
scripts above follows:

\section{Declarative usage}\label{declarative-usage}

\subsection{Existing declarative
syntaxes}\label{existing-declarative-syntaxes}

As described previously, declarative inputs are well-structured files
with a fixed set of available actions -- effectively forming an API --
where each entry in the file specifies an artifact (or set of artifacts)
to be placed in the dataset, along with any configurable options that
are available for that artifact.

Declarative formats can be used in one of two ways. The first is
\emph{execution}, in which the elements of the declarative script are
directly interpreted to generate imperative API calls. This is
characteristic of synthesizers that only support declarative script
inputs, exposing no low-level APIs. This takes advantage of the
high-level nature of declarative scripts; a declarative script can
remain the same even if the libraries that execute it change, so long as
the \emph{interpreter} is updated accordingly. The second is
\emph{translation}, in which the declarative script is used to generate
an equivalent imperative script adhering to a particular synthesizer's
API. This allows the declarative script to be used as a ``base'', after
which an experienced scenario developer can make additional
modifications to the generated imperative script as needed. Such scripts
are subject to changing dependencies and deprecated functions, but can
be regenerated so long as the \emph{translator} is updated accordingly.

It is important to note that a declarative syntax, which may be more
``rigid'' in structure, does not preclude the use of randomness. One
notable example of this is the discrete-time Markov chains used by
Yannikos et al.~to express scenarios in a probabilistic manner, with
each state of the Markov chain representing a particular action (sending
an email, deleting a file, etc.) taken by the synthesizer
\cite{yannikosDataCorporaDigital2014}. These chains are evaluated at
runtime to generate multiple unique datasets from a single description.

The challenges of defining a suitable declarative syntax for a
particular synthesizer is not unlike the challenges faced in general
programming language design. There are several key factors to the
success of imperative programming languages that extend to declarative
syntaxes, some of which are derived from \cite{finkel1996advanced}
and described as follows:

\begin{itemize}
\tightlist
\item
  The language should be \textbf{simple}, using as few basic concepts as
  possible. This makes code easier to read and write, an important
  aspect for users with limited programming experience.\\
\item
  The language should be \textbf{modular}, such that the role and
  interfaces of individual program units is clear.
\item
  The language should be \textbf{predictable}, such that users can apply
  their existing knowledge of a synthesizer to easily implement or add
  new features to a scenario.\\
\item
  The language should \textbf{abstract} as much as possible away from
  the user, such that the minimum information needed to fulfill artifact
  generation is exposed to the user.
\end{itemize}

Perhaps the most important factor, however, is an awareness of the
\textbf{purpose} of the declarative syntax. The purpose of a synthesizer
is to make it easier to generate forensic artifacts and datasets. The
declarative language should reflect this, focusing on making actions and
artifacts as easy to declare and customize as possible.

In designing the AKF declarative syntax, the declarative syntaxes of
both prior syntaxes and unrelated technologies were evaluated. An
analysis of some of these syntaxes, with examples, is described briefly
in \autoref{historical-declarative-syntaxes}.
However, two syntaxes in particular contributed the most to the AKF
declarative syntax: those of ForTrace and Ansible.

ForTrace uses YAML to express scenarios in a declarative manner.
ForTrace influenced both AKF declarative syntax and the libraries
leveraging the syntax significantly, in large part because it was the
sole synthesizer identified with both imperative and declarative support
that was open source.

Below is a simple example of a ForTrace declarative scenario:

\begin{lstlisting}
name: haystack-example
description: A example action suite to generate a haystack (traffic)
author: MPSE Group
seed: 1234
collections:
  c-http-0:
    type: http
    urls: ./generator/friendly_urls.txt
settings:
  host_nfs_path:
  guest_nfs_path:
applications:
hay:
  h-http-0:
    application: http
    amount: 3
    collection: c-http-0
needles:
  n-http-0:
    application: http
    file: [https://dasec.h-da.de/](https://dasec.h-da.de/)
    amount: 1
dumps:
  d-dump-0:
    dump-type: mem
    dump-path: /home/fortrace/gendump.file
\end{lstlisting}

At a high level, ForTrace scenarios contain five distinct elements:

\begin{itemize}
\tightlist
\item
  Metadata about the scenario, such as the name, description, and author
  of the scenario.
\item
  ``Collections'' of data that can be reused throughout the scenario in
  supported application types, such as a newline-separated list of URLs.
\item
  Configuration options, which may be applied to individual applications
  or the entire scenario.
\item
  The actual artifacts to create as part of the
  \passthrough{\lstinline!hay!} and \passthrough{\lstinline!needles!}
  sections, where \passthrough{\lstinline!hay!} includes artifacts that
  should be considered background noise, and
  \passthrough{\lstinline!needles!} includes artifacts that should be
  considered significant. Each artifact contains a unique ID, an
  application type (the \passthrough{\lstinline!application!} key), and
  arguments that are specific to the application responsible for
  generating the artifact, such as a the URLs for web browsing.\\
\item
  Any core outputs that should be created as part of the scenario.
\end{itemize}

This file is passed into a ``generator'', which parses the contents of
the YAML file to prepare various internal data structures, initialize
the virtual machine, and then execute the actions specified in the
\passthrough{\lstinline!hay!} and \passthrough{\lstinline!needles!}
sections in a random order according to the
\passthrough{\lstinline!seed!} key. Depending on the value of the
\passthrough{\lstinline!application!} key, the data for that action is
passed to an application-specific handler that interacts with the
running virtual machine using existing ForTrace libraries. Once all the
actions have been executed, the generator creates any requested outputs
(such as volatile memory dumps) and shuts down the virtual machine.

This analysis provided insight into the design decisions and
functionality required to execute actions from the high-level
descriptions of a scenario. In particular, it demonstrates the need for
actions or artifacts to be defined in a consistent, flexible manner such
that program state and other data can be passed to application-specific
libraries as needed. It also demonstrates the need for various levels of
configuration, including scenario-wide configuration,
application-specific configuration, and action/artifact-specific
configuration. ForTrace implements this in a somewhat inflexible manner;
in fact, nearly all declarative language support is contained in a
single file, with a hardcoded ``router'' handling each unique
\passthrough{\lstinline!application!} type. This makes it difficult to
add support for new applications without significant effort,
particularly because the generator must be aware of every possible
action/artifact type ahead of time.

With these priorities and issues from ForTrace identified, are there
ideas from other technologies that can be used to address them? That is,
are there other technologies designed to execute a large set of complex
actions, using a simple but flexible and configurable syntax, and how
does it work? Ansible, the second major inspiration for the AKF
declarative syntax, precisely fills this need.

Ansible is an open-source automation framework that is often used to
remotely configure Windows and Linux machines at scale, allowing
organizations to interact with many machines at once without the need to
install orchestration software on these machines in advance. To achieve
this, users write \emph{playbooks}, which are simple YAML files that
contain one or more \emph{plays}. Each play is simply a set of
\emph{tasks} that is run on multiple machines at once, and each task
depends on a \emph{module} that is designed to achieve a single,
specific outcome.

The following is a simple Ansible playbook with a single play, derived
from the official Ansible documentation for playbooks:

\begin{lstlisting}

- name: Update web servers
  hosts: webservers
  remote_user: root
  tasks:
  - name: Ensure apache is at the latest version
    ansible.builtin.yum:
      name: httpd
      state: latest
  - name: Write the apache config file
    ansible.builtin.template:
      src: /srv/httpd.j2
      dest: /etc/httpd.conf
\end{lstlisting}

This play uses the \passthrough{\lstinline!yum!} package manager to
install Apache, and then copies a local file to the remote host.
\passthrough{\lstinline!ansible.builtin.yum!} and
\passthrough{\lstinline!ansible.builtin.template!} are both modules in
the \passthrough{\lstinline!ansible.builtin!} collection included with
all default Ansible installations, which accept parameters passed as a
YAML dictionary.

Although Ansible contains many features that contribute to its
flexibility, the two important concepts of Ansible that are relevant to
AKF are \emph{roles} and \emph{modules}. Roles are a collection of
Ansible resources that typically achieve some ``larger'' reproducible
goal, typically by running multiple tasks and leveraging variables,
configuration options, and files included as part of the role. Roles can
include \emph{modules}, which are standalone imperative scripts
(typically in Python) that accept arguments, execute code based on those
arguments, and return data using well-structured interfaces. These
modules, as shown above, can be called and executed from playbooks or
executed independently on the command line.

These concepts are extremely relevant to synthesizers, as they must
support individual application-specific actions and group these actions
together in a flexible, well-defined manner. As described in
\autoref{chapter-four}, each of the RPyC subservices of AKF
agents expose a group of application-specific automation methods. The
functionality of each of these groups must be re-exposed in a
declarative manner, which can be achieved by adapting the concept of
Ansible roles and modules to AKF.

Together, the ForTrace and Ansible syntaxes provide three concepts that
are reflected in the AKF syntax, described further in the following
section:

\begin{itemize}
\tightlist
\item
  The overall structure and information of the data contained in the
  YAML file
\item
  An action syntax that allows us to declare individual actions,
  referring to those actions by name, and pass arguments directly to
  that action for translation \emph{or} execution
\item
  A modular architecture that allows us to define the supported
  arguments of each action and expose them to the declarative
  interpreter, while also being as decoupled from the standard
  imperative library as much as possible
\end{itemize}

\subsection{The AKF declarative
syntax}\label{the-akf-declarative-syntax}

The AKF declarative syntax is very similar to the Ansible playbook
syntax. Declarative scripts are comprised of metadata, global
configuration, libraries to import, and individual tasks to execute as
part of the scenario. Each task refers to a single \emph{module} by name
using a qualified Python import path, accepting a dictionary of
arguments in addition to global configuration overrides.

These modules are implemented as subclasses of
\passthrough{\lstinline!AKFModule!}, an abstract base class that accepts
Pydantic models. These Pydantic models dictate and validate the
arguments accepted by the module, which must act accordingly.
\passthrough{\lstinline!AKFModule!}s are responsible for two separate
tasks:

\begin{itemize}
\tightlist
\item
  When instructed to perform actions directly from the argument model,
  the \passthrough{\lstinline!AKFModule!} should import AKF core
  libraries and agent APIs to carry out the required actions.
\item
  When instructed to generate imperative code from the argument model,
  the \passthrough{\lstinline!AKFModule!} should generate the equivalent
  code that \emph{would} execute the actions if run and report on the
  library dependencies necessary to run the code.
\end{itemize}

In both cases, modules can read and modify a global state dictionary
that allows otherwise independent modules to cooperate with each other.
For example, if an action should be executed in a context manager,
causing the indentation level of the code to increase, successive
modules generating code within the context manager can increase the
indentation level of generated code, as well. Additionally, this allows
for ``outputs'', such as CASE bundles, to be passed and gradually
constructed across modules. This design allows for context-aware code
generation and action execution. More importantly, it allows for the
declarative syntax to be implemented wholly independently of the core
libraries, allowing for flexibility in the implementation of other AKF
features.

An example of a declarative AKF scenario, carrying out the same actions
as \ldots{}

(a brief explanation of the actual elements of the declarative file,
like the keys and stuff)

how the interpreter actually works (based on this example) -- how it
instantiates stuff based on the declared libraries, and how it actually
looks up the modules and passes information to them

something to tie it into the next two sections.

\section{Using generative AI for individual
artifacts}\label{using-generative-ai-for-individual-artifacts}

As it currently stands, users of synthesizers must still perform a
significant amount of work towards generating the artifacts to be
planted. While the process of generating an image based on some
predefined scenario has been streamlined through existing synthesizers,
users still need to define all of the data that they want to plant. For
example:

\begin{itemize}
\tightlist
\item
  If a user wants to place 100 photos on the drive to simulate real
  usage, the user needs to pass in 100 realistic images;
\item
  If a user wants to simulate an email or other online conversation, the
  user needs to pass in the entirety of the conversation to simulate;
\item
  If a user wants to generate ``proprietary'' documents to emulate some
  form of corporate sabotage, the user would need to generate a variety
  of Microsoft Office, PDF, or other files in these formats ahead of
  time.
\end{itemize}

The net result is that although creating images for the purposes of tool
validation and research can be accomplished with existing frameworks,
creating realistic images that are more reflective of real-world
scenarios that a forensic analyst might encounter still requires
extensive work. While true that images should often be small enough in a
classroom setting to allow the student to explore a single specific
technique, real-world scenarios encountered by analysts are typically
not limited by time or size. An analyst might have to deal with a drive
used over the course of a decade to store many photographs and send many
messages. Such scenarios are valuable training material for courses that
encapsulate a long period of forensic study, allowing a student to apply
many different techniques in reconstructing a large-scale scenario.

With recent advancements in generative AI, popularized by services such
as Midjourney and ChatGPT, it is now significantly easier to generate
realistic images and text content from short, high-level descriptions.
Additionally, various services exist for creating realistic audio and
video files that emulate a particular person's voice or facial
movements; these can be used to generate additional scenario content of
interest, especially if the scenario is based on a real-world event.

It holds that generative AI can be used to quickly populate forensic
datasets with realistic conversations and images consistent with an
arbitrary scenario. For example, a corporate espionage case could be
built by providing a large language model such as ChatGPT with prompts
to describe complex machinery in both a technical writing and a
conversational style. Simultaneously, similar prompts can be passed into
an image synthesizer such as Midjourney to produce related images. The
images and text produced can then be used to create documents describing
an unreleased product of high value, providing a pipeline through which
significant artifacts can be planted onto a forensic image.

This idea can be extended further by training models on specific
datasets; for example, if an instructor wished to create a fictional
scenario in which a user frequently interacts with users of a particular
online community, a large language model could be trained on available
conversations to provide a degree of realism to the scenario. However,
as mentioned before, this faces the challenges of ownership, privacy,
and legality behind works derived from publicly available information
that was (likely) not published with the expectation of its usage in an
AI model.

It is important to note that the inclusion of generative AI into
synthesizers does not necessarily require deep integration with the
framework itself. Many existing frameworks could be extended to use
documents, images, or other data sourced from generative AI instead of
user-defined files without the need to change the architecture of the
framework. However, as advancements in AI continue, it may make sense to
directly integrate AI-driven actions into synthesizers. For example,
there may come a time in which synthesizers can be provided natural
language prompts (such as ``Open Firefox and browse to news-related
websites'') that directly lead to the generation of relevant artifacts,
without the need to explicitly program the process of browsing to a
website in advance.

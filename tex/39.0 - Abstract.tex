\section{Dedication}\label{dedication}

To those in the osu! tournament community, without whom I would have
never embarked on this journey;

To my numerous teachers and professors, especially Keith Lightfoot,
Rodney Rogers, Marc Miller, and Gabbi Bachand, whom I have limitless
appreciation and admiration for;

To those on the United States Cyber Team and the broader CTF community
for supporting me even when I flailed like a fish out of water;

And, of course, to my friends, family, and bed, who provided support and
motivation.

\section{Acknowledgments}\label{acknowledgments}

I want to express my immense gratitude to Nancy Latourrette for her
support, guidance, and mentorship throughout the development of this
thesis. This thesis would be nowhere without her ideas and experience,
and I am truly grateful and honored to have been able to work with her
throughout this experience.

I would also like to thank Bill Doherty for his review of a prior paper
from which some of this content is derived.

\section{Abstract}\label{abstract}

As our world becomes increasingly dependent on technology, the
advancement of digital forensics has become a key focus in the fight
against cybercrime. The forensic community depends on the availability
of disk images, network captures, and other forensic artifacts for
education, tool validation, and research. However, real-world datasets
often contain sensitive information that may be difficult to remove,
making them challenging to distribute publicly. As a result, researchers
and educators can encounter gaps in available datasets, typically
leading to the manual development of new datasets. While viable, this
approach is time-consuming and rarely produces datasets that accurately
reflect real-world scenarios suitable for comprehensive training and
education. In turn, there is ongoing research into forensic
synthesizers, which automate the process of creating unique,
synthetically created datasets that can be publicly distributed without
legal and other logistical concerns.

This thesis introduces the \emph{\emph{automated kinetic framework}}, or
AKF, a modular synthesizer for creating and interacting with virtualized
environments to simulate human activity. AKF significantly improves upon
the designs and implementations of prior synthesizers while largely
maintaining feature parity and usability. Additionally, AKF leverages
the CASE standard to provide human- and machine-readable reporting,
exposing low-level dataset features in a searchable format. Finally, AKF
describes options for leveraging generative AI to develop high-level
scenarios as well as individual artifacts. These contributions are
intended to improve the speed at which synthetic datasets can be created
and ensure the long-term usefulness of AKF-generated datasets and the
framework as a whole.
